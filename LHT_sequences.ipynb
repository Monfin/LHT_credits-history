{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from IPython.display import display as d\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.dataset import CreditsHistoryDataset\n",
    "from src.data.components.targets_indexes_reader import TargetsReader, IndexesReader\n",
    "from src.data.components.data_reader import DataReader\n",
    "from src.utils.sampler import SamplerFactory\n",
    "from src.utils.metrics import GINI\n",
    "from torchmetrics import MeanMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randint(0, 4, (5, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 3, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Embedding(num_embeddings=4, embedding_dim=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[ 1.2962,  0.5405,  0.5765, -0.8487,  0.2105,  0.0374, -1.7631, -1.2126],\n",
       "         [ 0.2306, -0.5026, -1.0136, -0.8195, -0.7585,  0.4862,  0.5229,  0.2072],\n",
       "         [-0.2808, -0.1399,  0.6364,  0.4589,  0.8277,  1.0517, -0.7562,  1.4967],\n",
       "         [ 0.4944, -0.2382,  0.6527, -0.6246, -0.8596, -1.7815,  0.0119,  1.2357]],\n",
       "        requires_grad=True)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(dict(a.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2808, -0.1399,  0.6364,  0.4589,  0.8277,  1.0517, -0.7562,  1.4967],\n",
       "        [ 1.2962,  0.5405,  0.5765, -0.8487,  0.2105,  0.0374, -1.7631, -1.2126],\n",
       "        [ 0.2306, -0.5026, -1.0136, -0.8195, -0.7585,  0.4862,  0.5229,  0.2072],\n",
       "        [ 0.4944, -0.2382,  0.6527, -0.6246, -0.8596, -1.7815,  0.0119,  1.2357],\n",
       "        [ 0.4944, -0.2382,  0.6527, -0.6246, -0.8596, -1.7815,  0.0119,  1.2357]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe701280bd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a(sample).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 1, 2, 3]), tensor([2, 3, 4, 2, 3, 4]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(torch.concatenate([torch.stack(item).T for item in a]).unbind(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int = 128, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.position_wise_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, input_size)\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(input_size, eps=1e-6)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "\n",
    "        x = self.position_wise_layer(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooModel(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int = 128, max_seq_len: int = 50, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.position_wise_forward = PositionwiseFeedForward(\n",
    "            input_size=emb_dim, \n",
    "            hidden_size=emb_dim * 2, \n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.linear_layer = nn.Linear(emb_dim, 1)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool1d(kernel_size=max_seq_len)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.position_wise_forward(inputs)\n",
    "\n",
    "        x = self.linear_layer(x).squeeze()\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_batch = (torch.randn(size=(32, 50, emb_dim)), torch.randint(0, 2, (32, ), dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_model = FooModel(emb_dim, emb_dim * 2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa614b19890>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(some_batch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(some_model(some_batch[0]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification.auroc import BinaryAUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINI(BinaryAUROC):\n",
    "    def __init__(self) -> None:\n",
    "        super(GINI, self).__init__()\n",
    "        \n",
    "    def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        return (2. * super().forward(logits, labels) - 1.) * 100.\n",
    "    \n",
    "    # def compute(self) -> torch.Tensor:\n",
    "    #     return super().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = GINI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(43.7500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a(some_model(some_batch[0]), some_batch[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0903,  0.0469,  0.0347, -0.1100,  0.0162,  0.0895,  0.0320,  0.1441,\n",
       "         0.0787,  0.0022,  0.0888, -0.0043,  0.1492, -0.0996,  0.0271,  0.0832,\n",
       "        -0.0649,  0.0250,  0.0833, -0.0095,  0.1098,  0.1297,  0.0403,  0.0176,\n",
       "        -0.0573, -0.0441, -0.1633,  0.0786, -0.0913,  0.0039, -0.0435, -0.0718],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(some_model(some_batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a._buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.979999999999993"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d((0.5749 * 2 - 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7188)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6924)\n",
      "tensor(11.7409)\n",
      "tensor(0.5587) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danil/projects/torch_template/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:436: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(0.6924, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(some_model.training_step(some_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.collate import ModelInput, SingleForwardState, BaseCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sampler(targets: dict, n_samples: int = 1000, replacement: bool = True):\n",
    "\n",
    "    targets = np.asarray(list(targets.values()))\n",
    "    \n",
    "    sampler_factory = SamplerFactory(\n",
    "        targets=targets, \n",
    "        n_samples=n_samples,\n",
    "        replacement=replacement\n",
    "    )\n",
    "    return sampler_factory.balanced_random_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(features_path: str, data_path: str, indexes_path: str, targets_path: str, use_sampler: bool = True, batch_size: int = 32):\n",
    "    features_dict = OmegaConf.load(features_path)\n",
    "\n",
    "    data_reader = DataReader(data_path=data_path)\n",
    "    data_reader.setup()\n",
    "\n",
    "    indexes = IndexesReader(train_path=indexes_path).train_indexes\n",
    "\n",
    "    targets = TargetsReader(targets_path).targets\n",
    "\n",
    "    targets = {idx: targets.get(idx) for idx in indexes}\n",
    "\n",
    "    dataset = CreditsHistoryDataset(\n",
    "        data=data_reader, \n",
    "        targets=targets,\n",
    "        indexes=indexes,\n",
    "        features=features_dict\n",
    "    )\n",
    "\n",
    "    print(f\"dataset sample: {dataset[0]}\")\n",
    "\n",
    "    train_sampler = set_sampler(\n",
    "        targets=dataset.targets, \n",
    "        n_samples=10000,\n",
    "        replacement=False\n",
    "    ) if use_sampler else None\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=BaseCollator(max_seq_len=50),\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True\n",
    "    ) \n",
    "\n",
    "    return dataloader, features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sample: {'numerical': tensor([[ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
      "        [ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
      "        [ 0.4800,  0.1688,  0.1680,  0.9858,  7.2181,  0.0000],\n",
      "        [ 3.1200,  2.6531,  0.4693, -0.8830,  7.2181,  0.0000],\n",
      "        [ 0.2400,  0.0925,  0.0923,  0.9957,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 1.2000,  0.4866,  0.4677,  0.8839,  7.2181,  0.0000],\n",
      "        [ 2.2800,  1.3662,  0.9791,  0.2032,  7.2181,  0.0000],\n",
      "        [ 2.6400,  1.8312,  0.9663, -0.2574,  7.2181,  0.0000]]), 'categorical': tensor([[ 8, 12,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4, 11,\n",
      "          0],\n",
      "        [ 8,  6,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          3],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  1,  4,  2,\n",
      "          0],\n",
      "        [10,  1,  4,  3,  0,  2,  5, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          2],\n",
      "        [ 0, 17,  4,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          6],\n",
      "        [ 6,  8,  3,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "         11],\n",
      "        [18, 14,  3,  3,  0,  2, 13, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          0],\n",
      "        [11, 13,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          4],\n",
      "        [11,  0,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [ 7,  2,  0,  1,  0,  2,  4,  2,  2, 17,  0,  1,  1,  1,  2,  0,  4,  3,\n",
      "          0],\n",
      "        [ 7,  7,  2,  3,  0,  2,  1, 16,  2, 17,  1,  1,  1,  1,  2,  3,  4,  0,\n",
      "          2]]), 'target': 0, 'length': 12, 'sample_index': '205752'}\n"
     ]
    }
   ],
   "source": [
    "test_dataloader, _ = initialize_data(\n",
    "    \"configs/data/features/features_credits_aggregated_v2.yaml\",\n",
    "    \"./data/credits-history/serialized/serialized_first_part_v2\",\n",
    "    \"./data/credits-history/indexes/ser_full_0_indexes/train_indexes.pickle\",\n",
    "    \"./data/credits-history/targets/targets_dict.pickle\",\n",
    "    use_sampler=False,\n",
    "    batch_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sample: {'numerical': tensor([[ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
      "        [ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
      "        [ 0.4800,  0.1688,  0.1680,  0.9858,  7.2181,  0.0000],\n",
      "        [ 3.1200,  2.6531,  0.4693, -0.8830,  7.2181,  0.0000],\n",
      "        [ 0.2400,  0.0925,  0.0923,  0.9957,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 1.2000,  0.4866,  0.4677,  0.8839,  7.2181,  0.0000],\n",
      "        [ 2.2800,  1.3662,  0.9791,  0.2032,  7.2181,  0.0000],\n",
      "        [ 2.6400,  1.8312,  0.9663, -0.2574,  7.2181,  0.0000]]), 'categorical': tensor([[ 8, 12,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4, 11,\n",
      "          0],\n",
      "        [ 8,  6,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          3],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  1,  4,  2,\n",
      "          0],\n",
      "        [10,  1,  4,  3,  0,  2,  5, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          2],\n",
      "        [ 0, 17,  4,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          6],\n",
      "        [ 6,  8,  3,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "         11],\n",
      "        [18, 14,  3,  3,  0,  2, 13, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          0],\n",
      "        [11, 13,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          4],\n",
      "        [11,  0,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [ 7,  2,  0,  1,  0,  2,  4,  2,  2, 17,  0,  1,  1,  1,  2,  0,  4,  3,\n",
      "          0],\n",
      "        [ 7,  7,  2,  3,  0,  2,  1, 16,  2, 17,  1,  1,  1,  1,  2,  3,  4,  0,\n",
      "          2]]), 'target': 0, 'length': 12, 'sample_index': '205752'}\n"
     ]
    }
   ],
   "source": [
    "dataloader, features_dict = initialize_data(\n",
    "    \"configs/data/features/features_credits_aggregated_v2.yaml\",\n",
    "    \"./data/credits-history/serialized/serialized_first_part_v2\",\n",
    "    \"./data/credits-history/indexes/ser_full_0_indexes/train_indexes.pickle\",\n",
    "    \"./data/credits-history/targets/targets_dict.pickle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelBatch(numerical=tensor([[[ 1.1200,  0.5315,  0.5068,  0.8620,  7.2181,  0.2000],\n",
       "         [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
       "         [ 2.8800,  2.2093,  0.8030, -0.5960,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.0400,  1.1128,  0.8969,  0.4422,  7.2181,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2800,  1.3662,  0.9791,  0.2032,  7.2181,  0.0000],\n",
       "         [ 0.1200,  0.0587,  0.0586,  0.9983,  7.2181,  0.0000],\n",
       "         [ 2.8800,  2.2093,  0.8030, -0.5960,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
       "         [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.6800,  0.8012,  0.7182,  0.6959,  7.2181,  0.0000],\n",
       "         [ 2.0400,  1.1128,  0.8969,  0.4422,  7.2181,  0.0000],\n",
       "         [ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
       "         [ 2.0400,  1.1128,  0.8969,  0.4422,  7.2181,  0.0000],\n",
       "         [ 0.9600,  0.3633,  0.3554,  0.9347,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]), categorical=tensor([[[ 2,  3,  2,  ...,  4,  9,  0],\n",
       "         [ 7,  3,  4,  ...,  4,  1,  0],\n",
       "         [19, 10,  4,  ...,  4,  0,  4],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 9,  8,  3,  ...,  4,  7,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 0, 19,  2,  ...,  4,  1,  0],\n",
       "         [18, 16,  2,  ...,  1,  0,  8],\n",
       "         [ 4,  1,  2,  ...,  4,  6,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7, 17,  4,  ...,  4,  6,  0],\n",
       "         [19, 18,  2,  ...,  4,  3,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 1, 16,  4,  ...,  4,  0,  4],\n",
       "         [ 9, 13,  6,  ...,  4,  0,  3],\n",
       "         [ 9, 14,  3,  ...,  4,  7,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 0,  3,  4,  ...,  4,  1,  0],\n",
       "         [11, 11,  2,  ...,  4,  0,  2],\n",
       "         [11,  9,  2,  ...,  4,  5,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]]]), targets=tensor([[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]]), sample_indexes=['102314', '229903', '90435', '61245', '174052', '93740', '94686', '101106', '66413', '174905', '231140', '189231', '92473', '5712', '79795', '124067', '64965', '240713', '190651', '97511', '181136', '220632', '85187', '200688', '178421', '70124', '195405', '249807', '249463', '100840', '86663', '225669'], lengths=tensor([ 4,  1, 13, 12, 18, 23, 14,  3,  3,  2,  4,  7,  5, 14,  8,  3,  6, 14,\n",
       "        12,  3,  2, 10,  1,  9,  7, 24,  9,  3,  6,  2,  4,  4]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sample check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample():\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    x = ModelInput(\n",
    "        numerical=batch.numerical,\n",
    "        categorical=batch.categorical,\n",
    "        lengths=batch.lengths\n",
    "    )\n",
    "\n",
    "    labels = batch.targets\n",
    "\n",
    "    return x, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(sample[0].numerical.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1600,  1.9200,  1.5600,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0800,  1.0005,  0.7129,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0800,  0.8417,  0.6540,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9968,  0.5399,  0.7565,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  7.2181,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1200,  2.2800,  2.2800,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0587,  1.3662,  1.3662,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0586,  0.9791,  0.9791,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9983,  0.2032,  0.2032,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  7.2181,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2800,  1.7200,  0.1600,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.3662,  0.8417,  0.0800,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9791,  0.7458,  0.0800,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2032,  0.6662,  0.9968,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  5.8848,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.2000,  0.2000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1200,  1.8000,  0.2400,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0587,  0.8969,  0.0975,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0586,  0.7814,  0.0973,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9983,  0.6241,  0.9953,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  7.2181,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2500,  0.0000,  0.2000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.5600,  3.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7868,  2.4223,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7081,  0.6588,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7061, -0.7523,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2500,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.4000,  2.6000,  1.5600,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.5090,  1.8002,  0.8672,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9981,  0.9738,  0.7625,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0618, -0.2274,  0.6470,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  7.2181,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.2500,  0.2500,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(rearrange(sample[0].numerical, \"N L H -> N H L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model layers check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            categorical_features: dict,\n",
    "            embedding_dim: int = 32,\n",
    "            div_emb_dim: int = 4\n",
    "        ) -> None:\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.embeddings = nn.ModuleList()\n",
    "\n",
    "        for num_embs in self.categorical_features.values():\n",
    "            embedding = nn.Embedding(\n",
    "                num_embeddings=num_embs, \n",
    "                embedding_dim=embedding_dim // div_emb_dim\n",
    "            )\n",
    "\n",
    "            nn.init.xavier_normal_(embedding.weight, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "            self.embeddings.append(embedding)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        x = torch.concatenate(\n",
    "            [embedding(x[..., idx]) for idx, embedding in enumerate(self.embeddings)], dim=-1\n",
    "        ) # size = (batch_size, len(cat_features), embedding_dim)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            numerical_features: list,\n",
    "            categorical_features: dict,\n",
    "            embedding_dim: int = 16,\n",
    "            dropout_inputs: float = 0.5,\n",
    "            non_linear: bool = False,\n",
    "            num_batch_norm: bool = True,\n",
    "            div_emb_dim: int = 4\n",
    "        ) -> None:\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_inputs)\n",
    "\n",
    "        self.numerical_features = numerical_features\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.embeddings = EmbeddingLayer(\n",
    "            categorical_features=categorical_features,\n",
    "            embedding_dim=embedding_dim,\n",
    "            div_emb_dim=div_emb_dim\n",
    "        )\n",
    "\n",
    "        if non_linear:\n",
    "            self.out_linear_block = nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    (embedding_dim // div_emb_dim) * len(self.categorical_features)  + len(self.numerical_features), \n",
    "                    embedding_dim\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Linear(embedding_dim, embedding_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.out_linear_block = nn.Linear(\n",
    "                (embedding_dim // div_emb_dim) * len(self.categorical_features) + len(self.numerical_features), \n",
    "                embedding_dim\n",
    "            )\n",
    "\n",
    "        if num_batch_norm:\n",
    "            self.num_bn = nn.BatchNorm1d(len(self.numerical_features))\n",
    "        else: \n",
    "            self.num_bn = None\n",
    "\n",
    "    def forward(self, inputs: ModelInput) -> SingleForwardState:\n",
    "\n",
    "        embeddings = self.embeddings(inputs.categorical)\n",
    "        \n",
    "        if self.num_bn is None:\n",
    "            x_num = inputs.numerical\n",
    "        else:\n",
    "            x_num = rearrange(inputs.numerical, \"N L H -> N H L\")\n",
    "\n",
    "            x_num = self.num_bn(x_num)\n",
    "\n",
    "            x_num = rearrange(x_num, \"N H L -> N L H\")\n",
    "            \n",
    "        x = torch.concatenate((x_num, embeddings), dim=-1)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_linear_block(x)\n",
    "\n",
    "        return SingleForwardState(\n",
    "            sequences=x, \n",
    "            lengths=inputs.lengths\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttention1d(nn.Module):\n",
    "    def __init__(self, features_dim: int):\n",
    "        super(SimpleAttention1d, self).__init__()\n",
    "\n",
    "        self.features_dim = features_dim\n",
    "\n",
    "        self.linear = nn.Linear(self.features_dim, self.features_dim)\n",
    "        self.bn_layer = nn.BatchNorm1d(self.features_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x: SingleForwardState) -> SingleForwardState:\n",
    "        att_x = self.linear(x.sequences)\n",
    "\n",
    "        att_x = rearrange(att_x, \"N L H -> N H L\")\n",
    "\n",
    "        att_x = self.softmax(self.bn_layer(att_x))\n",
    "\n",
    "        att_x = rearrange(att_x, \"N H L -> N L H\")\n",
    "        \n",
    "        att_sequences = x.sequences * att_x\n",
    "\n",
    "        return SingleForwardState(\n",
    "            sequences=att_sequences,\n",
    "            lengths=x.lengths\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUSeqToSeq(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_size: int, \n",
    "            num_layers_gru: int = 1,\n",
    "            bidirectional: bool = False,\n",
    "            dropout_gru: float = 0.0\n",
    "    ) -> None:\n",
    "        super(GRUSeqToSeq, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=num_layers_gru,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_gru\n",
    "        )\n",
    "\n",
    "    def forward(self, x: SingleForwardState) -> SingleForwardState:\n",
    "\n",
    "        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            input=x.sequences, \n",
    "            lengths=x.lengths, \n",
    "            batch_first=True, \n",
    "            enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        state, _ = self.gru(packed_sequences)\n",
    "\n",
    "        padded_state, _ = torch.nn.utils.rnn.pad_packed_sequence(state, batch_first=True)\n",
    "\n",
    "        # unpacked_sequences = torch.nn.utils.rnn.unpack_sequence(packed_sequences=packed_sequences)\n",
    "\n",
    "        return SingleForwardState(\n",
    "            sequences=padded_state,\n",
    "            lengths=x.lengths\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc_ = EncoderLayer(\n",
    "    numerical_features=features_dict[\"numerical\"],\n",
    "    categorical_features=features_dict[\"categorical\"],\n",
    "    embedding_dim=32,\n",
    "    dropout_inputs=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc = x_enc_(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleForwardState(sequences=tensor([[[ 0.5259, -0.2437, -0.5757,  ..., -0.5438,  0.3662, -0.4735],\n",
       "         [ 0.5180, -0.1474, -0.3920,  ..., -0.4886, -0.3882,  0.2314],\n",
       "         [ 0.1812, -0.4041, -0.5693,  ..., -0.6219, -0.0128, -0.0935],\n",
       "         ...,\n",
       "         [-0.3381, -0.0586, -0.3365,  ..., -0.2523,  0.3794, -0.1328],\n",
       "         [-0.4922, -0.0100, -0.2548,  ..., -0.3652,  0.4200, -0.1312],\n",
       "         [-0.3738, -0.1144, -0.1217,  ..., -0.2849,  0.1392, -0.2825]],\n",
       "\n",
       "        [[ 0.1971, -0.5017, -0.4344,  ..., -0.6294, -0.2103,  0.4232],\n",
       "         [ 0.5734, -0.4943, -0.8932,  ..., -0.7433, -0.1422, -0.4528],\n",
       "         [ 0.2724, -0.7024, -0.6399,  ..., -0.4498,  0.1105,  0.0734],\n",
       "         ...,\n",
       "         [-0.3234, -0.1822, -0.2758,  ..., -0.3236,  0.2283, -0.2851],\n",
       "         [-0.3222, -0.0063, -0.3347,  ..., -0.0862,  0.3613, -0.0938],\n",
       "         [-0.3000,  0.1334, -0.2906,  ..., -0.0770,  0.2851, -0.1773]],\n",
       "\n",
       "        [[ 0.1207, -0.1098, -0.5983,  ..., -1.0455, -0.3807, -0.4127],\n",
       "         [ 0.4853,  0.1775, -0.3977,  ..., -0.4785,  0.2585, -0.3834],\n",
       "         [ 0.3212, -0.3502, -0.5423,  ..., -0.6051,  0.0504, -0.0818],\n",
       "         ...,\n",
       "         [-0.3795, -0.0449, -0.4691,  ..., -0.1301,  0.4361, -0.2756],\n",
       "         [-0.2509, -0.0896, -0.1795,  ..., -0.1412,  0.3039,  0.0976],\n",
       "         [-0.3949, -0.2134, -0.3792,  ..., -0.3143,  0.2255, -0.1708]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1643, -0.3610, -0.3426,  ..., -0.5224,  0.1794, -0.2514],\n",
       "         [-0.4651, -0.1198, -0.2978,  ..., -0.2256,  0.3342, -0.2031],\n",
       "         [-0.3712, -0.1111, -0.3837,  ..., -0.3340,  0.2231, -0.2345],\n",
       "         ...,\n",
       "         [-0.3268, -0.1051, -0.1023,  ..., -0.2423,  0.0880, -0.0106],\n",
       "         [-0.2328, -0.0227, -0.3238,  ..., -0.0995,  0.2162,  0.0421],\n",
       "         [-0.3927, -0.2484, -0.4117,  ..., -0.2549,  0.3376, -0.1726]],\n",
       "\n",
       "        [[ 0.6344, -0.0037, -0.3405,  ..., -0.6520,  0.0292, -0.2394],\n",
       "         [ 0.2292, -0.1871, -0.4776,  ..., -0.5601,  0.0281,  0.0023],\n",
       "         [ 0.2988, -0.3963, -0.8247,  ..., -1.1370,  0.1102, -0.2710],\n",
       "         ...,\n",
       "         [-0.3357, -0.1381, -0.3300,  ..., -0.3154,  0.3913, -0.2220],\n",
       "         [-0.3136, -0.1391, -0.5245,  ..., -0.0331,  0.4100, -0.1804],\n",
       "         [-0.4071, -0.1095, -0.1051,  ..., -0.3765,  0.2690, -0.1051]],\n",
       "\n",
       "        [[ 0.1734, -0.0800, -0.5432,  ..., -0.5832,  0.2508, -0.1976],\n",
       "         [ 0.1615,  0.1376, -0.3188,  ..., -0.7299,  0.1536, -0.3877],\n",
       "         [-0.3673, -0.0725, -0.1710,  ..., -0.2533,  0.1885,  0.1734],\n",
       "         ...,\n",
       "         [-0.4776, -0.0689, -0.1665,  ..., -0.2780,  0.4989,  0.0289],\n",
       "         [-0.3562, -0.0979, -0.2980,  ..., -0.2993,  0.3449, -0.2086],\n",
       "         [-0.2287,  0.0714, -0.2646,  ..., -0.1254,  0.2648, -0.0790]]],\n",
       "       grad_fn=<ViewBackward0>), lengths=tensor([14,  4, 10,  3, 10,  9,  6,  1,  4,  2,  6, 10, 15, 17,  7, 10,  7,  1,\n",
       "        20, 15,  4,  3,  1, 15, 15,  6, 24,  4, 17,  1, 19,  2]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_enc.sequences.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9276112190>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(12, 10))\n",
    "\n",
    "ax = figure.add_subplot(2, 2, 1)\n",
    "ax.imshow(sample[0].categorical[0])\n",
    "\n",
    "ax = figure.add_subplot(2, 1, 1)\n",
    "ax.imshow(x_enc.sequences[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att = SimpleAttention1d(features_dim=32)(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_att.sequences.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f92738368d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(6, 6))\n",
    "\n",
    "ax = figure.add_subplot()\n",
    "ax.imshow(x_att.sequences[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gru_ = GRUSeqToSeq(\n",
    "    hidden_size=32,\n",
    "    num_layers_gru=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gru = x_gru_(x_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 24, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_gru.sequences.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f92716ca5d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(6, 6))\n",
    "\n",
    "ax = figure.add_subplot()\n",
    "ax.imshow(x_gru.sequences[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.pooling.agg_pooling import ConvPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pooled_ = ConvPooling(pooling_type=\"avg\", dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvPooling(\n",
       "  (pooling_layer): AvgPooling()\n",
       "  (agg_layer): Identity()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_pooled_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pooled = x_pooled_(x_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_pooled.representations.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9271782750>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_pooled.representations[0].detach().unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.collate import ModelOutput\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_TYPE_MAPPING = {\n",
    "    \"tanh\": nn.Tanh,\n",
    "    \"gelu\": nn.GELU,\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"none\": nn.Identity\n",
    "}\n",
    "\n",
    "def init_linear_block_weights(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.zeros_(layer.bias)\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            in_features: int, \n",
    "            out_features: int = 1, \n",
    "            num_layers: int = 3, \n",
    "            dropout_rate: float = 0.0, \n",
    "            activation_type: str = \"tanh\",\n",
    "            use_batch_norm: bool = False,\n",
    "            bias: bool = True\n",
    "        ) -> None:\n",
    "        super(LinearBlock, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        if activation_type is None:\n",
    "            self.act = ACTIVATION_TYPE_MAPPING[\"tanh\"]\n",
    "        elif activation_type in ACTIVATION_TYPE_MAPPING.keys():\n",
    "            self.act = ACTIVATION_TYPE_MAPPING[activation_type]\n",
    "        else: \n",
    "            NotImplementedError(f\"activation_type must be in <{list(ACTIVATION_TYPE_MAPPING.keys())}>\")\n",
    "\n",
    "        if use_batch_norm:\n",
    "            self.layer_norm = nn.BatchNorm1d\n",
    "        else:\n",
    "            self.layer_norm = nn.LayerNorm\n",
    "\n",
    "        self.linear_block = nn.Sequential(\n",
    "            *[\n",
    "                nn.Sequential(\n",
    "                    *[\n",
    "                        nn.Linear(in_features // (2 ** i), in_features // (2 ** (i + 1)), bias),\n",
    "                        self.layer_norm(in_features // (2 ** (i + 1))),\n",
    "                        self.act()\n",
    "                    ]\n",
    "                ) for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.out_block = nn.Linear(\n",
    "            in_features=in_features // (2 ** num_layers), out_features=out_features\n",
    "        )\n",
    "\n",
    "        self.cls_layers = nn.Sequential(\n",
    "            self.dropout,\n",
    "            self.linear_block,\n",
    "            self.out_block,\n",
    "            self.act()\n",
    "        )\n",
    "\n",
    "        # weights init\n",
    "        self.cls_layers.apply(init_linear_block_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x: ModelOutput) -> ModelOutput:\n",
    "        logits = self.cls_layers(x.representations)\n",
    "\n",
    "        return ModelOutput(\n",
    "            representations=x.representations,\n",
    "            logits=logits\n",
    "        )\n",
    "\n",
    "\n",
    "class MultiTaskLinearBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            heads: List[LinearBlock]\n",
    "    ) -> None: \n",
    "        super(MultiTaskLinearBlock, self).__init__()\n",
    "\n",
    "        self.heads = nn.ModuleList(heads)\n",
    "\n",
    "    def forward(self, x: ModelOutput) -> ModelOutput:\n",
    "        multi_state = [\n",
    "            head(x).logits for head in self.heads\n",
    "        ]\n",
    "\n",
    "        logits = torch.concat(multi_state, dim=1) # size(batch_size, num_outputs)\n",
    "        \n",
    "        return ModelOutput(\n",
    "            representations=x.representations,\n",
    "            logits=logits\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = MultiTaskLinearBlock(\n",
    "    heads=[\n",
    "        LinearBlock(32, 1, 2)\n",
    "    ]\n",
    ")(x_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelOutput(representations=tensor([[-0.0807, -0.0925,  0.0185,  ...,  0.0862,  0.0276, -0.0489],\n",
       "        [-0.0164, -0.0240,  0.0047,  ...,  0.0191,  0.0072, -0.0139],\n",
       "        [-0.0550, -0.0686,  0.0153,  ...,  0.0614,  0.0193, -0.0378],\n",
       "        ...,\n",
       "        [-0.0029, -0.0036,  0.0004,  ...,  0.0021,  0.0021, -0.0017],\n",
       "        [-0.1101, -0.1254,  0.0267,  ...,  0.1202,  0.0347, -0.0692],\n",
       "        [-0.0092, -0.0124, -0.0006,  ...,  0.0077,  0.0030, -0.0051]],\n",
       "       grad_fn=<SqueezeBackward1>), logits=tensor([[-0.3835],\n",
       "        [-0.4595],\n",
       "        [-0.3846],\n",
       "        [-0.5128],\n",
       "        [-0.4077],\n",
       "        [-0.4268],\n",
       "        [-0.4213],\n",
       "        [-0.6295],\n",
       "        [-0.4995],\n",
       "        [-0.0691],\n",
       "        [-0.4164],\n",
       "        [-0.4121],\n",
       "        [-0.3576],\n",
       "        [-0.3559],\n",
       "        [-0.3748],\n",
       "        [-0.3683],\n",
       "        [-0.3324],\n",
       "        [-0.3280],\n",
       "        [-0.3166],\n",
       "        [-0.3467],\n",
       "        [-0.4153],\n",
       "        [-0.5702],\n",
       "        [-0.4393],\n",
       "        [-0.3760],\n",
       "        [-0.3955],\n",
       "        [-0.4136],\n",
       "        [-0.3758],\n",
       "        [-0.4318],\n",
       "        [-0.3609],\n",
       "        [-0.2603],\n",
       "        [-0.3825],\n",
       "        [-0.5049]], grad_fn=<CatBackward0>))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metrics import GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "            self, \n",
    "            model: nn.Module, \n",
    "            optimizer: torch.optim.Optimizer, \n",
    "            criterion: nn.BCEWithLogitsLoss,\n",
    "            train_dataloader: torch.utils.data.DataLoader, \n",
    "            scheduler: torch.optim.lr_scheduler.LRScheduler = None\n",
    "        ) -> None:\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.task_names = [\"tanh_output\"]\n",
    "        self.task_weights = torch.tensor([1.0])\n",
    "\n",
    "        self.train_data = train_dataloader\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "        self.gini = GINI()\n",
    "\n",
    "        self.train_results = list()\n",
    "\n",
    "    def multioutput_loss(self, logits: ModelOutput, targets: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # logits size is (batch_size, num_outputs)\n",
    "        # targets size is (batch_size, 1)\n",
    "\n",
    "        targets = targets.expand(size=(-1, len(self.task_names))) # to size like logits\n",
    "\n",
    "        weighted_loss = self.task_weights * self.criterion(logits, targets)\n",
    "        \n",
    "        # (self.task_weights * self.criterion(logits, targets)).sum() / len(self.task_names)\n",
    "        loss = weighted_loss.sum() / (len(weighted_loss) * len(self.task_names))\n",
    "        branched_loss = (weighted_loss.sum(dim=0) / len(weighted_loss)).detach()\n",
    "\n",
    "        return loss, branched_loss\n",
    "\n",
    "    def fit(self, epochs: int = 3, show_step: int = 100):\n",
    "        n_total_steps = len(self.train_data)\n",
    "\n",
    "        loss_step = 0\n",
    "        gini_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            self.epoch = epoch\n",
    "            \n",
    "            print('Epoch %s/%s' % (epoch + 1, epochs))\n",
    "\n",
    "            for step, batch in enumerate(self.train_data):\n",
    "                self.optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                x = ModelInput(\n",
    "                    numerical=batch.numerical,\n",
    "                    categorical=batch.categorical,\n",
    "                    lengths=batch.lengths\n",
    "                )\n",
    "\n",
    "                labels = batch.targets\n",
    "\n",
    "                outputs = self.model(x)\n",
    "        \n",
    "                loss, _ = self.multioutput_loss(\n",
    "                    logits=outputs.logits,\n",
    "                    targets=labels\n",
    "                )\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                loss_step += loss.item()\n",
    "                gini_step += self.gini(outputs.logits[:, 0], labels.squeeze())\n",
    "\n",
    "                self.train_results.append(\n",
    "                    [\n",
    "                        self.epoch * n_total_steps + step, \n",
    "                        loss.item()\n",
    "\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                if (step + 1) % show_step == 0:\n",
    "                    print(\n",
    "                        f\"Step [{step+1}/{n_total_steps}] | Time: {time.time() - epoch_start_time:.2f}s | Loss: {loss_step / show_step:.4f} | GINI: {gini_step / show_step:.1f}\"\n",
    "                    )\n",
    "                    gini_step = 0\n",
    "                    loss_step = 0\n",
    "\n",
    "        self.train_writer = pd.DataFrame(self.train_results, columns=[\"step\", \"loss\"])\n",
    "\n",
    "        print('\\nDone.')\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'''[INFO]\\n{\"-\" * 60}\\ndata: {self.data} \\n{\"-\" * 60} \\nmodel: {self.model} \\n{\"-\" * 60} \\noptimizer: {self.optimizer} \\n{\"-\" * 60}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    EncoderLayer(\n",
    "        numerical_features=features_dict[\"numerical\"],\n",
    "        categorical_features=features_dict[\"categorical\"],\n",
    "        embedding_dim=32,\n",
    "        dropout_inputs=0.1\n",
    "    ),\n",
    "    SimpleAttention1d(\n",
    "        features_dim=32\n",
    "    ),\n",
    "    GRUSeqToSeq(\n",
    "        hidden_size=32,\n",
    "        num_layers_gru=1\n",
    "    ),\n",
    "    ConvPooling(\n",
    "        pooling_type=\"avg\", dim=1\n",
    "    ),\n",
    "    MultiTaskLinearBlock(\n",
    "        heads=[\n",
    "            LinearBlock(32, 1, 2)\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.99)\n",
    "\n",
    "train_model = Trainer(\n",
    "    model=model, \n",
    "    criterion=nn.BCEWithLogitsLoss(\n",
    "        reduction=\"none\"\n",
    "    ),\n",
    "    train_dataloader=dataloader, \n",
    "    optimizer=opt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Step [30/313] | Time: 13.58s | Loss: 0.6872 | GINI: 22.2\n",
      "Step [60/313] | Time: 27.75s | Loss: 1.3371 | GINI: 40.4\n",
      "Step [90/313] | Time: 41.26s | Loss: 1.9622 | GINI: 47.0\n",
      "Step [120/313] | Time: 55.03s | Loss: 2.5918 | GINI: 42.0\n",
      "Step [150/313] | Time: 68.26s | Loss: 3.2062 | GINI: 45.6\n",
      "Step [180/313] | Time: 81.52s | Loss: 3.8370 | GINI: 40.9\n",
      "Step [210/313] | Time: 95.14s | Loss: 4.4491 | GINI: 44.3\n",
      "Step [240/313] | Time: 108.90s | Loss: 5.0678 | GINI: 42.9\n",
      "Step [270/313] | Time: 122.34s | Loss: 5.6726 | GINI: 42.5\n",
      "Step [300/313] | Time: 135.64s | Loss: 6.2600 | GINI: 42.1\n",
      "Epoch 2/3\n",
      "Step [30/313] | Time: 13.77s | Loss: 7.1534 | GINI: 66.2\n",
      "Step [60/313] | Time: 27.22s | Loss: 7.7777 | GINI: 46.2\n",
      "Step [90/313] | Time: 40.87s | Loss: 8.3910 | GINI: 45.8\n",
      "Step [120/313] | Time: 54.88s | Loss: 9.0316 | GINI: 44.5\n",
      "Step [150/313] | Time: 68.88s | Loss: 9.6643 | GINI: 44.8\n",
      "Step [180/313] | Time: 82.71s | Loss: 10.2649 | GINI: 52.5\n",
      "Step [210/313] | Time: 96.83s | Loss: 10.8753 | GINI: 45.5\n",
      "Step [240/313] | Time: 111.17s | Loss: 11.4702 | GINI: 48.1\n",
      "Step [270/313] | Time: 125.26s | Loss: 12.0696 | GINI: 46.7\n",
      "Step [300/313] | Time: 139.81s | Loss: 12.6425 | GINI: 49.1\n",
      "Epoch 3/3\n",
      "Step [30/313] | Time: 13.95s | Loss: 13.5054 | GINI: 71.3\n",
      "Step [60/313] | Time: 28.04s | Loss: 14.1128 | GINI: 50.4\n",
      "Step [90/313] | Time: 42.35s | Loss: 14.7222 | GINI: 48.8\n",
      "Step [120/313] | Time: 56.55s | Loss: 15.3328 | GINI: 46.9\n",
      "Step [150/313] | Time: 70.87s | Loss: 15.9247 | GINI: 50.3\n",
      "Step [180/313] | Time: 85.06s | Loss: 16.5096 | GINI: 54.2\n",
      "Step [210/313] | Time: 99.01s | Loss: 17.1139 | GINI: 49.0\n",
      "Step [240/313] | Time: 113.30s | Loss: 17.6970 | GINI: 52.8\n",
      "Step [270/313] | Time: 127.50s | Loss: 18.2655 | GINI: 53.2\n",
      "Step [300/313] | Time: 141.48s | Loss: 18.8300 | GINI: 50.3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "3 columns passed, passed data had 2 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 3 columns passed, passed data had 2 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[162], line 92\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, epochs, show_step)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     88\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_total_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] | Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mepoch_start_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms | Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_step\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mshow_step\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | GINI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgini_step\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mshow_step\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m             )\n\u001b[1;32m     90\u001b[0m             gini_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_writer \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDone.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/pandas/core/frame.py:840\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    839\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 840\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    849\u001b[0m         arrays,\n\u001b[1;32m    850\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    854\u001b[0m     )\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 3 columns passed, passed data had 2 columns"
     ]
    }
   ],
   "source": [
    "train_model.fit(epochs=3, show_step=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(test_sample).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(44.4487)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(GINI()(preds, test_sample.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - 40.82 ~ lr 1e-4\n",
    "# 2 - 44.80 ~ lr 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_preds = torch.concatenate((torch.sigmoid(preds), test_sample.targets), dim=1).sort(dim=0).values.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(test_sample.targets, torch.sigmoid(preds).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr, label=np.trapz(fpr, tpr))\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.embedding.encoder_layer import EncoderLayer\n",
    "from src.models.components.seq_to_seq.gru_seq_to_seq import GRUSeqToSeq\n",
    "from src.models.components.pooling.agg_pooling import ConvPooling\n",
    "from src.models.components.linear_blocks.linear_conv_blocks import MultiTaskLinearBlock, LinearBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import LightningModule\n",
    "from src.utils.metrics import GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.ch_lit_module import CHLitModule\n",
    "from IPython.display import display as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, ckpt_path: str):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = CHLitModule.load_from_checkpoint(ckpt_path)\n",
    "        self.net.eval()\n",
    "        self.net.freeze()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danil/projects/torch_template/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n"
     ]
    }
   ],
   "source": [
    "trained_model = PretrainedModel(\"logs/train/runs/2024-05-10_21-40-59/checkpoints/epoch_009.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'net.layers.0.embeddings.embeddings.0.weight': Parameter containing:\n",
       " tensor([[ 0.1163, -0.1310, -0.0592,  0.2793,  0.3741, -0.6908, -0.5971,  0.2201],\n",
       "         [ 0.0158,  0.4290, -0.4030,  0.0218,  0.0435, -0.1547, -0.0477,  0.1665],\n",
       "         [-0.0617,  0.2233, -0.1663,  0.4225, -0.3835,  0.7323,  0.3849,  0.2081],\n",
       "         [ 0.5352,  0.5145,  0.2374, -0.2541,  0.0298,  0.6522,  0.1205,  0.1835],\n",
       "         [ 0.1011, -0.4466, -0.3656, -0.6524, -0.8061,  0.1351,  0.7707, -0.0579],\n",
       "         [ 0.0419,  0.1185,  0.3030,  0.0406, -0.0423,  0.7063,  0.4330,  0.3869],\n",
       "         [-0.0862, -0.5944,  0.1390,  0.1104,  0.3812, -0.3613, -0.2918, -0.1140],\n",
       "         [-0.5155,  0.3444, -0.0941,  0.0787,  0.1592,  0.0584, -0.1778, -0.1210],\n",
       "         [ 0.7178, -0.4313,  0.1467, -0.0058, -0.5106, -0.3782, -0.6809, -0.6599],\n",
       "         [-0.0430,  0.7047,  0.2371, -0.0702, -0.3061,  0.2328,  0.4510, -0.3048],\n",
       "         [ 0.0031, -1.0576,  0.3733,  0.0736, -0.4612, -0.0251, -0.3969, -0.7177],\n",
       "         [-0.0506,  0.3903, -0.0733,  0.1037,  0.4574, -0.1006, -0.0785,  0.0768],\n",
       "         [-0.2653,  0.4140, -0.5615, -0.3166,  0.6889,  0.0751,  0.6697,  0.3573],\n",
       "         [-0.6426,  0.3681,  0.1530, -0.1063, -1.1145,  0.1245, -0.1078,  0.5884],\n",
       "         [ 0.8575, -0.4936, -0.3995,  0.3872, -0.1574, -0.4889,  0.0648, -0.0255],\n",
       "         [ 0.6924,  0.3530,  0.5028,  0.3254, -0.0732, -0.0140, -0.3945,  0.2561],\n",
       "         [ 0.1473, -0.6012,  0.0438,  0.2867,  0.1340,  0.1892, -0.5027,  0.0419],\n",
       "         [ 0.3430, -0.6733,  0.2177,  0.1009, -0.0754, -0.3898,  0.6684, -0.4465],\n",
       "         [-0.0849,  0.6269, -0.3552, -0.5311, -0.4286, -0.4197, -0.1531,  0.2260],\n",
       "         [-0.4743,  0.1523,  0.1388,  0.5476,  0.6124,  0.0395,  0.4427, -1.0215]]),\n",
       " 'net.layers.0.embeddings.embeddings.1.weight': Parameter containing:\n",
       " tensor([[ 0.2137,  0.0796, -0.4815,  0.1572,  0.2346, -0.6818,  0.0582,  0.0404],\n",
       "         [ 0.4608,  0.1463,  0.0688, -0.2376, -0.4971,  0.2539,  0.9804,  0.0255],\n",
       "         [ 0.3521,  0.3794, -0.1438, -0.6676,  0.2065, -0.3976, -0.3489, -0.4404],\n",
       "         [-0.2654, -0.4724, -0.6047,  0.2302, -0.6970, -0.0709,  0.3275,  0.4361],\n",
       "         [-0.7796,  0.3190, -0.2729,  0.1017,  0.2343, -0.1756,  0.0332,  0.3027],\n",
       "         [-0.0682, -0.0307,  0.6609,  0.8281,  0.6630, -0.2993,  0.1102,  0.7385],\n",
       "         [-0.2098,  0.1285,  0.0652, -0.2467, -0.6954,  0.3667, -0.1858, -0.0785],\n",
       "         [ 0.2409,  0.5445, -0.4894,  0.2290, -0.1473,  0.2833, -0.1067, -0.0734],\n",
       "         [-0.0301, -0.0046, -0.0951, -0.1433, -0.6790, -0.1922, -0.4510, -0.3100],\n",
       "         [-0.0441,  0.0442,  0.0286, -0.0518,  0.0062,  0.2718, -0.2137, -0.7409],\n",
       "         [ 0.0233, -0.8282,  0.2883, -0.1556, -0.2864, -0.2075, -0.4479, -0.1533],\n",
       "         [-0.0537,  0.0681, -0.3251,  0.2056,  0.5859, -0.6054, -0.3709, -0.4691],\n",
       "         [-0.1320, -0.4573, -0.3588, -0.3341, -0.1267,  0.1231,  0.4443,  0.5412],\n",
       "         [-0.1493,  0.0889, -1.0757, -0.1394, -0.6225, -0.1736,  0.5572,  0.6625],\n",
       "         [ 0.2286,  0.1072, -0.6088, -0.5604, -0.2644,  0.2230, -0.6730, -0.2534],\n",
       "         [-0.4566,  0.6257,  0.4736, -0.4560,  0.1046, -0.0380, -0.0801, -0.5122],\n",
       "         [-0.3900,  0.0458,  0.0788,  0.3594,  0.3411,  0.2647, -0.4624, -0.0282],\n",
       "         [ 0.5903,  0.0028,  0.3942, -0.6366, -0.0141, -0.3492, -0.5880,  0.4808],\n",
       "         [-0.9453, -0.2852, -0.3645,  0.6484,  0.1795, -0.3972,  0.6111,  0.1280],\n",
       "         [-0.5976,  0.3525, -0.1321, -0.5223, -0.3868, -0.6306, -0.2347,  0.4176]]),\n",
       " 'net.layers.0.embeddings.embeddings.2.weight': Parameter containing:\n",
       " tensor([[ 0.5204,  0.3193, -0.1787,  0.4264,  0.8492, -0.3405, -0.5695,  0.3320],\n",
       "         [ 0.0797, -0.1506, -0.5272, -0.3174, -0.1911,  0.0462,  0.0923, -0.1694],\n",
       "         [ 0.0657,  0.1052, -0.1796, -0.1257,  0.2691,  0.4032,  0.4428,  0.1954],\n",
       "         [ 0.4906, -0.4036,  0.5303, -0.0847, -0.2888,  0.2431, -0.2162, -0.4461],\n",
       "         [ 0.0470,  0.0751, -0.4501,  0.3573, -0.4471,  0.1137,  0.2513, -0.7573],\n",
       "         [-0.1296,  0.5999,  0.7004, -0.0484,  0.3904, -0.6700,  0.2068, -0.1933],\n",
       "         [ 0.3390, -0.6046, -0.0569,  0.3071, -0.5129,  0.7309, -0.0062, -0.7495]]),\n",
       " 'net.layers.0.embeddings.embeddings.3.weight': Parameter containing:\n",
       " tensor([[-0.0709, -0.0278,  0.2469,  0.2165, -0.3904, -0.6240,  0.8214,  0.0807],\n",
       "         [-0.1927,  0.1941,  1.1182,  0.2462, -0.2822, -1.1888,  0.2600, -0.1246],\n",
       "         [ 0.5356,  0.1710, -0.0571, -1.1629, -0.5057, -0.0917,  0.6005,  0.2558],\n",
       "         [ 0.3673,  0.0973, -0.2034,  1.0051, -0.0282,  0.6308, -0.0102,  0.1583],\n",
       "         [ 0.1587,  0.1229, -0.3495,  0.2419,  0.1320,  0.7192,  0.3404, -0.0060],\n",
       "         [-0.6656,  0.3405,  0.1414, -0.4119,  0.3923,  0.2578,  0.0910,  0.6805]]),\n",
       " 'net.layers.0.embeddings.embeddings.4.weight': Parameter containing:\n",
       " tensor([[ 0.1143, -0.2432,  0.3283, -0.0270, -0.2272,  0.9917,  1.0030, -0.2740]]),\n",
       " 'net.layers.0.embeddings.embeddings.5.weight': Parameter containing:\n",
       " tensor([[-0.2758,  0.2895,  0.3122,  0.5903, -0.1646,  0.0733,  0.7708, -0.5369],\n",
       "         [ 0.7528, -0.4436, -0.0173,  0.9546, -0.6131, -0.1111,  0.1583, -0.3574],\n",
       "         [-0.3160,  0.2483, -1.2386, -0.7267, -0.1929, -0.0825,  1.1944,  0.1082],\n",
       "         [ 0.6704,  0.2425,  0.8025, -0.6947, -0.8737, -0.1919, -1.0646,  1.4462]]),\n",
       " 'net.layers.0.embeddings.embeddings.6.weight': Parameter containing:\n",
       " tensor([[-0.1729,  0.1312,  0.0660,  0.0054,  0.3522,  0.5720,  0.8629, -0.2477],\n",
       "         [-0.1447, -0.7310, -0.1625, -0.3141, -0.2959, -0.4973,  0.5291,  0.3617],\n",
       "         [-0.1620,  1.2796,  0.8938,  0.1319, -0.2771, -0.8231,  0.4444, -0.7832],\n",
       "         [ 0.0230,  0.0321, -0.3398, -0.0685, -0.0688,  0.1764, -0.2427,  0.0038],\n",
       "         [ 0.2931, -0.0646,  0.2284,  0.1569, -0.1394, -0.0844,  0.5682,  0.0444],\n",
       "         [ 1.1332,  0.5424, -0.4430, -0.6205, -0.1328, -0.4329,  0.4719,  0.0145],\n",
       "         [-0.6813, -0.4152, -0.4024, -0.7101, -1.6585,  0.5565, -0.9481, -0.5136],\n",
       "         [-0.4711,  0.7258,  0.6825, -1.1356,  0.5863, -0.0397, -0.2578,  0.3359],\n",
       "         [-0.1623, -0.0191,  0.0742, -0.0161,  0.6914,  0.1909, -0.3610,  0.5985],\n",
       "         [-0.8010,  0.3752, -0.1041, -0.5577, -0.6666,  0.0804,  0.3734,  0.2374],\n",
       "         [ 0.0288, -0.2346, -0.4682,  0.0904, -0.7053, -0.2677,  0.0928, -0.3858],\n",
       "         [ 0.2144,  0.5006,  0.5874,  0.1291,  0.7912, -0.5731,  0.2350,  1.2334],\n",
       "         [-0.1211,  0.0104, -0.1102, -0.1453, -0.1424,  0.1323, -0.0913, -0.1100],\n",
       "         [ 0.7391,  0.1495, -0.0738,  0.8705, -0.4991,  0.0480,  0.0804,  0.4971]]),\n",
       " 'net.layers.0.embeddings.embeddings.7.weight': Parameter containing:\n",
       " tensor([[-0.4064, -0.3578, -0.4739, -0.2655,  0.2506,  0.0691, -0.5268,  0.2718],\n",
       "         [-0.2149, -0.1238, -0.1189,  0.1224,  0.0228,  0.1698, -0.3614, -0.0894],\n",
       "         [-0.0462,  0.3183, -0.1349,  0.2424, -0.3440,  0.3597, -0.0628, -0.1137],\n",
       "         [-0.6764,  0.5593,  0.3628, -0.1109,  0.3377,  0.2322,  0.4334, -0.0730],\n",
       "         [-0.0047,  0.0396, -0.8726, -0.1214, -0.7901,  0.4645, -0.6689, -0.0390],\n",
       "         [-0.0205, -0.8000,  0.0595,  0.1857, -0.6768,  0.2442, -0.4817, -0.0492],\n",
       "         [-0.4202,  0.4579,  0.4010, -0.5920,  0.9702, -0.0868, -0.2417,  0.6253],\n",
       "         [-0.0465, -0.2470,  0.3194,  0.4148, -0.4413, -0.2829,  0.6951, -0.1547],\n",
       "         [-0.0035, -0.3853, -0.9853,  0.1863,  0.0224, -0.0350, -0.1563, -0.2523],\n",
       "         [ 0.4621, -0.6174,  0.2753,  0.5160, -0.0556, -0.6035,  0.3174, -0.6517],\n",
       "         [ 0.7764,  0.0510, -0.8036,  0.1542,  0.1345, -0.3532,  0.0979, -0.3258],\n",
       "         [ 0.4281, -0.0747, -0.2685, -0.6451,  0.6263,  0.4271, -0.0310,  0.1703],\n",
       "         [ 0.4094,  0.2129, -0.5517, -0.1092, -0.0372,  0.1221, -0.2409, -0.5684],\n",
       "         [ 0.1631, -0.5857,  0.6179, -0.2313, -0.4762,  0.9530, -0.8586, -0.5297],\n",
       "         [-0.5023,  1.1498,  0.2984,  0.0293,  0.3445, -0.5799,  0.3526,  0.3826],\n",
       "         [ 0.3194, -0.4426, -0.4775, -0.4338,  0.3200, -0.2596,  0.3981,  0.0617],\n",
       "         [ 0.7015, -0.3624, -0.2722,  0.1218,  0.0327, -0.3314, -0.4188, -0.8221],\n",
       "         [-0.1983,  0.0085,  0.2661, -0.3790,  0.3452, -0.2725,  0.0111,  0.2714],\n",
       "         [-0.8424,  0.1555, -0.1107, -0.0812,  0.4953,  0.0531, -0.3422,  0.1022],\n",
       "         [-0.0525, -0.1702, -0.5607,  0.5272,  0.0395, -0.3224,  0.0545, -0.4079]]),\n",
       " 'net.layers.0.embeddings.embeddings.8.weight': Parameter containing:\n",
       " tensor([[-0.3913, -0.3857,  0.4728, -0.3627,  0.1606, -0.1837, -0.1450,  0.2831],\n",
       "         [-0.1531, -0.0278, -0.2378,  0.0013, -0.1135, -0.0301, -0.0059, -0.2484],\n",
       "         [-0.0311,  0.1535,  0.1180,  0.0472,  0.0078, -0.1315, -0.0870,  0.1066],\n",
       "         [-0.2260, -0.7317,  0.0193,  0.3010,  0.0136,  0.0135,  0.1848,  0.0568],\n",
       "         [ 0.1535,  0.1743,  0.0431, -0.6089,  0.0214, -0.1912,  0.1170, -0.0168],\n",
       "         [-0.3352,  0.4934,  0.4652, -0.0697,  0.2161, -0.3753, -0.4645, -0.2057],\n",
       "         [-0.2485, -0.1142, -0.3285, -0.0463,  0.2491, -0.0231,  0.0360,  0.1880],\n",
       "         [-0.0218, -0.0257,  0.0280, -0.0579,  0.0989, -0.0582, -0.0425, -0.0271],\n",
       "         [ 0.3534,  0.3121, -0.1578,  0.1715, -0.0819,  0.0815,  0.3672, -0.2310],\n",
       "         [-0.4334, -0.0403, -0.1967,  0.1936, -0.1538,  0.1093, -0.3946,  0.6651],\n",
       "         [ 0.4810, -0.0074, -0.1555, -0.2412,  0.0427, -0.0179,  0.2836, -0.0409],\n",
       "         [ 0.1614,  0.3191, -0.1885,  0.0777, -0.0842,  0.2940,  0.0873, -0.1070],\n",
       "         [-0.0485, -0.0741,  0.0602, -0.0636,  0.0438, -0.0202, -0.0320,  0.0161],\n",
       "         [ 0.0665,  0.1178, -0.0174, -0.0269,  0.0274,  0.0010,  0.0191, -0.0657],\n",
       "         [ 0.2263,  0.1357,  0.1331, -0.0512,  0.5539, -0.0472,  0.2400, -0.0757],\n",
       "         [-0.6851, -0.3251,  0.6195, -0.1704,  0.0565,  0.3435,  0.3026,  0.1606],\n",
       "         [ 0.0680,  0.0273, -0.0632,  0.0449, -0.0551, -0.1260,  0.0319,  0.2259],\n",
       "         [ 0.8959,  0.9726,  0.0347, -0.0993, -0.1356,  0.2005,  0.5470, -0.1691],\n",
       "         [ 0.0293, -0.0238, -0.0279, -0.0928,  0.0105,  0.0641,  0.0033,  0.0311],\n",
       "         [ 0.0436,  0.0311,  0.0638, -0.0329, -0.1106,  0.0476,  0.0906, -0.0674]]),\n",
       " 'net.layers.0.embeddings.embeddings.9.weight': Parameter containing:\n",
       " tensor([[-1.5125e-01,  5.1482e-01, -4.1090e-02,  1.6070e-01,  3.6646e-02,\n",
       "           2.0095e-01,  2.1150e-01,  2.3867e-01],\n",
       "         [-1.7164e-01,  2.1826e-01, -2.4287e-02, -1.8623e-01,  1.5719e-01,\n",
       "          -8.6375e-02, -6.1010e-01,  1.2426e-01],\n",
       "         [-2.4295e-01,  1.9356e-01,  2.3656e-01, -1.6219e-02, -1.8983e-01,\n",
       "          -1.1542e-01,  1.3147e-01,  4.2100e-02],\n",
       "         [-3.7464e-01,  8.4760e-01, -5.3351e-01, -6.1485e-01,  6.5448e-01,\n",
       "           1.8440e-01, -2.9649e-02,  2.1460e-01],\n",
       "         [-2.7831e-01, -3.2149e-01, -1.1761e-01,  6.8099e-01, -3.4339e-01,\n",
       "           1.2283e-01,  1.2776e-01, -5.1128e-01],\n",
       "         [-2.5472e-01, -2.5153e-01,  9.9120e-02,  2.6997e-02,  3.0884e-01,\n",
       "           6.7812e-01,  1.2919e-02, -4.1699e-01],\n",
       "         [-2.5123e-02, -1.0458e-01, -1.2800e-01,  4.7768e-01,  5.8606e-04,\n",
       "          -1.1830e-02, -1.5696e-02,  2.3809e-01],\n",
       "         [-8.8628e-01, -6.5774e-02, -3.9695e-01, -4.2403e-01, -2.4129e-01,\n",
       "           6.6612e-01, -6.6144e-02, -6.1127e-01],\n",
       "         [-1.5654e-01,  4.1087e-01, -4.7767e-01,  5.4739e-02, -3.6980e-02,\n",
       "           4.9373e-01, -4.1805e-01,  2.1734e-01],\n",
       "         [-4.4371e-01, -4.0868e-02,  2.6198e-01, -6.8320e-01,  2.4515e-01,\n",
       "          -3.4269e-01, -6.4767e-01,  1.1913e-01],\n",
       "         [-1.2599e-01,  2.9516e-01, -1.0126e-01,  4.4207e-01,  3.9267e-01,\n",
       "          -3.0768e-01,  6.9743e-01, -3.9490e-01],\n",
       "         [ 5.2890e-01, -7.7805e-02, -1.2690e-02,  2.1215e-02, -2.0001e-01,\n",
       "           5.1494e-01, -1.2268e-02,  5.6738e-01],\n",
       "         [-1.8241e-02,  1.4332e-01,  2.7973e-01,  8.1386e-02, -3.8391e-01,\n",
       "           1.2983e-01,  1.1966e-01, -4.7556e-02],\n",
       "         [ 1.1690e-01,  3.4890e-01, -2.8918e-01, -2.5392e-02, -5.7157e-02,\n",
       "           2.0163e-01, -5.3551e-01,  1.2677e-01],\n",
       "         [-2.2886e-02,  1.4197e-01, -9.9738e-02, -2.0464e-01, -1.9344e-01,\n",
       "          -2.0027e-01,  4.5213e-01,  6.3231e-02],\n",
       "         [-1.9436e-01,  4.8683e-01, -9.3151e-03, -1.6529e-01,  4.6130e-01,\n",
       "          -1.5471e-01,  3.5071e-03, -8.2349e-02],\n",
       "         [-7.6394e-01,  5.4020e-01, -1.0545e-01, -1.5743e-01,  9.1989e-01,\n",
       "           5.5937e-01, -3.1599e-01, -3.4751e-01],\n",
       "         [ 2.9148e-01, -7.3090e-02,  3.5073e-01,  3.9338e-01, -3.2920e-01,\n",
       "          -8.3241e-01,  5.3630e-02, -6.5643e-02],\n",
       "         [ 3.4573e-01,  3.8897e-01,  1.8808e-01,  6.9237e-02, -4.4186e-01,\n",
       "          -1.2324e-01, -1.4576e-01, -1.4929e-01],\n",
       "         [-1.1786e-01,  4.5282e-01,  4.9108e-01,  1.1046e-02,  2.5465e-01,\n",
       "          -4.8412e-01,  8.3229e-02,  7.0730e-02]]),\n",
       " 'net.layers.0.embeddings.embeddings.10.weight': Parameter containing:\n",
       " tensor([[-0.3144,  0.1349,  0.6300, -0.1467, -0.1245,  0.8861,  0.4833, -0.3786],\n",
       "         [ 0.0989, -0.3044, -0.5059,  0.4895,  0.1625,  0.3431,  0.7931,  1.0214]]),\n",
       " 'net.layers.0.embeddings.embeddings.11.weight': Parameter containing:\n",
       " tensor([[-0.3542, -0.8103,  0.1045,  1.4894,  0.1746, -0.7285,  0.2910,  0.9420],\n",
       "         [ 0.1600, -0.4830, -0.3897,  0.0624,  0.4449,  0.4817,  0.1818, -0.2207]]),\n",
       " 'net.layers.0.embeddings.embeddings.12.weight': Parameter containing:\n",
       " tensor([[ 0.0923, -0.3759,  0.3133,  0.1179,  0.8337,  0.1604, -0.3878, -0.7071],\n",
       "         [-0.5227,  0.3724,  0.0549, -0.3846, -0.2361,  0.0058,  0.9401, -0.3779]]),\n",
       " 'net.layers.0.embeddings.embeddings.13.weight': Parameter containing:\n",
       " tensor([[-0.1000,  0.6103,  0.7304, -1.2348,  0.3126,  0.1386,  0.0340, -0.0765],\n",
       "         [ 0.1793,  0.3776,  0.0121,  0.3835,  0.3539,  0.3500,  0.3984,  0.6294],\n",
       "         [ 0.2030, -0.1234, -0.0198,  0.1326,  0.2297, -0.2241,  0.3132, -0.2235],\n",
       "         [-0.1710,  0.8017, -0.9804,  0.2180, -0.1692, -0.0381, -0.6780,  0.0245],\n",
       "         [-0.2386, -0.0729, -0.5793,  0.1252,  0.3116,  0.7185, -0.1401, -0.5184],\n",
       "         [-0.2286, -0.2263,  0.2108, -0.3741, -0.1388,  0.4138,  0.3115,  0.3446],\n",
       "         [ 0.2296, -0.1960,  0.0999, -0.2384, -0.2440,  0.6099, -0.3972,  0.0061]]),\n",
       " 'net.layers.0.embeddings.embeddings.14.weight': Parameter containing:\n",
       " tensor([[-0.3801, -0.6441,  0.0271,  0.4770,  0.3873,  0.0906,  0.8833,  1.0463],\n",
       "         [-0.6277,  0.2357,  0.5071, -0.9259,  0.1244,  0.2215, -0.2348, -0.2466],\n",
       "         [ 0.4581, -0.2087, -0.4575, -0.5780,  0.1632, -0.3039, -0.2439, -0.1548],\n",
       "         [ 0.0225,  0.1363,  0.3874,  0.3914,  0.4395,  0.6963,  0.1540,  0.2003],\n",
       "         [ 0.0119, -0.0773, -0.3585, -1.1823, -0.3734, -0.3084, -0.3919,  0.2149],\n",
       "         [ 0.4860,  0.3269, -0.1972,  0.3933,  0.2790, -0.1798, -0.3568, -0.9996],\n",
       "         [ 0.0062, -0.0120,  0.2898,  0.1686, -0.0714,  0.0861, -0.5906, -0.7558]]),\n",
       " 'net.layers.0.embeddings.embeddings.15.weight': Parameter containing:\n",
       " tensor([[-0.4585,  0.2955, -0.2255,  0.2388,  0.1020,  0.3237, -0.0930, -1.7074],\n",
       "         [-0.7199,  0.2933, -0.9240,  0.1582, -0.5203,  1.0146,  0.6230,  0.0267],\n",
       "         [-0.0338, -0.0662, -0.3416, -0.9799,  0.1776,  0.4170,  0.0549, -0.9259],\n",
       "         [ 0.6035, -0.3259,  0.4026,  1.0649, -0.4758, -0.5213, -0.3372, -0.3513],\n",
       "         [-0.0115, -0.6940, -0.0231,  0.8166,  0.5918,  0.0844,  0.0293,  0.3378],\n",
       "         [-0.3400,  1.1247,  0.4490,  0.0999, -0.3842, -0.2970, -0.5959,  1.0727]]),\n",
       " 'net.layers.0.embeddings.embeddings.16.weight': Parameter containing:\n",
       " tensor([[-0.0249, -0.0397,  0.5573, -0.0171,  0.7715,  0.5539,  0.4427, -1.0661],\n",
       "         [ 0.2876, -0.8026, -0.9277,  0.6061, -0.6441, -0.2048, -0.4406, -0.1400],\n",
       "         [-0.5976,  0.1498,  0.1021, -0.5770,  0.5196, -0.0184, -1.1209,  0.0015],\n",
       "         [ 0.4801,  0.3487, -0.5381, -0.3321, -0.0832, -0.4835,  0.9777, -0.0460],\n",
       "         [-0.0658, -1.3313,  0.1982,  0.2390, -0.2132, -0.2396,  0.7825,  0.6990]]),\n",
       " 'net.layers.0.embeddings.embeddings.17.weight': Parameter containing:\n",
       " tensor([[ 0.4497,  0.4282,  0.9550,  0.2728, -0.2307,  0.0900, -0.1781,  0.1049],\n",
       "         [-0.3133,  0.4235, -0.0771,  0.4223,  0.1031,  0.3669, -0.5564,  0.0174],\n",
       "         [ 0.2687,  0.1139, -0.3016, -0.4697, -0.6533,  0.1126, -0.1271, -0.1450],\n",
       "         [ 0.4178,  0.1431,  0.4546,  0.3658, -0.6142, -0.1920, -0.4640, -0.6908],\n",
       "         [-0.2262, -0.1088, -0.2794,  0.1261,  0.1186,  0.0354,  0.1060,  0.4401],\n",
       "         [ 0.2451,  0.2686,  0.3866, -0.3563,  0.1272, -0.3696,  0.1177,  0.4951],\n",
       "         [-0.6210, -0.7407, -0.1040, -0.0595,  0.2549,  0.6195, -0.0291,  0.9157],\n",
       "         [-0.6366,  0.7428, -0.1641,  0.8066, -0.5383,  0.4070, -0.1555, -0.8741],\n",
       "         [ 0.0238, -0.0933,  0.0342, -0.3750, -0.2296, -0.3955,  0.2021,  0.9738],\n",
       "         [ 0.5821, -0.6015, -0.2499, -0.3507, -0.3875,  0.9517,  0.0027,  0.2374],\n",
       "         [ 0.8129, -0.6679,  0.1866,  0.3780, -0.2148, -0.5425,  0.5098,  0.0015],\n",
       "         [-0.1393,  0.2945, -0.2138, -0.3089, -0.1683, -0.4328, -0.0489,  0.6236],\n",
       "         [ 0.2426, -0.0630, -0.8946,  0.2437,  0.5058, -0.1040,  0.1946, -0.2018],\n",
       "         [-0.1398, -0.1899, -0.2497, -0.1951, -0.4257, -0.1834,  0.4159,  0.3359],\n",
       "         [-0.2685, -0.5703,  0.8160,  0.4978,  0.5360, -0.1782,  0.5761,  0.0114],\n",
       "         [-0.1695, -1.1287, -0.1758,  0.0740,  0.1950,  0.3485,  0.9030, -0.6249],\n",
       "         [-0.4578, -0.1862,  0.3779, -0.1859, -0.4109,  0.2708,  0.0510, -0.4049],\n",
       "         [ 0.5151,  0.3553, -0.1290, -0.1332, -0.0943,  0.2766,  0.0560,  0.0437]]),\n",
       " 'net.layers.0.embeddings.embeddings.18.weight': Parameter containing:\n",
       " tensor([[ 0.0327,  0.3245, -0.3171,  0.0804, -0.2050,  0.1764, -0.0348, -0.2452],\n",
       "         [-0.6374, -0.3624,  0.4005,  0.1170,  0.6652, -0.2579,  0.1347, -0.4330],\n",
       "         [ 0.7345, -0.0592, -0.1893,  0.1826, -0.7037,  0.1580, -0.3367,  0.7354],\n",
       "         [-0.7733, -0.1153,  0.1665, -0.1208, -0.0333, -0.0163, -0.0080,  0.1668],\n",
       "         [ 0.5134,  0.2441, -0.2087,  0.4453, -0.5613,  0.0384, -0.4517, -0.9246],\n",
       "         [-0.3878,  0.0376,  0.0069,  0.3516, -0.6354, -0.4175,  0.1576,  0.1870],\n",
       "         [ 0.0061,  0.3615,  0.1090, -0.2624, -0.3295,  0.5986, -0.1514,  0.5201],\n",
       "         [ 0.0633, -0.0516,  0.8607,  0.2727,  0.3408, -0.0146,  0.4089, -0.3729],\n",
       "         [ 0.0513, -0.0351, -0.6574, -0.4544, -0.2186, -0.0281,  0.0687, -0.3318],\n",
       "         [ 0.0294, -0.0836, -0.5459, -0.3424,  0.3839,  0.0215, -0.4541,  0.3037],\n",
       "         [-0.3734,  0.2669, -0.1904,  0.1917, -0.1580, -0.6432,  0.6901, -0.1555],\n",
       "         [-0.0293, -0.3539, -0.0324, -0.4153,  0.1570, -0.3865, -0.6330, -0.8303],\n",
       "         [-0.5224, -0.4517,  0.0457, -0.2043,  0.1125,  0.0616, -0.3320,  0.4183],\n",
       "         [ 0.4023, -0.2583,  0.3217,  0.1271,  0.4043,  0.0622, -0.3668,  0.3675],\n",
       "         [ 0.1734, -0.2145,  0.2174,  0.2614,  0.1653, -0.1750, -0.4903, -0.2734],\n",
       "         [-0.2279, -0.0096,  0.1268,  0.6342,  0.1469, -0.5949,  0.4679,  0.5923],\n",
       "         [ 0.3598, -0.0676, -0.3345,  0.0529,  0.5721, -0.7542, -0.2067,  0.2666]]),\n",
       " 'net.layers.0.out_linear_block.weight': Parameter containing:\n",
       " tensor([[ 0.0054,  0.0451, -0.0163,  ...,  0.0996, -0.0829,  0.0277],\n",
       "         [ 0.0064,  0.0485,  0.0314,  ..., -0.0748,  0.0245,  0.0552],\n",
       "         [ 0.0307,  0.0521,  0.0151,  ...,  0.0332, -0.0651, -0.0739],\n",
       "         ...,\n",
       "         [ 0.0698,  0.0454,  0.0688,  ...,  0.0059, -0.0744, -0.0492],\n",
       "         [-0.0242, -0.0422, -0.0748,  ...,  0.1054, -0.0876, -0.1607],\n",
       "         [ 0.0544,  0.0454,  0.1212,  ..., -0.0406,  0.0459, -0.0101]]),\n",
       " 'net.layers.0.out_linear_block.bias': Parameter containing:\n",
       " tensor([-0.0437, -0.0438, -0.0044, -0.0521, -0.0684, -0.0177,  0.0695, -0.0197,\n",
       "          0.0461,  0.0566,  0.0764, -0.0505,  0.0168,  0.0740, -0.0681, -0.0129,\n",
       "          0.0735, -0.0324,  0.0080, -0.0808,  0.0801, -0.0255, -0.0464, -0.0324,\n",
       "          0.0919,  0.0637,  0.0650,  0.0144, -0.0824, -0.0647, -0.0948,  0.0079]),\n",
       " 'net.layers.0.num_bn.weight': Parameter containing:\n",
       " tensor([0.9406, 0.9378, 0.8638, 0.9838, 0.8734, 1.1809]),\n",
       " 'net.layers.0.num_bn.bias': Parameter containing:\n",
       " tensor([-0.0896, -0.1116, -0.1384, -0.0403, -0.1398, -0.0710]),\n",
       " 'net.layers.1.att_block.0.weight': Parameter containing:\n",
       " tensor([[-0.0810, -0.0585, -0.0826,  ..., -0.1364,  0.0455, -0.1091],\n",
       "         [-0.0373,  0.1026,  0.0141,  ...,  0.1486,  0.0600,  0.0809],\n",
       "         [-0.0506, -0.0229,  0.1045,  ..., -0.1172, -0.2496, -0.0497],\n",
       "         ...,\n",
       "         [-0.0265, -0.0857, -0.1096,  ..., -0.1239, -0.0968, -0.0130],\n",
       "         [ 0.1839, -0.0598,  0.0286,  ...,  0.1783,  0.2015, -0.1292],\n",
       "         [ 0.0374,  0.0296, -0.2299,  ...,  0.0437, -0.0006, -0.0668]]),\n",
       " 'net.layers.1.att_block.0.bias': Parameter containing:\n",
       " tensor([ 0.1531,  0.0690,  0.1634, -0.0186, -0.0946,  0.1370, -0.0284, -0.1434,\n",
       "          0.0861, -0.1158,  0.0375,  0.0666, -0.1295, -0.0223,  0.0071, -0.0835,\n",
       "         -0.1152, -0.0667, -0.0257, -0.1797, -0.1148,  0.0598,  0.0313,  0.0982,\n",
       "          0.0015, -0.1371, -0.0540,  0.0240, -0.0665,  0.1077,  0.0726,  0.0759]),\n",
       " 'net.layers.1.att_block.1.weight': Parameter containing:\n",
       " tensor([1.0369, 1.0037, 1.0723, 0.9852, 1.0521, 1.1164, 0.9600, 1.0436, 1.0304,\n",
       "         1.1399, 0.9543, 0.8728, 0.9796, 1.0646, 0.9477, 1.0065, 1.0296, 1.1186,\n",
       "         0.8282, 1.0382, 1.0575, 0.9837, 1.0917, 1.0247, 1.0896, 1.0371, 1.1039,\n",
       "         1.0060, 1.0467, 0.9980, 0.9898, 1.0733]),\n",
       " 'net.layers.1.att_block.1.bias': Parameter containing:\n",
       " tensor([ 0.0197,  0.0765,  0.3332, -0.0320,  0.6339,  0.1035, -0.1015,  0.0946,\n",
       "          0.5814,  0.2330,  0.0834,  0.1104,  0.3220,  0.0408,  0.5187, -0.3033,\n",
       "          0.4313,  0.4401,  0.0207,  0.2978,  0.0724,  0.2836,  0.0270,  0.0751,\n",
       "         -0.0371,  0.2690, -0.0716,  0.1526,  0.1719,  0.4467, -0.0611,  0.1387]),\n",
       " 'net.layers.2.position_wise_layer.0.weight': Parameter containing:\n",
       " tensor([[ 0.1956,  0.0773,  0.2162,  ...,  0.1037, -0.1928, -0.0140],\n",
       "         [ 0.0468,  0.0864,  0.0888,  ...,  0.0446,  0.1037, -0.0316],\n",
       "         [-0.0625,  0.1135,  0.0776,  ...,  0.0345,  0.1886,  0.1219],\n",
       "         ...,\n",
       "         [ 0.1491,  0.0913,  0.1738,  ...,  0.1323,  0.1884,  0.2060],\n",
       "         [-0.2122, -0.2196, -0.1201,  ..., -0.1965,  0.0643, -0.0769],\n",
       "         [-0.0763, -0.1623, -0.0097,  ..., -0.2009,  0.0635, -0.0309]]),\n",
       " 'net.layers.2.position_wise_layer.0.bias': Parameter containing:\n",
       " tensor([ 1.4697e-01,  6.7760e-02, -1.5841e-02,  1.1405e-01, -1.4961e-03,\n",
       "         -7.0965e-04,  8.9109e-02, -7.9840e-02,  1.7209e-02, -8.1296e-02,\n",
       "          3.7978e-02, -4.1089e-02,  7.4732e-02, -2.6764e-02, -4.2907e-02,\n",
       "          3.3786e-02, -1.0200e-04, -3.0919e-02, -2.8355e-02,  2.7224e-02,\n",
       "         -5.3434e-02,  1.2564e-01, -1.4183e-02,  1.2354e-01,  9.3722e-02,\n",
       "          7.5388e-02,  5.4673e-03,  4.2122e-03,  1.1157e-01,  1.9586e-02,\n",
       "          1.8607e-02, -2.7392e-02]),\n",
       " 'net.layers.2.position_wise_layer.2.weight': Parameter containing:\n",
       " tensor([[ 0.1620,  0.1138,  0.1153,  ..., -0.0654, -0.0167, -0.1146],\n",
       "         [ 0.0271, -0.1746,  0.0723,  ..., -0.0680, -0.0775,  0.0367],\n",
       "         [-0.0390,  0.0108, -0.0793,  ...,  0.1877,  0.0553, -0.1760],\n",
       "         ...,\n",
       "         [ 0.0205,  0.1561,  0.0039,  ..., -0.0362, -0.0323, -0.1058],\n",
       "         [ 0.1154, -0.0017, -0.0601,  ..., -0.0325, -0.0511, -0.0246],\n",
       "         [ 0.1280,  0.1282,  0.1191,  ...,  0.0631, -0.1039, -0.1074]]),\n",
       " 'net.layers.2.position_wise_layer.2.bias': Parameter containing:\n",
       " tensor([-0.1050,  0.0870,  0.0553,  0.0246,  0.0121,  0.0851, -0.1539,  0.0713,\n",
       "          0.0131, -0.0205,  0.0136, -0.0672, -0.0648,  0.0276, -0.1171, -0.1487,\n",
       "          0.0306,  0.0115,  0.1182, -0.1326,  0.0205,  0.1832, -0.1165,  0.0457,\n",
       "         -0.1072, -0.1032,  0.1747, -0.0580, -0.1759, -0.0582, -0.1502,  0.1711]),\n",
       " 'net.layers.2.layer_norm.weight': Parameter containing:\n",
       " tensor([0.9860, 0.9801, 1.0210, 0.9049, 1.1048, 0.9246, 1.0077, 1.0212, 1.0346,\n",
       "         0.9729, 0.9837, 0.9728, 0.9543, 0.9661, 0.9804, 0.9263, 1.1745, 0.9938,\n",
       "         0.9641, 1.0010, 1.0704, 1.0099, 0.9917, 0.9441, 0.9420, 1.0032, 0.9552,\n",
       "         0.9750, 0.9544, 0.9854, 0.9147, 0.9747]),\n",
       " 'net.layers.2.layer_norm.bias': Parameter containing:\n",
       " tensor([ 0.0101, -0.0276, -0.0128, -0.0107, -0.0099, -0.0393, -0.0167, -0.0007,\n",
       "         -0.0157, -0.0047, -0.0141,  0.0127,  0.0466, -0.0300,  0.0170,  0.0591,\n",
       "         -0.0129, -0.0043, -0.0254,  0.0221, -0.0104,  0.0091,  0.0077, -0.0278,\n",
       "          0.0786,  0.0052, -0.0110, -0.0064,  0.0364, -0.0022,  0.0595, -0.0699]),\n",
       " 'net.layers.3.gru.weight_ih_l0': Parameter containing:\n",
       " tensor([[-0.0681, -0.0063,  0.0349,  ...,  0.1872, -0.1102,  0.0295],\n",
       "         [ 0.0686, -0.0813, -0.0338,  ...,  0.0572, -0.1832, -0.1026],\n",
       "         [-0.0198, -0.1011, -0.1940,  ..., -0.1234,  0.2202,  0.0861],\n",
       "         ...,\n",
       "         [-0.1590, -0.0102, -0.0106,  ...,  0.0113,  0.1641, -0.0497],\n",
       "         [ 0.0920, -0.0828, -0.0523,  ..., -0.1635,  0.0398,  0.0425],\n",
       "         [ 0.0988,  0.1733,  0.1597,  ..., -0.0624,  0.1311,  0.0983]]),\n",
       " 'net.layers.3.gru.weight_hh_l0': Parameter containing:\n",
       " tensor([[-0.0830,  0.1294,  0.0005,  ...,  0.0022,  0.1744, -0.0325],\n",
       "         [ 0.0990, -0.1366, -0.0074,  ..., -0.0201, -0.0358,  0.1627],\n",
       "         [ 0.0358,  0.0993,  0.0179,  ...,  0.1881,  0.1412, -0.0797],\n",
       "         ...,\n",
       "         [-0.0035, -0.1459,  0.1136,  ...,  0.0015, -0.0510,  0.0461],\n",
       "         [ 0.1278, -0.1278, -0.2371,  ...,  0.1053, -0.0903,  0.1585],\n",
       "         [ 0.0958,  0.0074,  0.1565,  ...,  0.0610,  0.0053, -0.0626]]),\n",
       " 'net.layers.3.gru.bias_ih_l0': Parameter containing:\n",
       " tensor([-6.4042e-02, -4.9184e-02, -1.1798e-01, -5.3758e-02,  2.8449e-02,\n",
       "         -1.1171e-01, -3.9305e-02,  1.0829e-02,  2.2804e-01,  2.5751e-02,\n",
       "          1.0154e-01,  4.8175e-02,  3.5042e-02,  1.2431e-01, -1.4366e-02,\n",
       "          9.9533e-02, -1.5914e-02,  1.1194e-01, -7.1402e-02, -1.2676e-01,\n",
       "          1.7763e-01,  1.1822e-01,  1.1910e-01, -1.3478e-01,  6.4891e-02,\n",
       "          7.0383e-02,  1.0989e-01,  9.6452e-02, -1.9524e-01, -3.8241e-02,\n",
       "          4.7584e-02, -1.9826e-02,  8.2646e-02, -5.0592e-02, -2.4726e-01,\n",
       "         -1.4882e-01,  1.6953e-01,  1.5409e-01, -2.0413e-01,  8.2175e-02,\n",
       "          2.2925e-01, -3.3273e-02, -2.4840e-01, -1.0117e-01, -1.7274e-01,\n",
       "         -1.4583e-02, -1.6989e-02, -2.3473e-01, -3.1114e-01,  1.0807e-01,\n",
       "          9.4202e-02, -1.0443e-01,  6.0986e-02,  1.3298e-03, -9.0105e-02,\n",
       "         -7.6981e-03, -3.2907e-02,  3.7657e-02, -4.8131e-04,  8.7219e-03,\n",
       "         -3.3887e-02,  1.5633e-02,  1.4580e-01, -2.9998e-02,  1.3510e-01,\n",
       "         -1.1819e-01,  4.4482e-03,  1.3396e-01,  6.0789e-02,  9.0697e-02,\n",
       "         -7.0534e-02,  1.5952e-01,  8.4511e-02, -2.7163e-04, -1.4381e-02,\n",
       "         -9.6116e-02, -3.7749e-02,  1.4518e-01, -1.3940e-01,  1.0535e-01,\n",
       "         -4.4957e-02,  1.5338e-01, -5.1245e-02,  1.1949e-01,  6.7576e-02,\n",
       "         -1.6669e-01, -2.3887e-02,  2.3754e-02,  6.9053e-02,  1.2561e-01,\n",
       "          3.2841e-03,  2.5516e-02, -8.0231e-02,  6.4638e-02,  1.7892e-01,\n",
       "          1.6612e-01]),\n",
       " 'net.layers.3.gru.bias_hh_l0': Parameter containing:\n",
       " tensor([ 0.0526,  0.0437, -0.0139, -0.0508,  0.0502,  0.0483,  0.0245, -0.0067,\n",
       "         -0.0277,  0.0694, -0.1454,  0.0985,  0.0442, -0.0205,  0.1209,  0.0666,\n",
       "         -0.0230,  0.0674,  0.0533,  0.0870,  0.0307,  0.0493, -0.0007, -0.0537,\n",
       "         -0.0610, -0.2157,  0.1776, -0.0052,  0.0805,  0.0571,  0.0230,  0.0687,\n",
       "         -0.0424, -0.0925, -0.1704, -0.1503, -0.0277,  0.0737, -0.0768,  0.0465,\n",
       "         -0.0862, -0.2385, -0.2028,  0.1658, -0.2116, -0.0604, -0.0134, -0.2158,\n",
       "         -0.1951, -0.1323, -0.0457,  0.0434, -0.0244, -0.2071,  0.0975, -0.1476,\n",
       "         -0.0214, -0.1821,  0.0168,  0.1056,  0.0445,  0.0655,  0.1792, -0.1483,\n",
       "          0.0535,  0.1249,  0.0892, -0.1722, -0.1685, -0.0184,  0.0307,  0.0601,\n",
       "          0.0074, -0.0612,  0.2031, -0.1678, -0.0335, -0.1671, -0.0552,  0.1122,\n",
       "          0.0525,  0.1552,  0.0109,  0.1391, -0.0267, -0.1808,  0.0663,  0.1097,\n",
       "         -0.1269,  0.0365,  0.0431, -0.0494, -0.0163,  0.0043,  0.0040,  0.1331]),\n",
       " 'net.layers.5.heads.0.linear_block.0.0.weight': Parameter containing:\n",
       " tensor([[-0.4997, -0.0714,  0.2941, -0.2845, -0.4579, -0.2965, -0.3533, -0.4770,\n",
       "          -0.0611, -0.2061, -0.2556, -0.0014, -0.4896,  0.4368, -0.4284,  0.2126,\n",
       "          -0.1543,  0.1269, -0.4333, -0.3318, -0.3332, -0.0409, -0.4758,  0.4286,\n",
       "          -0.2153, -0.3526, -0.1591,  0.0072,  0.4367, -0.3750, -0.4074,  0.1226],\n",
       "         [-0.0677, -0.1716,  0.1371, -0.3525, -0.0702,  0.5266, -0.3344, -0.1150,\n",
       "           0.1527, -0.0852,  0.1508,  0.0711,  0.1337, -0.4915, -0.0075,  0.1446,\n",
       "          -0.1630, -0.1797, -0.2637,  0.4186, -0.4529, -0.5075, -0.3254,  0.4103,\n",
       "          -0.2861, -0.1164, -0.1693, -0.3669, -0.2755, -0.1045, -0.2929,  0.1093],\n",
       "         [-0.3634,  0.0029,  0.0453, -0.2243, -0.0699,  0.3977,  0.4001,  0.4490,\n",
       "           0.0671,  0.2853,  0.0659,  0.5661,  0.5187, -0.1689, -0.4337, -0.0743,\n",
       "          -0.2434, -0.0566,  0.3692, -0.2921,  0.4459, -0.1160,  0.5497, -0.2112,\n",
       "          -0.2577, -0.0041,  0.3060, -0.1307, -0.3992,  0.3027, -0.4101,  0.0482],\n",
       "         [ 0.2034, -0.3344,  0.3047, -0.5746,  0.4433,  0.2189, -0.3805, -0.0095,\n",
       "           0.3194,  0.1852,  0.3255, -0.2469,  0.0900,  0.1332, -0.2501,  0.0277,\n",
       "           0.2164, -0.4539, -0.1702, -0.1122,  0.3753, -0.3440,  0.2374,  0.2048,\n",
       "           0.1409,  0.2365, -0.2112, -0.1981, -0.2606, -0.3642,  0.1291,  0.0245],\n",
       "         [ 0.1805,  0.0704, -0.2808, -0.2660, -0.0644, -0.4905,  0.2853,  0.0421,\n",
       "           0.2622,  0.5349,  0.0873,  0.0198,  0.1883, -0.0065,  0.3175, -0.3700,\n",
       "          -0.1669, -0.0129, -0.3969, -0.2858, -0.1827, -0.4357,  0.2227,  0.2817,\n",
       "           0.2322,  0.5085,  0.0818, -0.1802,  0.5066, -0.3473, -0.0254,  0.2819],\n",
       "         [ 0.2123, -0.2359, -0.2074,  0.3009, -0.4528, -0.1649, -0.4282,  0.1842,\n",
       "          -0.1352,  0.3685, -0.4294,  0.4566, -0.0625,  0.0528, -0.2654, -0.4090,\n",
       "           0.2931,  0.3751, -0.0391,  0.1353, -0.0789, -0.5150,  0.1465,  0.3621,\n",
       "           0.3633, -0.3818,  0.0913, -0.4150, -0.2983,  0.5076,  0.4557, -0.3692],\n",
       "         [-0.2372,  0.1058, -0.1306,  0.2829, -0.2425, -0.3554, -0.0485,  0.0624,\n",
       "           0.1605, -0.1494,  0.4512,  0.3889,  0.0380, -0.2791, -0.3040, -0.2416,\n",
       "          -0.3465,  0.0368, -0.2185, -0.0655,  0.1239,  0.4274, -0.0947, -0.2586,\n",
       "           0.2337, -0.3632,  0.0011,  0.0384,  0.2766,  0.3011,  0.0438, -0.4164],\n",
       "         [ 0.4852, -0.3463, -0.0553,  0.2900,  0.4396,  0.3970,  0.3592, -0.2366,\n",
       "           0.1473, -0.0583, -0.3322, -0.1927,  0.3116, -0.4022,  0.2591, -0.2028,\n",
       "           0.3980,  0.1352, -0.1557,  0.1083, -0.3750,  0.2393,  0.2513,  0.4055,\n",
       "           0.4776, -0.2499, -0.2430, -0.2414, -0.3987,  0.1882,  0.0326, -0.3919],\n",
       "         [ 0.1907,  0.3116, -0.5099,  0.4637,  0.3822, -0.0952,  0.3959, -0.1912,\n",
       "           0.2173,  0.2466,  0.0469,  0.1262,  0.1578, -0.2001,  0.4994, -0.3068,\n",
       "           0.0791, -0.1436, -0.1362,  0.1708, -0.3692,  0.0243, -0.1774, -0.0437,\n",
       "          -0.1117,  0.0695,  0.2951,  0.4563,  0.3369,  0.4147, -0.2994,  0.0901],\n",
       "         [-0.1832, -0.1788, -0.0903, -0.1712, -0.2150,  0.2679, -0.0442, -0.3686,\n",
       "           0.1766, -0.4133,  0.1223,  0.4244, -0.0802, -0.4584,  0.0770, -0.1849,\n",
       "           0.4055,  0.4107, -0.3305, -0.3942,  0.2605,  0.2750, -0.4637, -0.3877,\n",
       "           0.2872,  0.2951,  0.1251,  0.1044, -0.4187, -0.1429, -0.3359, -0.1337],\n",
       "         [ 0.1671, -0.0642,  0.2700,  0.0256,  0.2451,  0.3870, -0.0775,  0.0294,\n",
       "          -0.5014, -0.0851,  0.0520,  0.2919,  0.2056, -0.5065, -0.3941, -0.2699,\n",
       "           0.2864,  0.2431,  0.4024, -0.4359, -0.0977, -0.1724, -0.4798, -0.0097,\n",
       "          -0.1281, -0.1277, -0.1449, -0.2600,  0.0317, -0.1810,  0.2262, -0.0606],\n",
       "         [ 0.3139, -0.4191,  0.1503, -0.1832,  0.1340,  0.2459,  0.3138,  0.4149,\n",
       "           0.0525, -0.3846, -0.4304, -0.2901, -0.4975,  0.3631, -0.2137,  0.2934,\n",
       "           0.5570, -0.3835,  0.3551, -0.4332, -0.0769,  0.0101, -0.2621, -0.1477,\n",
       "           0.0434,  0.0062, -0.0435,  0.0120, -0.3438,  0.3437, -0.3874, -0.3215],\n",
       "         [ 0.4235,  0.3841,  0.0729, -0.4308, -0.0553,  0.4900, -0.3155, -0.2707,\n",
       "           0.0651, -0.3567, -0.2278, -0.2488,  0.3474, -0.2825,  0.4756,  0.2766,\n",
       "           0.3918, -0.4093, -0.3837,  0.0517, -0.3054,  0.4575, -0.5226, -0.2498,\n",
       "          -0.0781, -0.1116, -0.5088,  0.3375,  0.2472,  0.2057, -0.2595,  0.1421],\n",
       "         [-0.3613, -0.3167, -0.4047,  0.0275, -0.3954,  0.1179, -0.1075, -0.0415,\n",
       "           0.4246,  0.2002,  0.4876, -0.2395, -0.4772,  0.1381,  0.4226, -0.2385,\n",
       "          -0.2759, -0.0345,  0.0507, -0.1950,  0.0425, -0.4881,  0.3917,  0.2237,\n",
       "          -0.1405, -0.2350,  0.0285, -0.3971, -0.1465,  0.2829, -0.3405,  0.4514],\n",
       "         [-0.1227, -0.1505, -0.4444,  0.2847,  0.4791,  0.3702,  0.0468, -0.4703,\n",
       "          -0.1809, -0.2729,  0.4030,  0.2744, -0.1615,  0.2949, -0.1666,  0.0269,\n",
       "           0.4400,  0.2961,  0.4080,  0.1287, -0.2992, -0.2089, -0.3952, -0.2986,\n",
       "          -0.2781, -0.3653,  0.4801,  0.3241,  0.1461, -0.1579,  0.3821,  0.2067],\n",
       "         [-0.0351, -0.2451,  0.0885, -0.2317,  0.0885,  0.1003,  0.2428,  0.2815,\n",
       "           0.4187, -0.2439, -0.1680, -0.2420, -0.1210,  0.4530,  0.0978, -0.5896,\n",
       "           0.1327, -0.0661,  0.2004,  0.0030, -0.3728,  0.1002, -0.0461,  0.4900,\n",
       "           0.4360, -0.0839,  0.0286,  0.2500, -0.1714, -0.0440, -0.3432,  0.2112]]),\n",
       " 'net.layers.5.heads.0.linear_block.0.0.bias': Parameter containing:\n",
       " tensor([ 0.0272,  0.0610, -0.0234,  0.0046, -0.0136, -0.0652,  0.0171, -0.0349,\n",
       "         -0.0342,  0.0218,  0.0253, -0.0317, -0.0242,  0.0470,  0.0420, -0.0126]),\n",
       " 'net.layers.5.heads.0.linear_block.0.2.weight': Parameter containing:\n",
       " tensor([0.8959, 0.9830, 1.0236, 0.9088, 1.0507, 0.9889, 0.9342, 0.8999, 1.0406,\n",
       "         0.9668, 1.0627, 0.9917, 0.9933, 0.9795, 1.0003, 0.9283]),\n",
       " 'net.layers.5.heads.0.linear_block.0.2.bias': Parameter containing:\n",
       " tensor([-0.0105, -0.0057, -0.0046, -0.0104, -0.0028,  0.0091,  0.0084, -0.0007,\n",
       "         -0.0009,  0.0045,  0.0080,  0.0092,  0.0006, -0.0087,  0.0052,  0.0024]),\n",
       " 'net.layers.5.heads.0.linear_block.1.0.weight': Parameter containing:\n",
       " tensor([[ 0.3062,  0.2021,  0.1604, -0.2048,  0.6115,  0.6719,  0.0763, -0.5498,\n",
       "           0.4467,  0.1013, -0.5135,  0.4248,  0.2691, -0.6498,  0.0172,  0.6236],\n",
       "         [ 0.1655,  0.1007,  0.5626,  0.1228,  0.7173, -0.3824,  0.3750, -0.5083,\n",
       "          -0.4715,  0.2369, -0.4059, -0.5289,  0.2365,  0.1538, -0.2512,  0.1766],\n",
       "         [ 0.3999,  0.6936, -0.1457, -0.0545,  0.0286, -0.1491,  0.5844, -0.6437,\n",
       "          -0.4899,  0.4456,  0.6307,  0.3731,  0.1148, -0.1616,  0.4889,  0.2386],\n",
       "         [ 0.0942,  0.6207, -0.3733,  0.0501, -0.1893, -0.2600, -0.1780, -0.6393,\n",
       "          -0.3500, -0.2677,  0.1116, -0.6002,  0.5410, -0.6045,  0.6011,  0.5339],\n",
       "         [-0.5151,  0.2631, -0.5254,  0.0086,  0.4809,  0.3374,  0.4256, -0.1099,\n",
       "          -0.2458,  0.4714, -0.3364, -0.1820, -0.2222,  0.5196,  0.3391,  0.1559],\n",
       "         [-0.1851, -0.4795, -0.1476, -0.3224,  0.2121, -0.1804, -0.1055, -0.6450,\n",
       "          -0.0558,  0.4337, -0.2564, -0.6379, -0.5650,  0.2147,  0.2692,  0.5101],\n",
       "         [-0.3743, -0.4995, -0.0847,  0.3950, -0.4746, -0.2997, -0.5855,  0.4724,\n",
       "          -0.5236,  0.4833,  0.3784,  0.1663,  0.4393, -0.2667,  0.4079,  0.0650],\n",
       "         [ 0.1540, -0.5595,  0.3987, -0.0013,  0.8542,  0.0990,  0.5330, -0.4821,\n",
       "           0.2702, -0.5001,  0.2698,  0.5350, -0.4546, -0.3416,  0.3277,  0.3352]]),\n",
       " 'net.layers.5.heads.0.linear_block.1.0.bias': Parameter containing:\n",
       " tensor([-0.0001, -0.0192,  0.0064, -0.0037, -0.0401,  0.0107,  0.0019,  0.1103]),\n",
       " 'net.layers.5.heads.0.linear_block.1.2.weight': Parameter containing:\n",
       " tensor([1.0075, 0.9992, 1.0773, 1.0162, 1.0009, 0.9989, 0.9739, 0.9546]),\n",
       " 'net.layers.5.heads.0.linear_block.1.2.bias': Parameter containing:\n",
       " tensor([-0.0074, -0.0122,  0.0076, -0.0120, -0.0129, -0.0106,  0.0099,  0.0254]),\n",
       " 'net.layers.5.heads.0.out_block.weight': Parameter containing:\n",
       " tensor([[-0.7579, -0.2456,  1.2233,  0.0735, -0.2659, -0.5723,  0.9660,  0.0484]]),\n",
       " 'net.layers.5.heads.0.out_block.bias': Parameter containing:\n",
       " tensor([0.0088])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(dict(trained_model.net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHLitModule(\n",
       "  (net): SequentialLitModel(\n",
       "    (layers): Sequential(\n",
       "      (0): EncoderLayer(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (embeddings): EmbeddingLayer(\n",
       "          (embeddings): ModuleList(\n",
       "            (0-1): 2 x Embedding(20, 8)\n",
       "            (2): Embedding(7, 8)\n",
       "            (3): Embedding(6, 8)\n",
       "            (4): Embedding(1, 8)\n",
       "            (5): Embedding(4, 8)\n",
       "            (6): Embedding(14, 8)\n",
       "            (7-9): 3 x Embedding(20, 8)\n",
       "            (10-12): 3 x Embedding(2, 8)\n",
       "            (13-14): 2 x Embedding(7, 8)\n",
       "            (15): Embedding(6, 8)\n",
       "            (16): Embedding(5, 8)\n",
       "            (17): Embedding(18, 8)\n",
       "            (18): Embedding(17, 8)\n",
       "          )\n",
       "        )\n",
       "        (out_linear_block): Linear(in_features=158, out_features=32, bias=True)\n",
       "        (num_bn): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SimpleAttention1d(\n",
       "        (att_block): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): Softmax(dim=1)\n",
       "        )\n",
       "      )\n",
       "      (2): PositionwiseFeedForward(\n",
       "        (position_wise_layer): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): GRUSeqToSeq(\n",
       "        (gru): GRU(32, 32, batch_first=True)\n",
       "      )\n",
       "      (4): ConvPooling(\n",
       "        (pooling_layer): AvgPooling()\n",
       "        (agg_layer): Identity()\n",
       "      )\n",
       "      (5): MultiTaskLinearBlock(\n",
       "        (heads): ModuleList(\n",
       "          (0): LinearBlock(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear_block): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                (1): Tanh()\n",
       "                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "                (1): Tanh()\n",
       "                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (out_block): Linear(in_features=8, out_features=1, bias=True)\n",
       "            (cls_layers): Sequential(\n",
       "              (0): Dropout(p=0.0, inplace=False)\n",
       "              (1): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                  (1): Tanh()\n",
       "                  (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "                  (1): Tanh()\n",
       "                  (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=8, out_features=1, bias=True)\n",
       "              (3): Tanh()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       "  (train_metrics): ModuleDict(\n",
       "    (tanh_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "  )\n",
       "  (val_metrics): ModuleDict(\n",
       "    (tanh_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "  )\n",
       "  (test_metrics): ModuleDict(\n",
       "    (tanh_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "  )\n",
       "  (monitor_metric): CompositionalMetric(\n",
       "    true_divide(\n",
       "      CompositionalMetric(\n",
       "    add(\n",
       "      0,\n",
       "      BinaryAUROC()\n",
       "    )\n",
       "  ),\n",
       "      1\n",
       "    )\n",
       "  )\n",
       "  (train_loss): MeanMetric()\n",
       "  (train_branched_loss): ModuleDict(\n",
       "    (tanh_output): MeanMetric()\n",
       "  )\n",
       "  (val_loss): MeanMetric()\n",
       "  (val_branched_loss): ModuleDict(\n",
       "    (tanh_output): MeanMetric()\n",
       "  )\n",
       "  (test_loss): MeanMetric()\n",
       "  (test_branched_loss): ModuleDict(\n",
       "    (tanh_output): MeanMetric()\n",
       "  )\n",
       "  (val_best_metric): MaxMetric()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(trained_model.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(54.1870)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sample = next(iter(test_dataloader))\n",
    "d(GINI()(trained_model.net(test_sample).logits, test_sample.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [\n",
    "    trained_model.net(sample).logits.ravel() for i, sample in enumerate(test_dataloader) if i < 5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(plt.hist(preds, bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(plt.hist(torch.sigmoid(preds), bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thunder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_trained_model = thunder.jit(trained_model.net.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterpreterError",
     "evalue": "Encountered exception AttributeError: module 'dis' has no attribute '_parse_exception_table' while tracing SequentialLitModel(\n  (layers): Sequential(\n    (0): EncoderLayer(\n      (dropout): Dropout(p=0.3, inplace=False)\n      (embeddings): EmbeddingLayer(\n        (embeddings): ModuleList(\n          (0-1): 2 x Embedding(18, 32)\n          (2-3): 2 x Embedding(17, 32)\n          (4): Embedding(16, 32)\n          (5): Embedding(20, 32)\n          (6): Embedding(7, 32)\n          (7): Embedding(6, 32)\n          (8): Embedding(4, 32)\n          (9): Embedding(14, 32)\n          (10): Embedding(4, 32)\n          (11-12): 2 x Embedding(7, 32)\n          (13): Embedding(6, 32)\n          (14): Embedding(4, 32)\n          (15-16): 2 x Embedding(2, 32)\n          (17): Embedding(4, 32)\n          (18): Embedding(25, 32)\n          (19): Embedding(5, 32)\n          (20): Embedding(26, 32)\n          (21): Embedding(5, 32)\n          (22): Embedding(27, 32)\n          (23): Embedding(7, 32)\n          (24): Embedding(19, 32)\n          (25): Embedding(9, 32)\n          (26): Embedding(5, 32)\n          (27): Embedding(15, 32)\n          (28-30): 3 x Embedding(20, 32)\n        )\n      )\n      (out_linear_block): Linear(in_features=992, out_features=32, bias=True)\n    )\n    (1): GRUSeqToSeq(\n      (gru): GRU(32, 32, batch_first=True)\n    )\n    (2): ConvPooling(\n      (pooling_layer): AllPoolings()\n      (conv_layer): Conv1d(5, 1, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n    )\n    (3): MultiOutputLinearBlock(\n      (heads): ModuleList(\n        (0): LinearBlock(\n          (dropout): Dropout(p=0.0, inplace=False)\n          (linear_block): Sequential(\n            (0): Sequential(\n              (0): Linear(in_features=32, out_features=16, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n            )\n            (1): Sequential(\n              (0): Linear(in_features=16, out_features=8, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (out_block): Linear(in_features=8, out_features=1, bias=True)\n          (cls_layers): Sequential(\n            (0): Dropout(p=0.0, inplace=False)\n            (1): Sequential(\n              (0): Sequential(\n                (0): Linear(in_features=32, out_features=16, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n              )\n              (1): Sequential(\n                (0): Linear(in_features=16, out_features=8, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n              )\n            )\n            (2): Linear(in_features=8, out_features=1, bias=True)\n            (3): GELU(approximate='none')\n          )\n        )\n      )\n    )\n  )\n):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6557\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   6555\u001b[0m     populate_attribute_wrapper(wrapped_cell, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_contents\u001b[39m\u001b[38;5;124m\"\u001b[39m, fn_wrapped)\n\u001b[0;32m-> 6557\u001b[0m interpretation_result: Any \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_fn_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6558\u001b[0m interpretation_result \u001b[38;5;241m=\u001b[39m unwrap(interpretation_result)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6543\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_.<locals>.getfn.<locals>.fn_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_2\u001b[39m(args, kwargs):\n\u001b[0;32m-> 6543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/sequential_model.py:19\u001b[0m, in \u001b[0;36mSequentialLitModel.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: ModelInput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelOutput:\n\u001b[0;32m---> 19\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(inputs)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/embedding/encoder_layer.py:66\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: ModelInput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SingleForwardState:\n\u001b[0;32m---> 66\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(inputs\u001b[38;5;241m.\u001b[39mcategorical)\n\u001b[1;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/embedding/encoder_layer.py:29\u001b[0m, in \u001b[0;36mEmbeddingLayer.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m---> 29\u001b[0m         [embedding(x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]) \u001b[38;5;28;01mfor\u001b[39;00m idx, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m     ) \u001b[38;5;66;03m# size = (batch_size, len(cat_features), embedding_dim)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/embedding/encoder_layer.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m---> 29\u001b[0m         [embedding(x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]) \u001b[38;5;28;01mfor\u001b[39;00m idx, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m     ) \u001b[38;5;66;03m# size = (batch_size, len(cat_features), embedding_dim)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5601\u001b[0m, in \u001b[0;36m_unpack_sequence_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   5599\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[0;32m-> 5601\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6046\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6045\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_lookaside(lookaside_fn)\n\u001b[0;32m-> 6046\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mlookaside_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6047\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1831\u001b[0m, in \u001b[0;36m_next_lookaside\u001b[0;34m(iterator, default)\u001b[0m\n\u001b[1;32m   1829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n\u001b[0;32m-> 1831\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _nil \u001b[38;5;129;01mand\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1829\u001b[0m, in \u001b[0;36m_next_lookaside.<locals>.impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimpl\u001b[39m(iterator):\n\u001b[0;32m-> 1829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1966\u001b[0m, in \u001b[0;36mSequenceIter.__next__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_reversed \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_pos \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms))) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_reversed \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_pos \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 1966\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[1;32m   1967\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_pos]\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6301\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m-> 6301\u001b[0m     exception_table \u001b[38;5;241m=\u001b[39m \u001b[43mdis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_exception_table\u001b[49m(frame\u001b[38;5;241m.\u001b[39mcode)  \u001b[38;5;66;03m# type: ignore (_parse_exception_table is undocumented)\u001b[39;00m\n\u001b[1;32m   6303\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dis' has no attribute '_parse_exception_table'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInterpreterError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mjit_trained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:194\u001b[0m, in \u001b[0;36mThunderModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 194\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:611\u001b[0m, in \u001b[0;36mjit.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m cs\u001b[38;5;241m.\u001b[39mlast_trace_host_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[1;32m    609\u001b[0m cs\u001b[38;5;241m.\u001b[39mcalls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 611\u001b[0m cache_entry, inps, pro_to_epi \u001b[38;5;241m=\u001b[39m \u001b[43mget_computation_and_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m cs\u001b[38;5;241m.\u001b[39mlast_trace_host_execution_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[1;32m    614\u001b[0m result \u001b[38;5;241m=\u001b[39m cache_entry\u001b[38;5;241m.\u001b[39mcomputation_fn(\u001b[38;5;241m*\u001b[39minps)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:262\u001b[0m, in \u001b[0;36m_with_cache_info_ctx.<locals>.cache_info_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m tok \u001b[38;5;241m=\u001b[39m _cache_info_ctx\u001b[38;5;241m.\u001b[39mset({})\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     _cache_info_ctx\u001b[38;5;241m.\u001b[39mreset(tok)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:498\u001b[0m, in \u001b[0;36mjit.<locals>.get_computation_and_inputs\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m     prologue_trc: TraceCtx\n\u001b[1;32m    497\u001b[0m     computation_trc: TraceCtx\n\u001b[0;32m--> 498\u001b[0m     prologue_trc, computation_trc, \u001b[38;5;241m*\u001b[39mmaybe_epilogue \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharp_edges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msharp_edges\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maybe_epilogue:\n\u001b[1;32m    503\u001b[0m     epilogue_traces \u001b[38;5;241m=\u001b[39m maybe_epilogue\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:175\u001b[0m, in \u001b[0;36m_general_frontend\u001b[0;34m(fn, args, kwargs, sharp_edges)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_general_frontend\u001b[39m(fn: Callable, args, kwargs, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m, sharp_edges: SHARP_EDGES_OPTIONS) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[TraceCtx, TraceCtx]:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthunder_general_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharp_edges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharp_edges\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/jit_ext.py:1386\u001b[0m, in \u001b[0;36mthunder_general_jit\u001b[0;34m(fn, args, kwargs, sharp_edges)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m general_jit_ctx(ctx):\n\u001b[1;32m   1385\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracectx(computation_trace):\n\u001b[0;32m-> 1386\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mjfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m         prims\u001b[38;5;241m.\u001b[39mpython_return(result)\n\u001b[1;32m   1388\u001b[0m         process_recorded_modifications(ctx, epilogue_trace)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6566\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   6562\u001b[0m     traceback_str \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlinesep\u001b[38;5;241m.\u001b[39mjoin(f\u001b[38;5;241m.\u001b[39mformat_with_source() \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m runtimectx\u001b[38;5;241m.\u001b[39mframe_stack)\n\u001b[1;32m   6563\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   6564\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m while tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mlinesep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6565\u001b[0m     )\n\u001b[0;32m-> 6566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterpreterError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   6567\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   6568\u001b[0m     \u001b[38;5;66;03m# NOTE: Wrapped functions are valid to assign new attributes to.\u001b[39;00m\n\u001b[1;32m   6569\u001b[0m     fn_\u001b[38;5;241m.\u001b[39m_last_interpreted_instructions \u001b[38;5;241m=\u001b[39m runtimectx\u001b[38;5;241m.\u001b[39minterpreted_instructions  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mInterpreterError\u001b[0m: Encountered exception AttributeError: module 'dis' has no attribute '_parse_exception_table' while tracing SequentialLitModel(\n  (layers): Sequential(\n    (0): EncoderLayer(\n      (dropout): Dropout(p=0.3, inplace=False)\n      (embeddings): EmbeddingLayer(\n        (embeddings): ModuleList(\n          (0-1): 2 x Embedding(18, 32)\n          (2-3): 2 x Embedding(17, 32)\n          (4): Embedding(16, 32)\n          (5): Embedding(20, 32)\n          (6): Embedding(7, 32)\n          (7): Embedding(6, 32)\n          (8): Embedding(4, 32)\n          (9): Embedding(14, 32)\n          (10): Embedding(4, 32)\n          (11-12): 2 x Embedding(7, 32)\n          (13): Embedding(6, 32)\n          (14): Embedding(4, 32)\n          (15-16): 2 x Embedding(2, 32)\n          (17): Embedding(4, 32)\n          (18): Embedding(25, 32)\n          (19): Embedding(5, 32)\n          (20): Embedding(26, 32)\n          (21): Embedding(5, 32)\n          (22): Embedding(27, 32)\n          (23): Embedding(7, 32)\n          (24): Embedding(19, 32)\n          (25): Embedding(9, 32)\n          (26): Embedding(5, 32)\n          (27): Embedding(15, 32)\n          (28-30): 3 x Embedding(20, 32)\n        )\n      )\n      (out_linear_block): Linear(in_features=992, out_features=32, bias=True)\n    )\n    (1): GRUSeqToSeq(\n      (gru): GRU(32, 32, batch_first=True)\n    )\n    (2): ConvPooling(\n      (pooling_layer): AllPoolings()\n      (conv_layer): Conv1d(5, 1, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n    )\n    (3): MultiOutputLinearBlock(\n      (heads): ModuleList(\n        (0): LinearBlock(\n          (dropout): Dropout(p=0.0, inplace=False)\n          (linear_block): Sequential(\n            (0): Sequential(\n              (0): Linear(in_features=32, out_features=16, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n            )\n            (1): Sequential(\n              (0): Linear(in_features=16, out_features=8, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (out_block): Linear(in_features=8, out_features=1, bias=True)\n          (cls_layers): Sequential(\n            (0): Dropout(p=0.0, inplace=False)\n            (1): Sequential(\n              (0): Sequential(\n                (0): Linear(in_features=32, out_features=16, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n              )\n              (1): Sequential(\n                (0): Linear(in_features=16, out_features=8, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n              )\n            )\n            (2): Linear(in_features=8, out_features=1, bias=True)\n            (3): GELU(approximate='none')\n          )\n        )\n      )\n    )\n  )\n):\n"
     ]
    }
   ],
   "source": [
    "preds = jit_trained_model(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: ModelInput",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrained_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcredits_history_lit_model.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1405\u001b[0m, in \u001b[0;36mLightningModule.to_onnx\u001b[0;34m(self, file_path, input_sample, **kwargs)\u001b[0m\n\u001b[1;32m   1402\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_before_batch_transfer(input_sample)\n\u001b[1;32m   1403\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_batch_transfer_handler(input_sample)\n\u001b[0;32m-> 1405\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(mode)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:1613\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1610\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1611\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1613\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1628\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1629\u001b[0m )\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:1135\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m   1134\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1135\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:1011\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m   1007\u001b[0m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m   1013\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:915\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    913\u001b[0m prev_autocast_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    914\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 915\u001b[0m trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    924\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/jit/_trace.py:1296\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1295\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m-> 1296\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/jit/_trace.py:105\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 105\u001b[0m     in_vars, in_desc \u001b[38;5;241m=\u001b[39m \u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# NOTE: use full state, because we need it for BatchNorm export\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# This differs from the compiler path, which doesn't support it at the moment.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     module_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(_unique_state_dict(\u001b[38;5;28mself\u001b[39m, keep_vars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: ModelInput"
     ]
    }
   ],
   "source": [
    "trained_model.net.to_onnx(\"credits_history_lit_model.onnx\", sample[0], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
