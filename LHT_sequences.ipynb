{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from IPython.display import display as d\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.dataset import CreditsHistoryDataset\n",
    "from src.data.components.targets_indexes_reader import TargetsReader, IndexesReader\n",
    "from src.data.components.data_reader import DataReader\n",
    "from src.utils.sampler import SamplerFactory\n",
    "from src.utils.metrics import GINI\n",
    "from torchmetrics import MeanMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randint(0, 4, (5, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 3, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Embedding(num_embeddings=4, embedding_dim=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[ 1.2962,  0.5405,  0.5765, -0.8487,  0.2105,  0.0374, -1.7631, -1.2126],\n",
       "         [ 0.2306, -0.5026, -1.0136, -0.8195, -0.7585,  0.4862,  0.5229,  0.2072],\n",
       "         [-0.2808, -0.1399,  0.6364,  0.4589,  0.8277,  1.0517, -0.7562,  1.4967],\n",
       "         [ 0.4944, -0.2382,  0.6527, -0.6246, -0.8596, -1.7815,  0.0119,  1.2357]],\n",
       "        requires_grad=True)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(dict(a.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2808, -0.1399,  0.6364,  0.4589,  0.8277,  1.0517, -0.7562,  1.4967],\n",
       "        [ 1.2962,  0.5405,  0.5765, -0.8487,  0.2105,  0.0374, -1.7631, -1.2126],\n",
       "        [ 0.2306, -0.5026, -1.0136, -0.8195, -0.7585,  0.4862,  0.5229,  0.2072],\n",
       "        [ 0.4944, -0.2382,  0.6527, -0.6246, -0.8596, -1.7815,  0.0119,  1.2357],\n",
       "        [ 0.4944, -0.2382,  0.6527, -0.6246, -0.8596, -1.7815,  0.0119,  1.2357]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe701280bd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a(sample).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 1, 2, 3]), tensor([2, 3, 4, 2, 3, 4]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(torch.concatenate([torch.stack(item).T for item in a]).unbind(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int = 128, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.position_wise_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, input_size)\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(input_size, eps=1e-6)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "\n",
    "        x = self.position_wise_layer(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooModel(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int = 128, max_seq_len: int = 50, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.position_wise_forward = PositionwiseFeedForward(\n",
    "            input_size=emb_dim, \n",
    "            hidden_size=emb_dim * 2, \n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.linear_layer = nn.Linear(emb_dim, 1)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool1d(kernel_size=max_seq_len)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.position_wise_forward(inputs)\n",
    "\n",
    "        x = self.linear_layer(x).squeeze()\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_batch = (torch.randn(size=(32, 50, emb_dim)), torch.randint(0, 2, (32, ), dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_model = FooModel(emb_dim, emb_dim * 2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa614b19890>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(some_batch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(some_model(some_batch[0]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification.auroc import BinaryAUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINI(BinaryAUROC):\n",
    "    def __init__(self) -> None:\n",
    "        super(GINI, self).__init__()\n",
    "        \n",
    "    def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        return (2. * super().forward(logits, labels) - 1.) * 100.\n",
    "    \n",
    "    # def compute(self) -> torch.Tensor:\n",
    "    #     return super().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = GINI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(43.7500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a(some_model(some_batch[0]), some_batch[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0903,  0.0469,  0.0347, -0.1100,  0.0162,  0.0895,  0.0320,  0.1441,\n",
       "         0.0787,  0.0022,  0.0888, -0.0043,  0.1492, -0.0996,  0.0271,  0.0832,\n",
       "        -0.0649,  0.0250,  0.0833, -0.0095,  0.1098,  0.1297,  0.0403,  0.0176,\n",
       "        -0.0573, -0.0441, -0.1633,  0.0786, -0.0913,  0.0039, -0.0435, -0.0718],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(some_model(some_batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a._buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.979999999999993"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d((0.5749 * 2 - 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7188)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6924)\n",
      "tensor(11.7409)\n",
      "tensor(0.5587) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danil/projects/torch_template/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:436: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(0.6924, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(some_model.training_step(some_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.collate import ModelInput, SingleForwardState, BaseCollator, ModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sampler(targets: dict, n_samples: int = 1000, replacement: bool = True):\n",
    "\n",
    "    targets = np.asarray(list(targets.values()))\n",
    "    \n",
    "    sampler_factory = SamplerFactory(\n",
    "        targets=targets, \n",
    "        n_samples=n_samples,\n",
    "        replacement=replacement\n",
    "    )\n",
    "    return sampler_factory.balanced_random_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(features_path: str, data_path: str, indexes_path: str, targets_path: str, use_sampler: bool = True, batch_size: int = 32):\n",
    "    features_dict = OmegaConf.load(features_path)\n",
    "\n",
    "    data_reader = DataReader(data_path=data_path)\n",
    "    data_reader.setup()\n",
    "\n",
    "    indexes = IndexesReader(train_path=indexes_path).train_indexes\n",
    "\n",
    "    targets = TargetsReader(targets_path).targets\n",
    "\n",
    "    targets = {idx: targets.get(idx) for idx in indexes}\n",
    "\n",
    "    dataset = CreditsHistoryDataset(\n",
    "        data=data_reader, \n",
    "        targets=targets,\n",
    "        indexes=indexes,\n",
    "        features=features_dict\n",
    "    )\n",
    "\n",
    "    print(f\"dataset sample: {dataset[0]}\")\n",
    "\n",
    "    train_sampler = set_sampler(\n",
    "        targets=dataset.targets, \n",
    "        n_samples=10000,\n",
    "        replacement=False\n",
    "    ) if use_sampler else None\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=BaseCollator(max_seq_len=50),\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True\n",
    "    ) \n",
    "\n",
    "    return dataloader, features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sample: {'numerical': tensor([[ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
      "        [ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
      "        [ 0.4800,  0.1688,  0.1680,  0.9858,  7.2181,  0.0000],\n",
      "        [ 3.1200,  2.6531,  0.4693, -0.8830,  7.2181,  0.0000],\n",
      "        [ 0.2400,  0.0925,  0.0923,  0.9957,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 1.2000,  0.4866,  0.4677,  0.8839,  7.2181,  0.0000],\n",
      "        [ 2.2800,  1.3662,  0.9791,  0.2032,  7.2181,  0.0000],\n",
      "        [ 2.6400,  1.8312,  0.9663, -0.2574,  7.2181,  0.0000]]), 'categorical': tensor([[ 8, 12,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4, 11,\n",
      "          0],\n",
      "        [ 8,  6,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          3],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  1,  4,  2,\n",
      "          0],\n",
      "        [10,  1,  4,  3,  0,  2,  5, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          2],\n",
      "        [ 0, 17,  4,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          6],\n",
      "        [ 6,  8,  3,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "         11],\n",
      "        [18, 14,  3,  3,  0,  2, 13, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          0],\n",
      "        [11, 13,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          4],\n",
      "        [11,  0,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [ 7,  2,  0,  1,  0,  2,  4,  2,  2, 17,  0,  1,  1,  1,  2,  0,  4,  3,\n",
      "          0],\n",
      "        [ 7,  7,  2,  3,  0,  2,  1, 16,  2, 17,  1,  1,  1,  1,  2,  3,  4,  0,\n",
      "          2]]), 'target': 0, 'length': 12, 'sample_index': '205752'}\n"
     ]
    }
   ],
   "source": [
    "test_dataloader, _ = initialize_data(\n",
    "    \"configs/data/features/features_credits_aggregated_v2.yaml\",\n",
    "    \"./data/credits-history/serialized/serialized_first_part_v2\",\n",
    "    \"./data/credits-history/indexes/ser_full_0_indexes/train_indexes.pickle\",\n",
    "    \"./data/credits-history/targets/targets_dict.pickle\",\n",
    "    use_sampler=False,\n",
    "    batch_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sample: {'numerical': tensor([[ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
      "        [ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
      "        [ 0.4800,  0.1688,  0.1680,  0.9858,  7.2181,  0.0000],\n",
      "        [ 3.1200,  2.6531,  0.4693, -0.8830,  7.2181,  0.0000],\n",
      "        [ 0.2400,  0.0925,  0.0923,  0.9957,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 1.2000,  0.4866,  0.4677,  0.8839,  7.2181,  0.0000],\n",
      "        [ 2.2800,  1.3662,  0.9791,  0.2032,  7.2181,  0.0000],\n",
      "        [ 2.6400,  1.8312,  0.9663, -0.2574,  7.2181,  0.0000]]), 'categorical': tensor([[ 8, 12,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4, 11,\n",
      "          0],\n",
      "        [ 8,  6,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          3],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  1,  4,  2,\n",
      "          0],\n",
      "        [10,  1,  4,  3,  0,  2,  5, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          2],\n",
      "        [ 0, 17,  4,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          6],\n",
      "        [ 6,  8,  3,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "         11],\n",
      "        [18, 14,  3,  3,  0,  2, 13, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          0],\n",
      "        [11, 13,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          4],\n",
      "        [11,  0,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [ 7,  2,  0,  1,  0,  2,  4,  2,  2, 17,  0,  1,  1,  1,  2,  0,  4,  3,\n",
      "          0],\n",
      "        [ 7,  7,  2,  3,  0,  2,  1, 16,  2, 17,  1,  1,  1,  1,  2,  3,  4,  0,\n",
      "          2]]), 'target': 0, 'length': 12, 'sample_index': '205752'}\n"
     ]
    }
   ],
   "source": [
    "dataloader, features_dict = initialize_data(\n",
    "    \"configs/data/features/features_credits_aggregated_v2.yaml\",\n",
    "    \"./data/credits-history/serialized/serialized_first_part_v2\",\n",
    "    \"./data/credits-history/indexes/ser_full_0_indexes/train_indexes.pickle\",\n",
    "    \"./data/credits-history/targets/targets_dict.pickle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelBatch(numerical=tensor([[[ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
       "         [ 0.8400,  0.3087,  0.3038,  0.9527,  7.2181,  0.0000],\n",
       "         [ 1.0000,  0.3952,  0.3850,  0.9229,  7.2181,  0.2500],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.4000,  1.9453,  0.9307, -0.3658,  7.2181,  1.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
       "         [ 2.2800,  1.3662,  0.9791,  0.2032,  7.2181,  0.0000],\n",
       "         [ 1.5600,  0.7129,  0.6540,  0.7565,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.4800,  1.6455,  0.9972, -0.0747,  7.2181,  0.2500],\n",
       "         [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.2400,  0.0925,  0.0923,  0.9957,  7.2181,  0.0000],\n",
       "         [ 0.2400,  0.0925,  0.0923,  0.9957,  7.2181,  0.2500],\n",
       "         [ 1.7600,  0.8967,  0.7813,  0.6242,  7.2181,  0.2500],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 3.0000,  2.4223,  0.6588, -0.7523,  7.2181,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]), categorical=tensor([[[ 6, 15,  2,  ...,  4,  1,  0],\n",
       "         [11, 12,  2,  ...,  4,  0,  7],\n",
       "         [11, 15,  5,  ...,  4,  1,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[16,  1,  6,  ...,  4,  0,  8],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[16,  0,  2,  ...,  4,  7,  0],\n",
       "         [ 8, 10,  2,  ...,  4,  1,  0],\n",
       "         [ 8, 16,  2,  ...,  4,  6,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7, 16,  3,  ...,  4,  0,  4],\n",
       "         [ 7, 15,  0,  ...,  4,  0,  1],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 4, 10,  4,  ...,  4,  0, 10],\n",
       "         [ 4, 10,  4,  ...,  4,  0, 10],\n",
       "         [ 1,  0,  0,  ...,  4,  0,  3],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[12, 12,  6,  ...,  4,  9,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]]]), targets=tensor([[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]]), sample_indexes=['166561', '29039', '142458', '92842', '63485', '177722', '237106', '222266', '143985', '84561', '172637', '44514', '162322', '173461', '8144', '47765', '248141', '38443', '202691', '88755', '112445', '38852', '248875', '5463', '215551', '27057', '72713', '211051', '21951', '59326', '46900', '55254'], mask=tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "        [False,  True,  True,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False,  True,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False,  True,  True,  ...,  True,  True,  True]]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sample check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample():\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    x = ModelInput(\n",
    "        numerical=batch.numerical,\n",
    "        categorical=batch.categorical,\n",
    "        mask=batch.mask\n",
    "    )\n",
    "\n",
    "    labels = batch.targets\n",
    "\n",
    "    return x, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(sample[0].numerical.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d((~sample[0].mask).sum(dim=1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6800,  2.0000,  2.4800,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8012,  1.1430,  1.6569,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7182,  0.9099,  0.9963,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.6959,  0.4149, -0.0860,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  7.2181,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.2500,  0.4500,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.6800,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8012,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7182,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.6959,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1200,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0587,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0586,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9983,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.2000,  0.1200,  0.1200,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4866,  0.0587,  0.0587,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4677,  0.0586,  0.0586,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8839,  0.9983,  0.9983,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  7.2181,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.3200,  2.5200,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.4372,  1.6636,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9911,  0.9957,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1332, -0.0927,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2500,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2400,  2.3600,  1.8800,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.3824,  1.5141,  0.9819,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9823,  0.9984,  0.8315,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1873,  0.0566,  0.5555,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  7.2181,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4500,  0.2000,  0.2500,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(rearrange(sample[0].numerical, \"N L H -> N H L\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model layers check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            categorical_features: dict,\n",
    "            embedding_dim: int = 32,\n",
    "            div_emb_dim: int = 4\n",
    "        ) -> None:\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.embeddings = nn.ModuleList()\n",
    "\n",
    "        for num_embs in self.categorical_features.values():\n",
    "            embedding = nn.Embedding(\n",
    "                num_embeddings=num_embs, \n",
    "                embedding_dim=embedding_dim // div_emb_dim\n",
    "            )\n",
    "\n",
    "            nn.init.xavier_normal_(embedding.weight, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "            self.embeddings.append(embedding)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        x = torch.concatenate(\n",
    "            [embedding(x[..., idx]) for idx, embedding in enumerate(self.embeddings)], dim=-1\n",
    "        ) # size = (batch_size, len(cat_features), embedding_dim)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            numerical_features: list,\n",
    "            categorical_features: dict,\n",
    "            embedding_dim: int = 16,\n",
    "            dropout_inputs: float = 0.5,\n",
    "            non_linear: bool = False,\n",
    "            num_batch_norm: bool = True,\n",
    "            div_emb_dim: int = 4\n",
    "        ) -> None:\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_inputs)\n",
    "\n",
    "        self.numerical_features = numerical_features\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.embeddings = EmbeddingLayer(\n",
    "            categorical_features=categorical_features,\n",
    "            embedding_dim=embedding_dim,\n",
    "            div_emb_dim=div_emb_dim\n",
    "        )\n",
    "\n",
    "        if non_linear:\n",
    "            self.out_linear_block = nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    (embedding_dim // div_emb_dim) * len(self.categorical_features)  + len(self.numerical_features), \n",
    "                    embedding_dim\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Linear(embedding_dim, embedding_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.out_linear_block = nn.Linear(\n",
    "                (embedding_dim // div_emb_dim) * len(self.categorical_features) + len(self.numerical_features), \n",
    "                embedding_dim\n",
    "            )\n",
    "\n",
    "        if num_batch_norm:\n",
    "            self.num_bn = nn.BatchNorm1d(len(self.numerical_features))\n",
    "        else: \n",
    "            self.num_bn = None\n",
    "\n",
    "\n",
    "    def forward(self, inputs: ModelInput) -> SingleForwardState:\n",
    "\n",
    "        embeddings = self.embeddings(inputs.categorical)\n",
    "        \n",
    "        if self.num_bn is None:\n",
    "            x_num = inputs.numerical\n",
    "        else:\n",
    "            x_num = rearrange(inputs.numerical, \"N L H -> N H L\")\n",
    "\n",
    "            x_num = self.num_bn(x_num)\n",
    "\n",
    "            x_num = rearrange(x_num, \"N H L -> N L H\")\n",
    "            \n",
    "        x = torch.concatenate((x_num, embeddings), dim=-1)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_linear_block(x)\n",
    "\n",
    "        return SingleForwardState(\n",
    "            sequences=x, \n",
    "            mask=inputs.mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = EncoderLayer(\n",
    "    numerical_features=features_dict[\"numerical\"],\n",
    "    categorical_features=features_dict[\"categorical\"],\n",
    "    embedding_dim=32,\n",
    "    dropout_inputs=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc = enc(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleForwardState(sequences=tensor([[[ 3.0180e-01, -4.1825e-01,  6.0283e-01,  ..., -4.9092e-01,\n",
       "           1.5259e-01,  2.9201e-01],\n",
       "         [ 4.5527e-01, -3.5896e-01,  1.5147e-01,  ..., -5.5303e-01,\n",
       "           3.3580e-01,  2.5049e-01],\n",
       "         [ 2.3227e-01, -3.9913e-01,  3.5249e-01,  ...,  1.6609e-01,\n",
       "           6.1646e-01,  2.5856e-02],\n",
       "         ...,\n",
       "         [-5.3288e-02,  3.5347e-02, -4.8583e-01,  ..., -4.6117e-01,\n",
       "           5.0640e-01,  8.3791e-02],\n",
       "         [-8.3981e-02,  2.8281e-01, -3.8616e-01,  ..., -6.0089e-01,\n",
       "           4.8202e-01,  1.0850e-01],\n",
       "         [-7.7968e-02,  1.4037e-01, -2.8565e-01,  ..., -5.1693e-01,\n",
       "           6.4352e-01,  2.0679e-02]],\n",
       "\n",
       "        [[ 6.1151e-01, -4.8622e-01,  7.3609e-01,  ..., -2.9638e-01,\n",
       "           3.0921e-01,  2.1559e-01],\n",
       "         [-1.5264e-01, -3.0955e-01,  2.5721e-01,  ..., -3.3205e-01,\n",
       "           6.9550e-01, -3.2945e-01],\n",
       "         [-4.4376e-02, -3.4382e-01,  4.4636e-01,  ..., -2.7084e-01,\n",
       "           3.7750e-01,  4.0952e-02],\n",
       "         ...,\n",
       "         [-6.7407e-02,  2.3539e-01, -2.7732e-01,  ..., -4.8801e-01,\n",
       "           5.1613e-01,  1.9290e-01],\n",
       "         [ 3.4369e-03,  1.7188e-01, -4.8944e-01,  ..., -5.4598e-01,\n",
       "           3.5015e-01,  5.5552e-02],\n",
       "         [-4.9246e-02,  1.8812e-01, -3.3011e-01,  ..., -4.2105e-01,\n",
       "           7.7007e-01,  8.3189e-02]],\n",
       "\n",
       "        [[-2.3394e-01, -2.0632e-01,  6.9819e-02,  ..., -4.8171e-01,\n",
       "           4.5947e-02, -1.7278e-01],\n",
       "         [ 1.9385e-01, -2.9817e-01,  7.6244e-01,  ..., -4.2454e-02,\n",
       "           1.0309e-01, -7.8634e-02],\n",
       "         [-6.0670e-02, -6.8397e-01,  1.1948e-01,  ..., -2.1238e-01,\n",
       "           1.3682e-01, -8.6383e-02],\n",
       "         ...,\n",
       "         [ 1.8076e-02,  2.5940e-01, -3.4561e-01,  ..., -4.5960e-01,\n",
       "           4.2568e-01,  1.6353e-01],\n",
       "         [-2.6243e-02,  3.4461e-01, -2.2319e-01,  ..., -4.5945e-01,\n",
       "           5.9211e-01,  1.8699e-01],\n",
       "         [ 5.7967e-02,  1.8118e-01, -4.0740e-01,  ..., -5.9300e-01,\n",
       "           5.7889e-01,  1.2324e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.0277e-01, -4.9420e-01,  2.2763e-01,  ..., -4.1587e-01,\n",
       "           2.8642e-01,  2.3104e-01],\n",
       "         [ 3.7925e-01, -4.6778e-01,  1.7048e-01,  ..., -4.0257e-01,\n",
       "           1.0929e-01,  2.7371e-01],\n",
       "         [-7.5160e-02, -5.9823e-01,  2.0630e-02,  ..., -6.0649e-01,\n",
       "           4.6509e-01, -2.7334e-01],\n",
       "         ...,\n",
       "         [ 3.6909e-02,  2.0729e-01, -2.2755e-01,  ..., -2.2702e-01,\n",
       "           4.2570e-01,  1.3329e-01],\n",
       "         [-3.2950e-02,  3.2820e-01, -2.3337e-01,  ..., -6.0597e-01,\n",
       "           4.4188e-01,  1.1158e-01],\n",
       "         [ 5.5514e-02,  1.6204e-01, -3.5487e-01,  ..., -4.7499e-01,\n",
       "           5.3949e-01,  1.4793e-01]],\n",
       "\n",
       "        [[ 4.5707e-01, -4.2029e-01,  2.4085e-01,  ..., -5.3996e-01,\n",
       "           3.0347e-01,  3.0252e-02],\n",
       "         [ 1.5173e-02, -7.0665e-01,  1.1267e-01,  ..., -4.3119e-01,\n",
       "           7.0364e-01, -5.2331e-03],\n",
       "         [-2.7025e-01, -7.5446e-01,  2.2325e-01,  ..., -7.7656e-01,\n",
       "           4.3479e-01, -2.3246e-01],\n",
       "         ...,\n",
       "         [ 6.1126e-02,  2.4662e-01, -4.0110e-01,  ..., -6.5554e-01,\n",
       "           5.7412e-01,  1.1349e-01],\n",
       "         [-1.8797e-02,  2.4473e-01, -5.1057e-01,  ..., -5.9192e-01,\n",
       "           3.4066e-01,  9.0137e-02],\n",
       "         [-6.6966e-02,  2.6505e-01, -4.5408e-01,  ..., -4.4472e-01,\n",
       "           4.8782e-01,  6.8653e-04]],\n",
       "\n",
       "        [[-1.7834e-01, -7.2798e-01, -9.9494e-04,  ..., -3.2949e-01,\n",
       "           6.1314e-01, -2.4791e-01],\n",
       "         [-5.6395e-01, -5.8298e-01,  1.5215e-01,  ..., -2.4222e-01,\n",
       "           2.1598e-01, -7.5223e-02],\n",
       "         [ 1.7239e-01,  1.4533e-01, -3.7204e-01,  ..., -5.4269e-01,\n",
       "           4.4982e-01,  1.2223e-01],\n",
       "         ...,\n",
       "         [-1.1296e-01,  2.1168e-01, -4.5799e-01,  ..., -6.6444e-01,\n",
       "           6.4817e-01,  5.7098e-02],\n",
       "         [ 1.5109e-01,  4.6742e-01, -3.5487e-01,  ..., -4.3550e-01,\n",
       "           5.2329e-01,  1.7551e-01],\n",
       "         [ 2.0342e-01,  1.9950e-01, -4.0699e-01,  ..., -5.4015e-01,\n",
       "           5.2039e-01, -1.6422e-02]]], grad_fn=<ViewBackward0>), mask=tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False,  True,  ...,  True,  True,  True]]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False,  True,  ...,  True,  True,  True]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_enc.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_enc.sequences.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f683b0e39d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(12, 10))\n",
    "\n",
    "ax = figure.add_subplot(2, 2, 1)\n",
    "ax.imshow(sample[0].categorical[0])\n",
    "\n",
    "ax = figure.add_subplot(2, 1, 1)\n",
    "ax.imshow(x_enc.sequences[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.base_transformer.encoder_decoder import Encoder, Decoder\n",
    "from src.models.components.base_transformer.sub_layers import EncoderLayer, DecoderLayer\n",
    "from src.models.components.base_transformer.multihead_attention import MultiHeadAttention\n",
    "from src.models.components.base_transformer.positionwise_ff import PositionwiseFeedForward\n",
    "from src.models.components.base_transformer.transformer import BaseTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = BaseTransformer(\n",
    "    Encoder(\n",
    "        encoder_layer=EncoderLayer(\n",
    "            attention=MultiHeadAttention(EMB_DIM, 1),\n",
    "            feed_forward=PositionwiseFeedForward(EMB_DIM, activation_type=\"gelu\")\n",
    "        ),\n",
    "        n_layers=1\n",
    "    ),\n",
    "    Decoder(\n",
    "        decoder_layer=DecoderLayer(\n",
    "            src_attention=MultiHeadAttention(EMB_DIM, 2),\n",
    "            tgt_attention=MultiHeadAttention(EMB_DIM, 3),\n",
    "            feed_forward=PositionwiseFeedForward(EMB_DIM, activation_type=\"gelu\")\n",
    "        ),\n",
    "        n_layers=2\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att = attn(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1815, -0.6403,  0.3771,  ..., -0.2175, -1.9895, -0.9573],\n",
       "        [-0.0900, -0.5626, -0.4823,  ..., -1.4979, -0.7396,  0.6867],\n",
       "        [-1.0799, -1.8166, -0.0866,  ...,  0.3099,  0.3094,  0.4028],\n",
       "        ...,\n",
       "        [-0.2612,  1.3261, -1.2604,  ..., -1.1673,  0.2154,  0.2035],\n",
       "        [ 0.0205,  0.7286, -0.9850,  ..., -2.1068,  0.2001, -0.1033],\n",
       "        [ 0.7794, -0.2183, -0.7187,  ..., -0.8687,  0.7998, -0.3253]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_att.sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_att.sequences.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f683b08fe10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(6, 6))\n",
    "\n",
    "ax = figure.add_subplot()\n",
    "ax.imshow(x_att.sequences[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUAggregator(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_size: int, \n",
    "            num_layers_gru: int = 1,\n",
    "            bidirectional: bool = False,\n",
    "            dropout_gru: float = 0.0\n",
    "    ) -> None:\n",
    "        super(GRUAggregator, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=num_layers_gru,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_gru\n",
    "        )\n",
    "\n",
    "    def forward(self, x: SingleForwardState) -> SingleForwardState:\n",
    "\n",
    "        lengths = (~x.mask).sum(dim=1)\n",
    "\n",
    "        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            input=x.sequences, \n",
    "            lengths=lengths, \n",
    "            batch_first=True, \n",
    "            enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        _, hidden_state = self.gru(packed_sequences)\n",
    "\n",
    "        return SingleForwardState(\n",
    "            sequences=hidden_state[-1],\n",
    "            mask=x.mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gru_ = GRUAggregator(\n",
    "    hidden_size=EMB_DIM,\n",
    "    num_layers_gru=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gru = x_gru_(x_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_gru.sequences.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f683085fd90>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(6, 6))\n",
    "\n",
    "ax = figure.add_subplot()\n",
    "ax.imshow(x_gru.sequences[0].detach().unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.pooling.agg_pooling import ConvPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingType(nn.Module):\n",
    "    num_poolings: int = None\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PoolingType, self).__init__()\n",
    "\n",
    "def first_pooling(hidden_state: torch.Tensor, dim: int = 1):\n",
    "    assert len(hidden_state.size()) == 3, \\\n",
    "        \"hidden state size should be (batch_size x num_seq x seq_len)\"\n",
    "\n",
    "    return hidden_state[:, 0, :] if dim == 1 else hidden_state[:, :, 0]\n",
    "\n",
    "\n",
    "def last_pooling(hidden_state: torch.Tensor, lengths: torch.Tensor, dim: int = 1):\n",
    "    assert len(hidden_state.size()) == 3, \\\n",
    "        \"hidden state size should be (batch_size x num_seq x seq_len)\"\n",
    "    \n",
    "    if dim == 1:\n",
    "        hidden_state = hidden_state[torch.arange(hidden_state.size(0)), lengths - 1, :] # (N, L, B)\n",
    "    elif dim == 2:\n",
    "        hidden_state = hidden_state[torch.arange(hidden_state.size(0)), :, lengths - 1] # (N, B, L)\n",
    "    else:\n",
    "        raise NotImplementedError(\"dim is not valid, select dim from the <[1, 2]>\")\n",
    "\n",
    "    return hidden_state\n",
    "\n",
    "\n",
    "def avg_pooling(hidden_state: torch.Tensor, lengths: torch.Tensor, dim: int = 1):\n",
    "    assert len(hidden_state.size()) == 3, \\\n",
    "        \"hidden state size should be (batch_size x num_seq x seq_len) or (num_seq x seq_len)\"\n",
    "\n",
    "    return torch.mean(hidden_state, dim=dim)\n",
    "\n",
    "\n",
    "class FirstLastAvgPoolings(PoolingType):\n",
    "    def __init__(self, dim: int = 1):\n",
    "        super(FirstLastAvgPoolings, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "\n",
    "        self.num_poolings = 3\n",
    "\n",
    "    def forward(self, hidden_state: torch.Tensor):\n",
    "        pooled_results = [\n",
    "            first_pooling(hidden_state, self.dim),\n",
    "            last_pooling(hidden_state, self.dim),\n",
    "            avg_pooling(hidden_state, self.dim)\n",
    "        ]\n",
    "        hidden_state_pooled = torch.concatenate(pooled_results, dim=self.dim)\n",
    "\n",
    "        return hidden_state_pooled\n",
    "    \n",
    "\n",
    "POOLING_MAPPING = {\n",
    "    \"first_last_avg\": FirstLastAvgPoolings\n",
    "}\n",
    "\n",
    "\n",
    "class Pooling(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            emb_dim: int,\n",
    "            pooling_type: str = \"all\", \n",
    "            use_batch_norm: bool = True,\n",
    "            dim: int = 1\n",
    "        ) -> None:\n",
    "        super(Pooling, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "\n",
    "        pooling_types = list(POOLING_MAPPING.keys())\n",
    "        assert pooling_type in pooling_types, \\\n",
    "            f\"You should specify pooling type from {pooling_types}, not {pooling_type}\"\n",
    "        \n",
    "        self.pooling_layer = POOLING_MAPPING[pooling_type](dim=dim)\n",
    "\n",
    "        input_size = self.pooling_layer.num_poolings * emb_dim\n",
    "\n",
    "        self.agg_layer = nn.Linear(input_size, emb_dim)\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(emb_dim) if use_batch_norm else nn.Identity()\n",
    "        \n",
    "    def forward(self, hidden_state: SingleForwardState) -> ModelOutput:\n",
    "        x = self.pooling_layer(hidden_state.sequences)\n",
    "        x = self.batch_norm(self.agg_layer(x))\n",
    "\n",
    "        return ModelOutput(\n",
    "            representations=x,\n",
    "            logits=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pooled_ = Pooling(emb_dim=32, pooling_type=\"first_last_avg\", use_batch_norm=False, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pooling(\n",
       "  (pooling_layer): FirstLastAvgPoolings()\n",
       "  (agg_layer): Linear(in_features=96, out_features=32, bias=True)\n",
       "  (batch_norm): Identity()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_pooled_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pooled = x_pooled_(x_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_pooled.representations.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f63a2eb4790>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAABACAYAAADS6ZfiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAQS0lEQVR4nO3de1BU9d8H8PeC7OrKTeSyrAgCXtBUSpR169EsNsHS8VLzo5/OhGY4GsyUmKM0o6T+gWlPVuqk8zSTzeSldCSfbPRJUWBKhCT4oWWMMIygsZISF7ksl/0+fzhubYLKOW1nj7xfM2eGPfv98v3w4TPHj8u5aIQQAkREREQq4aF0AERERET9weaFiIiIVIXNCxEREakKmxciIiJSFTYvREREpCpsXoiIiEhV2LwQERGRqrB5ISIiIlVh80JERESqwuaFiIiIVMVlzUtDQwOWLFkCX19f+Pv7Y/ny5bh9+/Z958yaNQsajcZpW7lypatCJCIiIhXSuOrZRnPmzEFdXR327t2Lrq4uLFu2DNOmTcOBAwf6nDNr1iyMHTsWmzdvduzT6/Xw9fV1RYhERESkQoNc8U0vX76MkydP4ocffsDUqVMBADt37sTzzz+P9957D0ajsc+5er0eBoPBFWERERHRI8AlzUthYSH8/f0djQsAWCwWeHh4oKioCAsXLuxz7v79+/H555/DYDBg3rx52LBhA/R6fZ/jbTYbbDab47XdbkdDQwOGDx8OjUbz9/xARERE5FJCCLS0tMBoNMLD4/5ntbikebFarQgODnZeaNAgBAQEwGq19jlv8eLFiIiIgNFoRHl5OdatW4eKigocPXq0zznZ2dnYtGnT3xY7ERERKae2thZhYWH3HdOv5mX9+vV499137zvm8uXL/fmWTlasWOH4etKkSQgNDUVCQgKqqqoQHR3d65zMzExkZGQ4Xjc1NSE8PBz/hRcwSOMlKY7rGfGS5gGAee5/JM8FgO/OTpY8N+x0h6y1W8N0kuc+/nq5rLU9NHbJc6v/NUzW2rX/jpQ8t/2xdllre18YInmucf5VWWsH61okzy25MVLW2m3XvSXPjczplLV2U/RgWfM7vaV/ohvycZGstT2DgyTPnf1Nhay1I7xuSp576DeTrLWj9NLXzvnWLGvtiOP3v9Dkfqr+3fdfDR6Gxk96rRv+Vytr7f/7708lz533yxxJ87rbOnH+5f+Bj4/PA8f2q3lZs2YNli5det8xUVFRMBgMqK+vdw6quxsNDQ39Op/FZLpT8JWVlX02LzqdDjrdvf/oDtJ4SW5ePHXSD25ab3kF4zFY+tqDZH6O5uklvXnRekvL9V1ympdBHvJyLuf37aGXd767nLW9hsr7ubWDpc/3bJFeKwDgMUROncu7SNJTK6958dRJb16kHpMca8uo9SHe8g4Qeq2n5LlebfJqVTdUet7kHFMBYNCgbulry6hzANDopdf6IC95Off1kbH2UHnHh4c55aNf1RwUFISgoAd3/mazGY2NjSgpKUFcXBwA4MyZM7Db7Y6G5GGUlZUBAEJDQ/sTJhERET3CXHKfl/HjxyMpKQmpqakoLi5GRkYGXnjhBWg0GixcuBDFxcW4fv06YmJiUFxcDACoqqrCli1bUFJSgt27dyMsLAwzZsyAXq/HtWvXXBEmERERqZDLblK3f/9+xMTEYObMmdixYwemT5+OoqIixMbGIjExEXV1daioqEBbWxsAQKvV4vTp03jmmWeQnp6Ojo4OLFu2DGlpaViwYAEuXbrkqlCJiIhIRVxytREABAQE4MCBAzCZTJg2bRp27doFAJgyZQq++eYbnD59Gn++P97IkSORn5+P5ORktLa24vjx4473CgoKsGvXLuzZs8dV4RIREZFKuPTZRp2dnSgpKYHFYvljQQ8PWCwWFBYW9jqnsLDQaTwAJCYm9jneZrOhubnZaSMiIqJHl0ubl5s3b6KnpwchISFO+0NCQvq834vVau3X+OzsbPj5+Tm2kSPlXcJJRERE7k31T5XOzMxEU1OTY6utrVU6JCIiInIhl53zAgCBgYHw9PTEjRs3nPbfuHGjz/u9GAyGfo3v6z4vRERE9Ghy6ScvWq0WcXFx2LFjB0aNGoXBgwfDZDLhxIkTMJt7v+uhwWDA6tWrodFoHNuWLVv6HE9EREQDi8v/bDR9+nQUFBTAYrHg8OHDaG5uxs2bNzF37lwAwCuvvILMzEzH+Oeeew4AsHHjRhQUFGDNmjXw9PREenq6q0MlIiIiFXB583L+/HnMmDEDp06dwksvvQQfHx8EBgY6LoWuqalBXV2dY/yYMWOg1+tx6NAhWCwWnDx5EseOHcPEiRNdHSoRERGpgEvPebl7qfSRI0ewYMECx/6UlBTHpc95eXn3zLPZbOjo6EBwcDCio6MRERHR5xo2mw02m83xuqmpCQDQLbokx91jk/6Aw87b8h4aZ++QvnZ3t7wHM/Z0SX9OT+dt6fkG5D3bqNsuL+dyft/2Npk5t0l/Tk5Xq7yfu7Nb+vyeNtuDB92HvV36s2q6ZcQNAD3ypsv6nck5LgGAkFHr7belP6MHANq8eiTPlVurNhl5k3NMBeQdV+3t8j4f0Gil5627S/oxFQCaW2Qck1ulHR+62+78vH++B1yfhAtdv35dABDnzp1z2r927VoRHx/f65xz586Jzz77TJSWloq8vDwxd+5c4evrK2pra3sdn5WVJQBw48aNGzdu3B6Bra9/7//MpZ+8SGE2m51Ozn3yyScxfvx47N27F1u2bLlnfGZmJjIyMhyv7XY7GhoaMHz48F6fTNnc3IyRI0eitrYWvr6+rvkhHjHMmTTMW/8xZ9Iwb/3HnEnjyrwJIdDS0gKj0fjAsW53qfRfeXl54YknnkBlZWWv7/d2qbS/v/8Dv6+vry8Ltp+YM2mYt/5jzqRh3vqPOZPGVXnz8/N7qHH/yKXSubm5jn12ux25ubkPfelzT08PLl68iNDQUFeFSURERCri8j8bZWRkICUlBVOnTkV8fDw++OADtLa2YtmyZQDuXCo9YsQIZGdnAwA2b96M6dOnY/To0WhsbMT27dtx9epVvPbaa64OlYiIiFTA5c1LcnIyfvvtN2zcuBFWqxWPP/44Tp486Xh+UU1NDTw8/vgA6Pfff0dqaiqsViuGDRuGuLg4nDt3DhMmTPhb4tHpdMjKyuJdefuBOZOGees/5kwa5q3/mDNp3CVvGiEe5pokIiIiIveg+gczEhER0cDC5oWIiIhUhc0LERERqQqbFyIiIlIVNi9ERESkKgOqedm9ezdGjRqFwYMHw2Qyobi4WOmQ3No777wDjUbjtMXExCgdltspKCjAvHnzYDQaodFo8NVXXzm9L4TAxo0bERoaiiFDhsBiseDKlSvKBOsmHpSzpUuX3lN7SUlJygTrJrKzszFt2jT4+PggODgYCxYsQEVFhdOYjo4OpKWlYfjw4fD29saLL754zx3OB5qHydusWbPuqbeVK1cqFLHyPv74Y0yePNlxF12z2YwTJ0443neHOhswzcsXX3yBjIwMZGVl4ccff0RsbCwSExNRX1+vdGhu7bHHHkNdXZ1j++6775QOye20trYiNjYWu3fv7vX9bdu24aOPPsKePXtQVFSEoUOHIjExER0yn3arZg/KGQAkJSU51d7Bgwf/wQjdT35+PtLS0nD+/HmcOnUKXV1dmD17NlpbWx1jVq9eja+//hqHDx9Gfn4+fv31VyxatEjBqJX3MHkDgNTUVKd627Ztm0IRKy8sLAxbt25FSUkJLly4gGeffRbz58/HTz/9BMBN6qx/z4lWr/j4eJGWluZ43dPTI4xGo8jOzlYwKveWlZUlYmNjlQ5DVQCInJwcx2u73S4MBoPYvn27Y19jY6PQ6XTi4MGDCkTofv6aMyGESElJEfPnz1ckHrWor68XAER+fr4Q4k5deXl5icOHDzvGXL58WQAQhYWFSoXpdv6aNyGEePrpp8Ubb7yhXFAqMGzYMPHJJ5+4TZ0NiE9eOjs7UVJSAovF4tjn4eEBi8WCwsJCBSNzf1euXIHRaERUVBSWLFmCmpoapUNSlerqalitVqfa8/Pzg8lkYu09QF5eHoKDgzFu3DisWrUKt27dUjokt9LU1AQACAgIAACUlJSgq6vLqdZiYmIQHh7OWvuTv+btrv379yMwMBATJ05EZmYm2tralAjP7fT09ODQoUNobW2F2Wx2mzpz+eMB3MHNmzfR09PjeCTBXSEhIfjll18Uisr9mUwm7Nu3D+PGjUNdXR02bdqEGTNm4NKlS/Dx8VE6PFWwWq0A0Gvt3X2P7pWUlIRFixYhMjISVVVVePvttzFnzhwUFhbC09NT6fAUZ7fb8eabb+Kpp57CxIkTAdypNa1WC39/f6exrLU/9JY3AFi8eDEiIiJgNBpRXl6OdevWoaKiAkePHlUwWmVdvHgRZrMZHR0d8Pb2Rk5ODiZMmICysjK3qLMB0byQNHPmzHF8PXnyZJhMJkRERODLL7/E8uXLFYyMHnUvv/yy4+tJkyZh8uTJiI6ORl5eHhISEhSMzD2kpaXh0qVLPAetn/rK24oVKxxfT5o0CaGhoUhISEBVVRWio6P/6TDdwrhx41BWVoampiYcOXIEKSkpyM/PVzoshwHxZ6PAwEB4enreczb0jRs3YDAYFIpKffz9/TF27FhUVlYqHYpq3K0v1p48UVFRCAwMZO0BSE9Px/Hjx3H27FmEhYU59hsMBnR2dqKxsdFpPGvtjr7y1huTyQQAA7retFotRo8ejbi4OGRnZyM2NhYffvih29TZgGhetFot4uLikJub69hnt9uRm5sLs9msYGTqcvv2bVRVVSE0NFTpUFQjMjISBoPBqfaam5tRVFTE2uuHa9eu4datWwO69oQQSE9PR05ODs6cOYPIyEin9+Pi4uDl5eVUaxUVFaipqRnQtfagvPWmrKwMAAZ0vf2V3W6HzWZznzr7x04NVtihQ4eETqcT+/btEz///LNYsWKF8Pf3F1arVenQ3NaaNWtEXl6eqK6uFt9//72wWCwiMDBQ1NfXKx2aW2lpaRGlpaWitLRUABDvv/++KC0tFVevXhVCCLF161bh7+8vjh07JsrLy8X8+fNFZGSkaG9vVzhy5dwvZy0tLeKtt94ShYWForq6Wpw+fVpMmTJFjBkzRnR0dCgdumJWrVol/Pz8RF5enqirq3NsbW1tjjErV64U4eHh4syZM+LChQvCbDYLs9msYNTKe1DeKisrxebNm8WFCxdEdXW1OHbsmIiKihIzZ85UOHLlrF+/XuTn54vq6mpRXl4u1q9fLzQajfj222+FEO5RZwOmeRFCiJ07d4rw8HCh1WpFfHy8OH/+vNIhubXk5GQRGhoqtFqtGDFihEhOThaVlZVKh+V2zp49KwDcs6WkpAgh7lwuvWHDBhESEiJ0Op1ISEgQFRUVygatsPvlrK2tTcyePVsEBQUJLy8vERERIVJTUwf8fzR6yxcA8emnnzrGtLe3i9dff10MGzZM6PV6sXDhQlFXV6dc0G7gQXmrqakRM2fOFAEBAUKn04nRo0eLtWvXiqamJmUDV9Crr74qIiIihFarFUFBQSIhIcHRuAjhHnWmEUKIf+5zHiIiIiJ5BsQ5L0RERPToYPNCREREqsLmhYiIiFSFzQsRERGpCpsXIiIiUhU2L0RERKQqbF6IiIhIVdi8EBERkaqweSEiIiJVYfNCREREqsLmhYiIiFTl/wH0EU3avPTjzQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_pooled.representations[0].detach().unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.collate import ModelOutput\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_TYPE_MAPPING = {\n",
    "    \"tanh\": nn.Tanh,\n",
    "    \"gelu\": nn.GELU,\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"none\": nn.Identity\n",
    "}\n",
    "\n",
    "def init_linear_block_weights(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.zeros_(layer.bias)\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            in_features: int, \n",
    "            out_features: int = 1, \n",
    "            num_layers: int = 3, \n",
    "            dropout_rate: float = 0.0, \n",
    "            activation_type: str = \"tanh\",\n",
    "            use_batch_norm: bool = False,\n",
    "            bias: bool = True\n",
    "        ) -> None:\n",
    "        super(LinearBlock, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        if activation_type is None:\n",
    "            self.act = ACTIVATION_TYPE_MAPPING[\"tanh\"]\n",
    "        elif activation_type in ACTIVATION_TYPE_MAPPING.keys():\n",
    "            self.act = ACTIVATION_TYPE_MAPPING[activation_type]\n",
    "        else: \n",
    "            NotImplementedError(f\"activation_type must be in <{list(ACTIVATION_TYPE_MAPPING.keys())}>\")\n",
    "\n",
    "        if use_batch_norm:\n",
    "            self.layer_norm = nn.BatchNorm1d\n",
    "        else:\n",
    "            self.layer_norm = nn.LayerNorm\n",
    "\n",
    "        self.linear_block = nn.Sequential(\n",
    "            *[\n",
    "                nn.Sequential(\n",
    "                    *[\n",
    "                        nn.Linear(in_features // (2 ** i), in_features // (2 ** (i + 1)), bias),\n",
    "                        self.layer_norm(in_features // (2 ** (i + 1))),\n",
    "                        self.act()\n",
    "                    ]\n",
    "                ) for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.out_block = nn.Linear(\n",
    "            in_features=in_features // (2 ** num_layers), out_features=out_features\n",
    "        )\n",
    "\n",
    "        self.cls_layers = nn.Sequential(\n",
    "            self.dropout,\n",
    "            self.linear_block,\n",
    "            self.out_block,\n",
    "            self.act()\n",
    "        )\n",
    "\n",
    "        # weights init\n",
    "        self.cls_layers.apply(init_linear_block_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x: ModelOutput) -> ModelOutput:\n",
    "        logits = self.cls_layers(x.representations)\n",
    "\n",
    "        return ModelOutput(\n",
    "            representations=x.representations,\n",
    "            logits=logits\n",
    "        )\n",
    "\n",
    "\n",
    "class MultiTaskLinearBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            heads: List[LinearBlock]\n",
    "    ) -> None: \n",
    "        super(MultiTaskLinearBlock, self).__init__()\n",
    "\n",
    "        self.heads = nn.ModuleList(heads)\n",
    "\n",
    "    def forward(self, x: ModelOutput) -> ModelOutput:\n",
    "        multi_state = [\n",
    "            head(x).logits for head in self.heads\n",
    "        ]\n",
    "\n",
    "        logits = torch.concat(multi_state, dim=1) # size(batch_size, num_outputs)\n",
    "        \n",
    "        return ModelOutput(\n",
    "            representations=x.representations,\n",
    "            logits=logits\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = MultiTaskLinearBlock(\n",
    "    heads=[\n",
    "        LinearBlock(32, 1, 2)\n",
    "    ]\n",
    ")(x_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelOutput(representations=tensor([[-0.0807, -0.0925,  0.0185,  ...,  0.0862,  0.0276, -0.0489],\n",
       "        [-0.0164, -0.0240,  0.0047,  ...,  0.0191,  0.0072, -0.0139],\n",
       "        [-0.0550, -0.0686,  0.0153,  ...,  0.0614,  0.0193, -0.0378],\n",
       "        ...,\n",
       "        [-0.0029, -0.0036,  0.0004,  ...,  0.0021,  0.0021, -0.0017],\n",
       "        [-0.1101, -0.1254,  0.0267,  ...,  0.1202,  0.0347, -0.0692],\n",
       "        [-0.0092, -0.0124, -0.0006,  ...,  0.0077,  0.0030, -0.0051]],\n",
       "       grad_fn=<SqueezeBackward1>), logits=tensor([[-0.3835],\n",
       "        [-0.4595],\n",
       "        [-0.3846],\n",
       "        [-0.5128],\n",
       "        [-0.4077],\n",
       "        [-0.4268],\n",
       "        [-0.4213],\n",
       "        [-0.6295],\n",
       "        [-0.4995],\n",
       "        [-0.0691],\n",
       "        [-0.4164],\n",
       "        [-0.4121],\n",
       "        [-0.3576],\n",
       "        [-0.3559],\n",
       "        [-0.3748],\n",
       "        [-0.3683],\n",
       "        [-0.3324],\n",
       "        [-0.3280],\n",
       "        [-0.3166],\n",
       "        [-0.3467],\n",
       "        [-0.4153],\n",
       "        [-0.5702],\n",
       "        [-0.4393],\n",
       "        [-0.3760],\n",
       "        [-0.3955],\n",
       "        [-0.4136],\n",
       "        [-0.3758],\n",
       "        [-0.4318],\n",
       "        [-0.3609],\n",
       "        [-0.2603],\n",
       "        [-0.3825],\n",
       "        [-0.5049]], grad_fn=<CatBackward0>))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metrics import GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "            self, \n",
    "            model: nn.Module, \n",
    "            optimizer: torch.optim.Optimizer, \n",
    "            criterion: nn.BCEWithLogitsLoss,\n",
    "            train_dataloader: torch.utils.data.DataLoader, \n",
    "            scheduler: torch.optim.lr_scheduler.LRScheduler = None\n",
    "        ) -> None:\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.task_names = [\"tanh_output\"]\n",
    "        self.task_weights = torch.tensor([1.0])\n",
    "\n",
    "        self.train_data = train_dataloader\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "        self.gini = GINI()\n",
    "\n",
    "        self.train_results = list()\n",
    "\n",
    "    def multioutput_loss(self, logits: ModelOutput, targets: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # logits size is (batch_size, num_outputs)\n",
    "        # targets size is (batch_size, 1)\n",
    "\n",
    "        targets = targets.expand(size=(-1, len(self.task_names))) # to size like logits\n",
    "\n",
    "        weighted_loss = self.task_weights * self.criterion(logits, targets)\n",
    "        \n",
    "        # (self.task_weights * self.criterion(logits, targets)).sum() / len(self.task_names)\n",
    "        loss = weighted_loss.sum() / (len(weighted_loss) * len(self.task_names))\n",
    "        branched_loss = (weighted_loss.sum(dim=0) / len(weighted_loss)).detach()\n",
    "\n",
    "        return loss, branched_loss\n",
    "\n",
    "    def fit(self, epochs: int = 3, show_step: int = 100):\n",
    "        n_total_steps = len(self.train_data)\n",
    "\n",
    "        loss_step = 0\n",
    "        gini_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            self.epoch = epoch\n",
    "            \n",
    "            print('Epoch %s/%s' % (epoch + 1, epochs))\n",
    "\n",
    "            for step, batch in enumerate(self.train_data):\n",
    "                self.optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                x = ModelInput(\n",
    "                    numerical=batch.numerical,\n",
    "                    categorical=batch.categorical,\n",
    "                    lengths=batch.lengths\n",
    "                )\n",
    "\n",
    "                labels = batch.targets\n",
    "\n",
    "                outputs = self.model(x)\n",
    "        \n",
    "                loss, _ = self.multioutput_loss(\n",
    "                    logits=outputs.logits,\n",
    "                    targets=labels\n",
    "                )\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                loss_step += loss.item()\n",
    "                gini_step += self.gini(outputs.logits[:, 0], labels.squeeze())\n",
    "\n",
    "                self.train_results.append(\n",
    "                    [\n",
    "                        self.epoch * n_total_steps + step, \n",
    "                        loss.item()\n",
    "\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                if (step + 1) % show_step == 0:\n",
    "                    print(\n",
    "                        f\"Step [{step+1}/{n_total_steps}] | Time: {time.time() - epoch_start_time:.2f}s | Loss: {loss_step / show_step:.4f} | GINI: {gini_step / show_step:.1f}\"\n",
    "                    )\n",
    "                    gini_step = 0\n",
    "                    loss_step = 0\n",
    "\n",
    "        self.train_writer = pd.DataFrame(self.train_results, columns=[\"step\", \"loss\"])\n",
    "\n",
    "        print('\\nDone.')\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'''[INFO]\\n{\"-\" * 60}\\ndata: {self.data} \\n{\"-\" * 60} \\nmodel: {self.model} \\n{\"-\" * 60} \\noptimizer: {self.optimizer} \\n{\"-\" * 60}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    EncoderLayer(\n",
    "        numerical_features=features_dict[\"numerical\"],\n",
    "        categorical_features=features_dict[\"categorical\"],\n",
    "        embedding_dim=32,\n",
    "        dropout_inputs=0.1\n",
    "    ),\n",
    "    SimpleAttention1d(\n",
    "        features_dim=32\n",
    "    ),\n",
    "    GRUSeqToSeq(\n",
    "        hidden_size=32,\n",
    "        num_layers_gru=1\n",
    "    ),\n",
    "    ConvPooling(\n",
    "        pooling_type=\"avg\", dim=1\n",
    "    ),\n",
    "    MultiTaskLinearBlock(\n",
    "        heads=[\n",
    "            LinearBlock(32, 1, 2)\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = bnb.optim.Adam8bit(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.99)\n",
    "\n",
    "train_model = Trainer(\n",
    "    model=model, \n",
    "    criterion=nn.BCEWithLogitsLoss(\n",
    "        reduction=\"none\"\n",
    "    ),\n",
    "    train_dataloader=dataloader, \n",
    "    optimizer=opt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.fit(epochs=3, show_step=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(test_sample).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(44.4487)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(GINI()(preds, test_sample.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - 40.82 ~ lr 1e-4\n",
    "# 2 - 44.80 ~ lr 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_preds = torch.concatenate((torch.sigmoid(preds), test_sample.targets), dim=1).sort(dim=0).values.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(test_sample.targets, torch.sigmoid(preds).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr, label=np.trapz(fpr, tpr))\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.ch_lit_module import CHLitModule\n",
    "from IPython.display import display as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, ckpt_path: str):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = CHLitModule.load_from_checkpoint(ckpt_path)\n",
    "        self.net.eval()\n",
    "        self.net.freeze()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danil/projects/LHT_credits_history/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n"
     ]
    }
   ],
   "source": [
    "trained_model = PretrainedModel(\"logs/train/runs/2024-05-17_15-29-11/checkpoints/epoch_008.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'net.layers.0.embeddings.embeddings.0.weight': Parameter containing:\n",
       " tensor([[ 0.3699, -0.2070, -0.0574,  0.2860,  0.2871, -0.6516, -0.6582,  0.5127],\n",
       "         [ 0.1410,  0.2636, -0.3663,  0.0577, -0.0728, -0.2222, -0.1203,  0.2031],\n",
       "         [-0.0567,  0.1484, -0.0080,  0.4410, -0.4481,  0.6227,  0.2812,  0.1424],\n",
       "         [ 0.5029,  0.5404,  0.2679, -0.2057,  0.1066,  0.6148,  0.0578,  0.2919],\n",
       "         [ 0.0854, -0.5548, -0.3337, -0.7263, -0.8032,  0.1141,  0.6581, -0.1204],\n",
       "         [ 0.0527,  0.1385,  0.4128,  0.0555, -0.0998,  0.6886,  0.2679,  0.2707],\n",
       "         [ 0.0658, -0.6800,  0.2542,  0.0125,  0.1882, -0.2867, -0.4131, -0.0066],\n",
       "         [-0.5129,  0.3926, -0.1316,  0.1095,  0.1492,  0.0342, -0.1043, -0.1082],\n",
       "         [ 0.7351, -0.2886, -0.0506, -0.1919, -0.3095, -0.0912, -0.4972, -0.6453],\n",
       "         [-0.0855,  0.7006,  0.1623,  0.0464, -0.3214,  0.2569,  0.4515, -0.2935],\n",
       "         [ 0.1043, -1.0722,  0.4554, -0.1094, -0.4576,  0.2693, -0.4176, -0.5339],\n",
       "         [-0.0371,  0.3646,  0.0029,  0.1255,  0.3745, -0.1615, -0.2103,  0.1747],\n",
       "         [-0.4477,  0.4286, -0.7409, -0.2609,  0.8090, -0.2080,  0.7119,  0.1521],\n",
       "         [-0.5949,  0.2777,  0.2093, -0.1092, -1.0188,  0.3513, -0.0582,  0.6688],\n",
       "         [ 0.7310, -0.3986, -0.3268,  0.1958, -0.1449, -0.1986,  0.1352,  0.0091],\n",
       "         [ 0.5874,  0.3664,  0.4509,  0.1803, -0.0789,  0.3012, -0.4218, -0.0349],\n",
       "         [ 0.2038, -0.5040, -0.1111,  0.3532,  0.3121,  0.2887, -0.4364, -0.0628],\n",
       "         [ 0.3136, -0.6425,  0.2121,  0.2583, -0.0404, -0.3557,  0.4833, -0.4263],\n",
       "         [-0.1137,  0.6033, -0.3684, -0.4334, -0.4225, -0.4419, -0.1906,  0.0969],\n",
       "         [-0.5504,  0.2417,  0.0559,  0.5556,  0.6404, -0.0128,  0.5223, -0.9649]]),\n",
       " 'net.layers.0.embeddings.embeddings.1.weight': Parameter containing:\n",
       " tensor([[ 1.4486e-01, -8.4162e-03, -4.5565e-01,  1.9824e-01,  3.5770e-01,\n",
       "          -6.7466e-01,  2.1231e-02, -5.9421e-02],\n",
       "         [ 6.2493e-01,  2.9356e-01,  3.8539e-02, -2.5011e-01, -4.3072e-01,\n",
       "           1.8201e-01,  8.8827e-01,  8.6883e-02],\n",
       "         [ 2.1339e-01,  2.5476e-01, -2.7484e-01, -7.7017e-01,  2.8994e-01,\n",
       "          -6.1247e-01, -3.1169e-01, -4.6875e-01],\n",
       "         [-1.9644e-01, -4.6290e-01, -5.3011e-01,  1.6047e-01, -6.8754e-01,\n",
       "          -2.2702e-02,  4.1159e-01,  3.6379e-01],\n",
       "         [-4.9860e-01,  3.4768e-01, -1.9776e-01, -4.3667e-02,  1.6519e-02,\n",
       "           1.4165e-01,  1.3021e-01,  3.0409e-01],\n",
       "         [ 1.0245e-01, -1.9459e-01,  9.2944e-01,  7.6801e-01,  3.6170e-01,\n",
       "           1.3476e-01,  5.3134e-02,  7.4413e-01],\n",
       "         [-4.8779e-02,  2.3430e-01,  3.3678e-01, -3.7895e-01, -8.2183e-01,\n",
       "           5.9627e-01, -4.4715e-02, -3.0324e-02],\n",
       "         [ 2.1342e-01,  6.2804e-01, -6.1529e-01,  1.6437e-01,  1.1295e-01,\n",
       "           1.2914e-01, -2.2412e-01, -1.8831e-01],\n",
       "         [-3.7579e-02, -1.5021e-02, -2.2728e-01, -1.4991e-01, -5.8891e-01,\n",
       "          -2.6950e-01, -4.0308e-01, -2.9204e-01],\n",
       "         [-9.1534e-02,  3.7934e-02, -1.4085e-01, -1.1701e-01,  6.4543e-02,\n",
       "           2.5350e-01, -1.5982e-01, -6.4189e-01],\n",
       "         [ 5.3639e-02, -6.7709e-01,  3.7026e-01, -1.2262e-01, -2.7149e-01,\n",
       "          -1.2375e-01, -4.6411e-01, -1.2218e-01],\n",
       "         [-3.6897e-01,  6.1150e-02, -4.4581e-01,  1.8853e-01,  6.0916e-01,\n",
       "          -6.5131e-01, -3.3568e-01, -4.2717e-01],\n",
       "         [-2.0694e-01, -3.8299e-01, -3.5880e-01, -2.5959e-01, -1.3685e-01,\n",
       "           3.3959e-02,  5.1714e-01,  5.0149e-01],\n",
       "         [-1.0959e-01,  1.2136e-01, -8.4377e-01,  1.9433e-02, -7.5642e-01,\n",
       "           2.0120e-01,  5.3814e-01,  6.7135e-01],\n",
       "         [ 2.1148e-01,  2.5272e-01, -8.0080e-01, -6.6379e-01, -2.8547e-01,\n",
       "           1.1342e-01, -6.1835e-01, -2.6939e-01],\n",
       "         [-5.7616e-01,  5.5770e-01,  2.2561e-01, -4.1419e-01,  2.9555e-01,\n",
       "          -3.2157e-01, -1.9211e-02, -5.0737e-01],\n",
       "         [-3.9740e-01,  9.5004e-02, -4.4697e-02,  3.2251e-01,  3.6058e-01,\n",
       "           2.1366e-01, -4.4092e-01, -5.1126e-02],\n",
       "         [ 6.4047e-01, -3.5863e-04,  3.8538e-01, -6.6080e-01,  8.4513e-02,\n",
       "          -4.3819e-01, -6.5651e-01,  4.4106e-01],\n",
       "         [-8.3729e-01, -4.2938e-01,  2.7319e-01,  8.4573e-01, -1.7910e-01,\n",
       "           2.2771e-01,  6.2106e-01,  3.3628e-01],\n",
       "         [-5.5010e-01,  2.1760e-01,  6.0231e-03, -3.7408e-01, -5.1552e-01,\n",
       "          -4.0486e-01, -8.0313e-02,  4.9991e-01]]),\n",
       " 'net.layers.0.embeddings.embeddings.2.weight': Parameter containing:\n",
       " tensor([[ 0.6608,  0.3828,  0.0715,  0.4743,  0.9467, -0.4042, -0.6038,  0.5793],\n",
       "         [-0.0612,  0.0080, -0.6608, -0.2622, -0.1906,  0.0737, -0.0367, -0.2096],\n",
       "         [-0.0613, -0.0596, -0.1397, -0.1823,  0.0946,  0.4129,  0.4616,  0.0570],\n",
       "         [ 0.4553, -0.2540,  0.4839, -0.1264, -0.4109,  0.1005, -0.3238, -0.4464],\n",
       "         [ 0.2446,  0.1265, -0.3660,  0.3330, -0.4137,  0.0578,  0.2425, -0.6465],\n",
       "         [-0.1739,  0.7009,  0.7156,  0.1337,  0.4426, -0.7709,  0.0276, -0.0102],\n",
       "         [ 0.3795, -0.6475, -0.0967,  0.2992, -0.4874,  0.7064, -0.0865, -0.8072]]),\n",
       " 'net.layers.0.embeddings.embeddings.3.weight': Parameter containing:\n",
       " tensor([[-1.0307e-38,  5.6863e-38,  1.3083e-37, -1.1697e-37, -4.3280e-37,\n",
       "          -6.1806e-16,  1.2844e-12,  6.1162e-37],\n",
       "         [-1.9754e-01,  9.8726e-02,  9.4574e-01,  1.8982e-01, -2.6669e-01,\n",
       "          -1.2165e+00,  3.3451e-01, -4.1318e-02],\n",
       "         [ 4.7152e-01,  2.4193e-01, -2.0784e-02, -1.1080e+00, -5.6541e-01,\n",
       "          -1.0781e-01,  5.4607e-01,  2.7843e-01],\n",
       "         [ 3.9281e-01,  3.9180e-02, -2.5086e-01,  1.0118e+00,  2.0189e-02,\n",
       "           7.5169e-01, -1.0633e-01,  1.3392e-01],\n",
       "         [ 2.3112e-01,  2.1500e-01, -2.8654e-01,  1.2198e-01,  1.1343e-01,\n",
       "           7.2469e-01,  2.1169e-01, -4.4113e-02],\n",
       "         [-6.1595e-01,  1.4697e-01,  6.3444e-02, -4.7802e-01,  5.5114e-01,\n",
       "           1.2976e-01,  2.6681e-01,  7.6738e-01]]),\n",
       " 'net.layers.0.embeddings.embeddings.4.weight': Parameter containing:\n",
       " tensor([[ 1.3618e-01, -1.8195e-01,  2.1763e-01,  2.9006e-04, -1.0983e-01,\n",
       "           9.5374e-01,  8.8828e-01, -2.7143e-01]]),\n",
       " 'net.layers.0.embeddings.embeddings.5.weight': Parameter containing:\n",
       " tensor([[-6.9460e-37,  5.8971e-37, -4.8037e-41,  1.6891e-16, -1.4655e-37,\n",
       "           1.7127e-37,  2.9910e-15, -2.6226e-24],\n",
       "         [ 7.6857e-01, -4.5586e-01,  7.3561e-02,  9.7966e-01, -5.7258e-01,\n",
       "          -5.3602e-02,  2.7674e-01, -3.9850e-01],\n",
       "         [-2.7756e-01,  2.5624e-01, -1.1488e+00, -7.0115e-01, -1.5195e-01,\n",
       "          -1.9409e-01,  1.0869e+00,  9.1124e-02],\n",
       "         [ 6.9379e-01,  2.2495e-01,  7.4558e-01, -7.9139e-01, -8.2792e-01,\n",
       "          -1.9944e-01, -1.0485e+00,  1.3868e+00]]),\n",
       " 'net.layers.0.embeddings.embeddings.6.weight': Parameter containing:\n",
       " tensor([[-0.2413,  0.1284,  0.0037, -0.0816,  0.2464,  0.5616,  0.6795, -0.1006],\n",
       "         [ 0.0222, -0.7855, -0.0211, -0.2199, -0.1987, -0.5374,  0.5106,  0.3013],\n",
       "         [-0.1688,  1.3242,  0.7843,  0.1698, -0.3121, -0.9089,  0.4922, -1.0942],\n",
       "         [ 0.0239, -0.1377, -0.2940, -0.0451,  0.0362,  0.2306, -0.2560,  0.1016],\n",
       "         [ 0.3291, -0.0495,  0.3242,  0.1616, -0.1243, -0.0969,  0.5979, -0.0494],\n",
       "         [ 1.0816,  0.4916, -0.4460, -0.5293, -0.1079, -0.3923,  0.3422, -0.0344],\n",
       "         [-0.8146, -0.4814, -0.8073, -0.8589, -1.7223,  0.7144, -1.0766,  0.3380],\n",
       "         [-0.4894,  0.6819,  0.4576, -1.0043,  0.4201,  0.1259, -0.3841,  0.6140],\n",
       "         [-0.1321,  0.0510,  0.2373,  0.0292,  0.7752,  0.0834, -0.3249,  0.4005],\n",
       "         [-0.8666,  0.4070, -0.2442, -0.5267, -0.6530,  0.0758,  0.3668,  0.2747],\n",
       "         [-0.1379,  0.0351, -0.6636,  0.0691, -0.8350, -0.1817,  0.2017, -0.2158],\n",
       "         [ 0.3363,  0.5530,  0.8710,  0.2909,  0.9601, -0.6810,  0.3714,  0.5128],\n",
       "         [-0.1757,  0.0308, -0.1793, -0.2242, -0.1382,  0.1037, -0.1528, -0.0276],\n",
       "         [ 0.7769,  0.1083,  0.0385,  0.8766, -0.2536, -0.1284,  0.2989,  0.3563]]),\n",
       " 'net.layers.0.embeddings.embeddings.7.weight': Parameter containing:\n",
       " tensor([[-0.3831, -0.4169, -0.4428, -0.1510,  0.2282, -0.0667, -0.5584,  0.1191],\n",
       "         [-0.2802, -0.1744, -0.1539,  0.0575,  0.0026,  0.3624, -0.3464, -0.0626],\n",
       "         [ 0.0131,  0.2963, -0.1381,  0.2302, -0.3822,  0.2743, -0.1141, -0.0994],\n",
       "         [-0.7013,  0.5318,  0.4939, -0.2377,  0.3926,  0.2371,  0.4776,  0.0802],\n",
       "         [ 0.0450, -0.0245, -0.7132,  0.0357, -0.7897,  0.3641, -0.5876, -0.0212],\n",
       "         [-0.0416, -0.7332,  0.0334,  0.2584, -0.6165,  0.1971, -0.5438,  0.0716],\n",
       "         [-0.4723,  0.5654,  0.3618, -0.6227,  0.9729,  0.0349, -0.1327,  0.6978],\n",
       "         [ 0.0999, -0.3877,  0.1779,  0.4706, -0.4632, -0.2266,  0.6148, -0.3059],\n",
       "         [ 0.0262, -0.3809, -1.0266,  0.1099, -0.0987, -0.1246, -0.2548, -0.3345],\n",
       "         [ 0.4611, -0.4514,  0.1950,  0.3692, -0.0317, -0.6240,  0.3002, -0.4926],\n",
       "         [ 0.7806,  0.0408, -0.8322,  0.2131,  0.0719, -0.3996,  0.0612, -0.4567],\n",
       "         [ 0.3560, -0.0604, -0.1971, -0.5029,  0.6104,  0.3185, -0.0287,  0.1506],\n",
       "         [ 0.3948,  0.1358, -0.6924, -0.0508, -0.1562,  0.0299, -0.3302, -0.6646],\n",
       "         [ 0.3628, -0.6740,  0.4207,  0.0690, -0.6097,  0.9868, -1.0510, -0.6634],\n",
       "         [-0.4883,  1.1292,  0.3740,  0.0675,  0.4617, -0.6138,  0.3504,  0.4487],\n",
       "         [ 0.2615, -0.3776, -0.4519, -0.4168,  0.2798, -0.1662,  0.3122,  0.0571],\n",
       "         [ 0.6981, -0.3692, -0.2504,  0.1838, -0.0111, -0.3197, -0.3824, -0.8023],\n",
       "         [-0.3031,  0.1286,  0.2887, -0.4914,  0.5416, -0.1604,  0.0435,  0.3013],\n",
       "         [-0.8132,  0.2175, -0.0792, -0.1296,  0.4513,  0.0279, -0.3165,  0.1563],\n",
       "         [ 0.0203, -0.1471, -0.6696,  0.6428, -0.0872, -0.1789,  0.0263, -0.3440]]),\n",
       " 'net.layers.0.embeddings.embeddings.8.weight': Parameter containing:\n",
       " tensor([[-0.0887,  0.0170,  0.0787,  0.0677,  0.0756, -0.0773, -0.0963, -0.0482],\n",
       "         [ 0.0419, -0.1665, -0.3908,  0.0793, -0.3039,  0.0738,  0.0727, -0.0283],\n",
       "         [-0.0011,  0.1489,  0.1656,  0.0133, -0.0372, -0.1898, -0.0264,  0.0895],\n",
       "         [-0.2190, -0.7439, -0.1381,  0.2555,  0.0461,  0.1681,  0.2141,  0.0791],\n",
       "         [ 0.1159,  0.1202,  0.0080, -0.4905,  0.0407, -0.1019,  0.0962, -0.0536],\n",
       "         [-0.3728,  0.8235,  0.6007, -0.0352,  0.5079, -0.7777, -0.4698, -0.3093],\n",
       "         [-0.1261, -0.3202, -0.4856, -0.1554,  0.1413,  0.2780,  0.1156,  0.3592],\n",
       "         [-0.0191,  0.0695,  0.0480, -0.0247,  0.2341, -0.0353, -0.0913, -0.0529],\n",
       "         [ 0.3356,  0.1528, -0.0897, -0.0039, -0.0739,  0.1632,  0.3652, -0.0745],\n",
       "         [-0.3567, -0.2443, -0.3196,  0.0603, -0.2701,  0.2214, -0.2196,  0.5629],\n",
       "         [ 0.3753,  0.0369, -0.0829, -0.0962,  0.0412, -0.0087,  0.2009,  0.0116],\n",
       "         [ 0.1938,  0.4010, -0.2405, -0.1433, -0.1336,  0.4342,  0.1869,  0.1119],\n",
       "         [ 0.0010, -0.1381, -0.0301, -0.0407,  0.0045,  0.2324,  0.0015,  0.0239],\n",
       "         [ 0.2502, -0.0748, -0.0329, -0.2237, -0.0660,  0.1394,  0.0933,  0.0889],\n",
       "         [ 0.1725,  0.1875,  0.1636, -0.0098,  0.6621,  0.0621,  0.2414,  0.0727],\n",
       "         [-0.7369, -0.1966,  0.8105, -0.1380,  0.1937,  0.3890,  0.1746, -0.0463],\n",
       "         [ 0.1713,  0.0159, -0.1305, -0.1307, -0.1213, -0.1826,  0.0161,  0.2578],\n",
       "         [ 0.8933,  0.5469,  0.0242, -0.4879, -0.0253,  0.4660,  0.5605,  0.0847],\n",
       "         [ 0.0652, -0.0024, -0.0419, -0.0670, -0.0487,  0.2839, -0.0283,  0.0283],\n",
       "         [-0.0255,  0.1182,  0.0724, -0.0030,  0.0246,  0.0268, -0.0100, -0.2308]]),\n",
       " 'net.layers.0.embeddings.embeddings.9.weight': Parameter containing:\n",
       " tensor([[-0.3213,  0.5153, -0.1018,  0.0601,  0.0301,  0.3129,  0.0267,  0.3361],\n",
       "         [-0.1591,  0.4491, -0.1488, -0.3203,  0.2155,  0.0978, -0.4693,  0.3432],\n",
       "         [-0.2984,  0.2238,  0.1454, -0.1610,  0.0139, -0.1156,  0.0280,  0.1426],\n",
       "         [-0.4718,  1.0050, -0.6100, -0.7001,  0.7681,  0.3090, -0.1499,  0.3004],\n",
       "         [-0.3025, -0.3094, -0.1449,  0.7013, -0.2669,  0.0736, -0.1078, -0.5032],\n",
       "         [-0.2671, -0.2319,  0.0858, -0.0189,  0.3643,  0.5338,  0.0410, -0.4559],\n",
       "         [-0.0715, -0.2244, -0.1092,  0.5166,  0.0093,  0.0112, -0.0499,  0.3208],\n",
       "         [-0.7349, -0.0860, -0.2521, -0.3993, -0.1924,  0.6249, -0.0383, -0.6879],\n",
       "         [-0.1712,  0.4790, -0.4338, -0.0961, -0.0756,  0.5965, -0.2708,  0.3095],\n",
       "         [-0.4475,  0.0493,  0.2219, -0.7793,  0.2198, -0.2449, -0.5104,  0.2094],\n",
       "         [-0.2789,  0.4379, -0.1685,  0.4615,  0.4090, -0.1856,  0.6667, -0.3288],\n",
       "         [ 0.4492, -0.1214, -0.1666, -0.0107, -0.1517,  0.4920, -0.0994,  0.4554],\n",
       "         [-0.0350,  0.2706,  0.2295,  0.0117, -0.2074,  0.3779,  0.0185,  0.0496],\n",
       "         [ 0.1030,  0.3818, -0.2804, -0.0565, -0.0500,  0.3161, -0.4357,  0.1672],\n",
       "         [-0.2674,  0.3690, -0.1886, -0.2708, -0.0643, -0.0652,  0.3795,  0.1503],\n",
       "         [-0.2040,  0.5028, -0.1293, -0.1505,  0.4970, -0.0878, -0.0750,  0.0107],\n",
       "         [-0.7710,  0.5228, -0.0239, -0.1900,  0.9982,  0.5661, -0.4154, -0.3557],\n",
       "         [ 0.2565, -0.0655,  0.3542,  0.3906, -0.2783, -0.7857,  0.0610, -0.1003],\n",
       "         [ 0.2237,  0.4810,  0.0777,  0.0153, -0.3737, -0.0502, -0.0437, -0.1091],\n",
       "         [-0.1595,  0.4802,  0.4217, -0.0025,  0.2673, -0.4429,  0.1339, -0.0154]]),\n",
       " 'net.layers.0.embeddings.embeddings.10.weight': Parameter containing:\n",
       " tensor([[-0.1891,  0.2401,  0.6123, -0.1554, -0.1301,  0.7779,  0.3927, -0.3423],\n",
       "         [ 0.1212, -0.4372, -0.4910,  0.3850,  0.1452,  0.3034,  0.7498,  0.8975]]),\n",
       " 'net.layers.0.embeddings.embeddings.11.weight': Parameter containing:\n",
       " tensor([[-0.5760, -0.6169,  0.4271,  1.5180,  0.0122, -0.7530,  0.5248,  1.0505],\n",
       "         [ 0.0851, -0.4647, -0.3914, -0.0527,  0.4631,  0.4202,  0.0944, -0.2080]]),\n",
       " 'net.layers.0.embeddings.embeddings.12.weight': Parameter containing:\n",
       " tensor([[ 0.1376, -0.4114,  0.4250,  0.1801,  0.9097,  0.1948, -0.3582, -0.7290],\n",
       "         [-0.4982,  0.4025,  0.0877, -0.3788, -0.2560, -0.0104,  0.8675, -0.3599]]),\n",
       " 'net.layers.0.embeddings.embeddings.13.weight': Parameter containing:\n",
       " tensor([[-6.0072e-08,  2.3362e-04,  8.3390e-13, -1.0469e-03, -5.8885e-04,\n",
       "          -6.2651e-06, -6.6802e-05, -8.4885e-06],\n",
       "         [ 1.6027e-01,  3.5757e-01, -8.9040e-03,  2.7691e-01,  3.8958e-01,\n",
       "           4.3144e-01,  4.1128e-01,  4.9539e-01],\n",
       "         [ 3.1289e-01, -1.0793e-01, -7.5482e-02,  1.3855e-01,  8.3097e-02,\n",
       "          -4.7159e-01,  2.8731e-01, -5.9911e-02],\n",
       "         [ 1.6580e-01,  5.6175e-01, -1.1814e+00,  8.2343e-02, -1.6861e-01,\n",
       "          -1.1163e-01, -1.0191e+00, -1.0704e-01],\n",
       "         [ 3.2897e-02, -1.4383e-01, -6.9260e-01, -1.3416e-01,  2.6739e-01,\n",
       "           4.0858e-01, -4.7624e-01, -2.0612e-01],\n",
       "         [-1.3136e-01, -1.2645e-01,  2.6186e-01, -1.0437e-01, -7.9133e-02,\n",
       "           2.8178e-01,  3.5988e-01,  9.6962e-02],\n",
       "         [ 2.0276e-01,  1.9968e-02,  7.0914e-02, -1.8071e-01, -2.8233e-01,\n",
       "           9.3903e-01, -6.8328e-02, -8.4316e-03]]),\n",
       " 'net.layers.0.embeddings.embeddings.14.weight': Parameter containing:\n",
       " tensor([[-0.1353, -0.6455, -0.1610,  0.1535,  0.0486, -0.1417,  0.4860,  0.6765],\n",
       "         [-0.7442,  0.1611,  0.4347, -0.5585,  0.2298,  0.2902,  0.0047, -0.3423],\n",
       "         [ 0.4194, -0.1868, -0.3656, -0.5380,  0.0782, -0.2336, -0.2759, -0.1146],\n",
       "         [ 0.0030,  0.2495,  0.3349,  0.3881,  0.4534,  0.6536,  0.1641,  0.1043],\n",
       "         [ 0.1121, -0.1445, -0.3760, -1.1398, -0.4515, -0.3297, -0.6497,  0.3621],\n",
       "         [ 0.3684,  0.0864, -0.2460,  0.3889,  0.3454, -0.2345, -0.2668, -0.6077],\n",
       "         [-0.0304,  0.0534,  0.1391,  0.1652,  0.0433, -0.0218, -0.3206, -0.3333]]),\n",
       " 'net.layers.0.embeddings.embeddings.15.weight': Parameter containing:\n",
       " tensor([[-0.1895,  0.3512, -0.3661,  0.0062,  0.2483,  0.5834,  0.2658, -1.7934],\n",
       "         [-0.6979,  0.1805, -1.1045,  0.1074, -0.5061,  1.1015,  0.6865, -0.0029],\n",
       "         [ 0.1658,  0.1043, -0.4313, -1.1367,  0.2264,  0.4805, -0.0635, -1.0172],\n",
       "         [ 0.4902, -0.2647,  0.2869,  1.0406, -0.4891, -0.4472, -0.2855, -0.2732],\n",
       "         [ 0.0246, -0.5862, -0.0483,  0.8256,  0.4503,  0.0913,  0.0567,  0.3148],\n",
       "         [-0.8464,  0.9901,  0.4946,  0.3443, -0.0529, -0.1688, -0.4665,  1.1000]]),\n",
       " 'net.layers.0.embeddings.embeddings.16.weight': Parameter containing:\n",
       " tensor([[ 1.6203e-37, -6.0786e-37,  2.8775e-26, -6.3934e-37,  7.8445e-15,\n",
       "           2.4013e-18, -1.2605e-37, -3.0099e-07],\n",
       "         [ 1.5572e-01, -7.1458e-01, -9.2235e-01,  6.4094e-01, -4.9816e-01,\n",
       "          -9.8599e-02, -3.7303e-01, -3.2612e-01],\n",
       "         [-7.1664e-01,  1.5654e-01,  6.4631e-02, -7.0614e-01,  5.4036e-01,\n",
       "           7.4472e-02, -1.1542e+00, -3.8993e-02],\n",
       "         [ 1.7894e-01,  3.1493e-01, -3.4817e-01, -6.3263e-01,  3.3546e-02,\n",
       "          -5.2596e-01,  1.0314e+00,  3.4716e-01],\n",
       "         [ 5.1263e-02, -1.1011e+00,  1.6123e-01,  2.5478e-01, -1.8900e-01,\n",
       "          -9.6235e-02,  8.0228e-01,  6.7749e-01]]),\n",
       " 'net.layers.0.embeddings.embeddings.17.weight': Parameter containing:\n",
       " tensor([[ 4.3539e-01,  3.4163e-01,  8.9343e-01,  2.1335e-01, -2.1181e-01,\n",
       "           4.4179e-02, -1.4050e-01,  9.3238e-02],\n",
       "         [-2.5339e-01,  5.0645e-01, -1.4207e-01,  3.7112e-01, -7.7007e-02,\n",
       "           2.7463e-01, -6.4376e-01, -2.6677e-02],\n",
       "         [ 2.9055e-01,  5.0680e-02, -2.9195e-01, -4.4720e-01, -7.3568e-01,\n",
       "           2.1418e-01, -1.3449e-01, -1.0054e-01],\n",
       "         [ 4.1167e-01,  5.1290e-02,  3.0616e-01,  3.9143e-01, -4.0894e-01,\n",
       "          -1.9080e-02, -4.4146e-01, -5.6574e-01],\n",
       "         [-1.4218e-01, -2.8339e-01, -4.2854e-01,  3.8817e-04,  6.4396e-02,\n",
       "          -6.2242e-02,  1.5361e-01,  4.0618e-01],\n",
       "         [ 2.6432e-01,  2.0742e-01,  2.3468e-01, -4.4556e-01,  4.0000e-02,\n",
       "          -3.7557e-01,  1.7160e-01,  5.3973e-01],\n",
       "         [-6.5461e-01, -6.9751e-01, -9.7789e-02,  3.5048e-02,  3.8629e-01,\n",
       "           7.2590e-01, -5.6016e-02,  9.6905e-01],\n",
       "         [-6.1588e-01,  7.7564e-01, -1.6748e-01,  8.5528e-01, -3.2732e-01,\n",
       "           4.4020e-01, -1.9385e-01, -7.3765e-01],\n",
       "         [ 6.3634e-02, -1.7160e-02,  1.7056e-02, -4.3382e-01, -2.3687e-01,\n",
       "          -5.1957e-01,  2.6780e-01,  9.9234e-01],\n",
       "         [ 5.4904e-01, -6.0352e-01, -4.0018e-01, -3.8817e-01, -5.4633e-01,\n",
       "           7.9012e-01,  8.2668e-02,  1.0462e-01],\n",
       "         [ 8.6447e-01, -7.6857e-01, -1.3896e-02,  2.4954e-01, -2.8747e-01,\n",
       "          -5.0881e-01,  5.1559e-01, -1.2843e-02],\n",
       "         [-1.1647e-01,  2.0484e-01, -3.5006e-01, -4.0192e-01, -1.7167e-01,\n",
       "          -4.0066e-01, -2.9514e-02,  7.1507e-01],\n",
       "         [ 2.8056e-01, -6.5353e-02, -8.9366e-01,  1.7662e-01,  4.5346e-01,\n",
       "          -2.3570e-01,  1.2821e-01, -2.7469e-01],\n",
       "         [-5.9398e-02, -2.4007e-01, -3.4979e-01, -2.5347e-01, -4.7828e-01,\n",
       "          -1.7809e-01,  3.7143e-01,  5.2174e-01],\n",
       "         [-3.0315e-01, -6.1225e-01,  8.2811e-01,  4.0402e-01,  4.3790e-01,\n",
       "          -2.2718e-01,  4.5417e-01,  2.1983e-02],\n",
       "         [-2.1968e-01, -9.7699e-01,  7.2826e-02,  2.8257e-01,  1.8036e-01,\n",
       "           3.2361e-01,  9.2294e-01, -5.5877e-01],\n",
       "         [-3.9790e-01, -1.3958e-01,  4.9135e-01, -6.1779e-02, -4.6985e-01,\n",
       "           1.9947e-01,  8.3648e-02, -3.4447e-01],\n",
       "         [ 4.7954e-01,  3.5575e-01, -1.7876e-01, -9.8665e-02,  5.3181e-03,\n",
       "           3.7279e-01,  6.9046e-02,  1.3126e-01]]),\n",
       " 'net.layers.0.embeddings.embeddings.18.weight': Parameter containing:\n",
       " tensor([[-0.0549,  0.3557, -0.3752,  0.0790, -0.1296,  0.1875, -0.0361, -0.1924],\n",
       "         [-0.5485, -0.4588,  0.4104,  0.0770,  0.7058, -0.4511,  0.1482, -0.4598],\n",
       "         [ 0.6910, -0.0158, -0.0235,  0.0466, -0.7259,  0.2444, -0.3894,  0.7420],\n",
       "         [-0.8548, -0.2296,  0.1978, -0.2134, -0.0438, -0.1481,  0.0615,  0.1818],\n",
       "         [ 0.4070,  0.3224, -0.1304,  0.5145, -0.3644,  0.0499, -0.4189, -0.8215],\n",
       "         [-0.4851,  0.2049,  0.0790,  0.4298, -0.5386, -0.4876,  0.2717,  0.1191],\n",
       "         [-0.1082,  0.5287,  0.1941, -0.1939, -0.3707,  0.5616, -0.1148,  0.3887],\n",
       "         [-0.1413, -0.1806,  0.7639,  0.2811,  0.5759,  0.0979,  0.3890, -0.4435],\n",
       "         [-0.0275, -0.0221, -0.6424, -0.4822, -0.2432, -0.0957,  0.0827, -0.2710],\n",
       "         [ 0.0867, -0.0937, -0.4486, -0.3780,  0.1472,  0.0607, -0.5104,  0.2844],\n",
       "         [-0.2980,  0.1437, -0.2575,  0.0655, -0.1744, -0.4496,  0.6490, -0.1050],\n",
       "         [-0.0389, -0.3472,  0.0728, -0.3594,  0.0991, -0.5701, -0.6624, -0.6770],\n",
       "         [-0.4006, -0.4330,  0.0789, -0.2948,  0.0383,  0.1184, -0.2945,  0.3538],\n",
       "         [ 0.6115, -0.3334,  0.2896,  0.0479,  0.4364,  0.1239, -0.4277,  0.2253],\n",
       "         [ 0.2127, -0.2855,  0.1152,  0.1721,  0.1543, -0.0668, -0.4994, -0.2221],\n",
       "         [-0.1723, -0.0629,  0.1204,  0.5192,  0.1148, -0.5376,  0.4710,  0.7193],\n",
       "         [ 0.4769, -0.0566, -0.5287, -0.1655,  0.4982, -0.6181, -0.3408,  0.1398]]),\n",
       " 'net.layers.0.out_linear_block.weight': Parameter containing:\n",
       " tensor([[-0.0180,  0.0209, -0.0287,  ...,  0.0361, -0.0553,  0.0406],\n",
       "         [-0.0255, -0.0080, -0.0378,  ...,  0.0333, -0.0747,  0.0360],\n",
       "         [ 0.0002, -0.0062, -0.0031,  ..., -0.0703,  0.0235,  0.0046],\n",
       "         ...,\n",
       "         [ 0.0735,  0.0225,  0.0532,  ..., -0.1285,  0.0714,  0.1155],\n",
       "         [-0.0032,  0.0125,  0.0189,  ..., -0.0300,  0.1586, -0.0604],\n",
       "         [ 0.0132, -0.0121,  0.0581,  ..., -0.0417, -0.0724, -0.0736]]),\n",
       " 'net.layers.0.out_linear_block.bias': Parameter containing:\n",
       " tensor([-0.0397, -0.0874, -0.0478,  0.0162, -0.0749, -0.0132,  0.0528,  0.0234,\n",
       "          0.0089,  0.0588,  0.1218, -0.0620,  0.0212,  0.0846, -0.1005, -0.0398,\n",
       "          0.0591, -0.0231,  0.0337, -0.0832,  0.0659, -0.0164, -0.0561, -0.0477,\n",
       "          0.0525,  0.1063,  0.0805,  0.0162, -0.0567, -0.1046, -0.0704,  0.0157]),\n",
       " 'net.layers.0.num_bn.weight': Parameter containing:\n",
       " tensor([0.9007, 0.9247, 0.8880, 0.9454, 0.8057, 1.2055]),\n",
       " 'net.layers.0.num_bn.bias': Parameter containing:\n",
       " tensor([-0.1994, -0.2414, -0.2604, -0.0786, -0.1908, -0.1913]),\n",
       " 'net.layers.1.position_wise_layer.0.weight': Parameter containing:\n",
       " tensor([[-0.0898, -0.1443, -0.0776,  ..., -0.1566, -0.0926, -0.0913],\n",
       "         [-0.1884,  0.0630, -0.0407,  ...,  0.1368, -0.0161,  0.1441],\n",
       "         [-0.0139, -0.1241,  0.1603,  ...,  0.0809, -0.1675,  0.0091],\n",
       "         ...,\n",
       "         [-0.1136, -0.0003,  0.1104,  ...,  0.0535,  0.2096, -0.0023],\n",
       "         [ 0.1302,  0.1176,  0.2322,  ...,  0.1465,  0.0769,  0.0855],\n",
       "         [-0.1827, -0.1797,  0.0293,  ..., -0.1256, -0.1043,  0.0998]]),\n",
       " 'net.layers.1.position_wise_layer.0.bias': Parameter containing:\n",
       " tensor([ 0.0497, -0.0881, -0.0402,  0.0433, -0.1759, -0.0909, -0.0711, -0.0167,\n",
       "         -0.1448, -0.0933,  0.0224, -0.1780, -0.0223, -0.1625, -0.2358, -0.1808,\n",
       "          0.1166, -0.1606,  0.0907, -0.0616, -0.1796, -0.2069,  0.1143, -0.1865,\n",
       "         -0.1275,  0.0138, -0.1726, -0.0260,  0.0649, -0.1251,  0.0074,  0.0437,\n",
       "          0.0822, -0.0094,  0.0043,  0.0878, -0.1825, -0.1465,  0.0906, -0.1362,\n",
       "         -0.0498, -0.0647, -0.0636, -0.0909,  0.0214, -0.1539, -0.0549, -0.0312,\n",
       "         -0.1184, -0.2282, -0.2838, -0.0478, -0.0774,  0.0728, -0.1735,  0.0810,\n",
       "          0.0552,  0.0416, -0.1570, -0.0187,  0.1729,  0.0331, -0.0244, -0.0423]),\n",
       " 'net.layers.1.position_wise_layer.2.weight': Parameter containing:\n",
       " tensor([[ 0.1334,  0.1508,  0.0824,  ..., -0.0050, -0.0555, -0.0422],\n",
       "         [-0.0663, -0.0693, -0.0681,  ..., -0.0699, -0.0976,  0.0959],\n",
       "         [-0.0852, -0.0285,  0.0880,  ..., -0.0385, -0.0404, -0.2013],\n",
       "         ...,\n",
       "         [ 0.0231,  0.0985, -0.0376,  ...,  0.1101,  0.0562, -0.1266],\n",
       "         [-0.0277,  0.1610, -0.0322,  ..., -0.0507, -0.0140, -0.0829],\n",
       "         [ 0.0003,  0.0370,  0.0965,  ...,  0.0058, -0.0417,  0.0155]]),\n",
       " 'net.layers.1.position_wise_layer.2.bias': Parameter containing:\n",
       " tensor([ 0.0176,  0.0611, -0.0404, -0.0976,  0.0564, -0.1150, -0.0684,  0.1453,\n",
       "         -0.1264, -0.0260, -0.0103, -0.0017, -0.0003,  0.1086,  0.0516, -0.0916,\n",
       "          0.1189,  0.1206, -0.0276,  0.1009, -0.0312,  0.0612,  0.0537,  0.0436,\n",
       "         -0.0360, -0.0267, -0.0624, -0.0562,  0.0144, -0.0406, -0.0380,  0.0160]),\n",
       " 'net.layers.1.layer_norm.weight': Parameter containing:\n",
       " tensor([1.0268, 1.0857, 0.9313, 1.0373, 0.8841, 0.9817, 0.9772, 0.9801, 0.9052,\n",
       "         0.9523, 0.9848, 0.9749, 0.9732, 0.9731, 0.9676, 0.9902, 1.1238, 0.9981,\n",
       "         0.8287, 0.9608, 0.9791, 0.8742, 0.9073, 0.9014, 0.9727, 0.9736, 0.9590,\n",
       "         0.8445, 0.9091, 1.0826, 0.9626, 1.0928]),\n",
       " 'net.layers.1.layer_norm.bias': Parameter containing:\n",
       " tensor([ 3.0717e-02, -2.7414e-02,  6.9915e-02,  4.9484e-05, -2.6491e-02,\n",
       "          2.4890e-02,  3.7044e-04,  1.2504e-02,  3.0295e-02, -5.2074e-02,\n",
       "         -3.3098e-02,  4.1176e-02,  7.5433e-02,  1.8818e-02,  1.1207e-02,\n",
       "          2.5477e-02, -2.1186e-02, -2.0661e-02,  4.1460e-03,  8.1063e-03,\n",
       "          1.9449e-02, -1.1387e-03,  5.7350e-03, -1.3789e-04,  4.9138e-02,\n",
       "         -4.0924e-02, -1.9845e-02, -6.0532e-02,  8.6678e-04,  1.0556e-03,\n",
       "          2.0784e-02,  2.8078e-02]),\n",
       " 'net.layers.2.gru.weight_ih_l0': Parameter containing:\n",
       " tensor([[ 0.0641, -0.0320,  0.0253,  ...,  0.1477,  0.1248,  0.1878],\n",
       "         [-0.0305, -0.0604,  0.0616,  ..., -0.1363, -0.0322,  0.0153],\n",
       "         [-0.0580, -0.1045, -0.0354,  ...,  0.3431,  0.2326, -0.1190],\n",
       "         ...,\n",
       "         [ 0.0428, -0.0848,  0.1358,  ...,  0.0890,  0.0801,  0.1203],\n",
       "         [-0.1012, -0.0637, -0.0695,  ...,  0.1512, -0.0324,  0.1003],\n",
       "         [ 0.1605, -0.2403,  0.0643,  ...,  0.2116,  0.0329,  0.0674]]),\n",
       " 'net.layers.2.gru.weight_hh_l0': Parameter containing:\n",
       " tensor([[ 0.1252, -0.0832, -0.0551,  ...,  0.0469,  0.2503,  0.1052],\n",
       "         [-0.0457,  0.0952,  0.1296,  ...,  0.1408,  0.0984, -0.0053],\n",
       "         [-0.0437,  0.0212,  0.1516,  ...,  0.0363, -0.0067, -0.0554],\n",
       "         ...,\n",
       "         [ 0.0980, -0.1581,  0.0090,  ..., -0.1855,  0.0437, -0.1293],\n",
       "         [ 0.0794,  0.1149, -0.1771,  ..., -0.1339, -0.1018,  0.0516],\n",
       "         [ 0.0841,  0.0382, -0.0077,  ...,  0.1389, -0.1262, -0.0472]]),\n",
       " 'net.layers.2.gru.bias_ih_l0': Parameter containing:\n",
       " tensor([ 0.0182,  0.0426, -0.1152, -0.0699,  0.1286, -0.1811, -0.0333, -0.1298,\n",
       "          0.0171, -0.0622,  0.1290, -0.0965,  0.0953, -0.0862, -0.1125, -0.0477,\n",
       "         -0.1179,  0.0624,  0.2178,  0.0350,  0.0528, -0.0082, -0.1448, -0.0979,\n",
       "          0.1778,  0.2542, -0.1884, -0.0853, -0.1801, -0.1076,  0.1513,  0.0818,\n",
       "         -0.1960, -0.0517,  0.1168, -0.0636,  0.0999, -0.0528, -0.0757,  0.0003,\n",
       "          0.0554,  0.0637,  0.0136,  0.2018,  0.1753, -0.0011, -0.1860, -0.0770,\n",
       "         -0.0972, -0.1346, -0.0228,  0.0040, -0.0350,  0.0919,  0.1336,  0.0096,\n",
       "         -0.1066,  0.0775, -0.1105,  0.0823,  0.0037,  0.1789,  0.0945,  0.0589,\n",
       "         -0.1526,  0.2496, -0.1363,  0.0080,  0.0623,  0.1137,  0.1313,  0.1089,\n",
       "         -0.1071,  0.0613,  0.0477, -0.1502, -0.0930,  0.0912, -0.1227,  0.0492,\n",
       "         -0.0967,  0.1799,  0.0211, -0.1046,  0.0644, -0.1126,  0.0364,  0.1003,\n",
       "          0.0926,  0.0706, -0.0485, -0.0545,  0.0167, -0.1726,  0.0382,  0.0311]),\n",
       " 'net.layers.2.gru.bias_hh_l0': Parameter containing:\n",
       " tensor([-0.2026,  0.0376,  0.0675, -0.1831,  0.1923,  0.1047, -0.0090,  0.1654,\n",
       "         -0.1057,  0.0570,  0.0994,  0.0672, -0.0136, -0.0071, -0.1924,  0.2321,\n",
       "         -0.0896, -0.0152,  0.0357, -0.0010,  0.0693, -0.1082,  0.0421, -0.2020,\n",
       "          0.0393,  0.0931, -0.0194, -0.0151,  0.1245,  0.1126,  0.1242, -0.1788,\n",
       "         -0.0333, -0.0191,  0.0204, -0.0640, -0.0191, -0.0479,  0.1350,  0.0283,\n",
       "         -0.0947,  0.1139, -0.0541,  0.0823,  0.1690, -0.0309, -0.2586,  0.0573,\n",
       "         -0.0655,  0.1126,  0.0958, -0.0321, -0.1529,  0.1671,  0.0793, -0.0886,\n",
       "         -0.1549,  0.1073,  0.1566,  0.1232,  0.0460, -0.0676, -0.0580, -0.0866,\n",
       "         -0.0350,  0.1547, -0.0133,  0.1254, -0.0074,  0.0473,  0.1020, -0.0492,\n",
       "         -0.0014, -0.1628,  0.0419, -0.0373,  0.1198,  0.0648, -0.1506, -0.1495,\n",
       "         -0.1252,  0.0801,  0.0428,  0.0839, -0.1411,  0.0075, -0.0864, -0.1257,\n",
       "         -0.0532, -0.1148, -0.0174,  0.0084,  0.0047,  0.0068, -0.0930,  0.0497]),\n",
       " 'net.layers.3.agg_layer.weight': Parameter containing:\n",
       " tensor([[[ 0.0043,  0.2484, -0.1597],\n",
       "          [ 0.1646,  0.0241,  0.2101],\n",
       "          [ 0.1220,  0.1829,  0.3189]]]),\n",
       " 'net.layers.4.heads.0.linear_block.0.0.weight': Parameter containing:\n",
       " tensor([[-0.2124, -0.1738,  0.0606,  0.3558,  0.2000, -0.2629,  0.1284,  0.4022,\n",
       "           0.4317,  0.3059, -0.5277,  0.3435,  0.0983, -0.2995, -0.1152,  0.2583,\n",
       "           0.1792,  0.2158, -0.1293, -0.2302, -0.0500,  0.0146, -0.0208,  0.4554,\n",
       "          -0.2079, -0.5258, -0.0102,  0.0412,  0.1117,  0.2160,  0.1763,  0.2738],\n",
       "         [-0.2780, -0.0870, -0.0108, -0.2906, -0.0060,  0.0349, -0.3999, -0.0700,\n",
       "           0.3480, -0.0381,  0.1043, -0.2678,  0.1311, -0.5006, -0.0639, -0.1828,\n",
       "          -0.0644,  0.5551, -0.2088,  0.5612, -0.4323,  0.4973,  0.2037, -0.4380,\n",
       "          -0.0159, -0.4176,  0.0629,  0.1088,  0.5038,  0.4842,  0.0735, -0.1471],\n",
       "         [ 0.1281,  0.3320,  0.0571, -0.3767,  0.0023, -0.0282,  0.0263,  0.4732,\n",
       "          -0.2240, -0.0960, -0.2471,  0.0353, -0.0875,  0.1641,  0.4672, -0.4446,\n",
       "          -0.4008, -0.1283,  0.1861, -0.1658,  0.1691,  0.1299, -0.1950, -0.2108,\n",
       "           0.3001, -0.1613, -0.0417, -0.0865,  0.4109, -0.4541, -0.4589, -0.2309],\n",
       "         [-0.0187,  0.1639, -0.1142, -0.4457, -0.3123, -0.1266,  0.0173,  0.1374,\n",
       "           0.4733,  0.4250, -0.3774,  0.1169, -0.0336, -0.1072, -0.0722, -0.0617,\n",
       "           0.0462,  0.5896, -0.2964, -0.2145,  0.4392,  0.2613,  0.3691,  0.3443,\n",
       "           0.0736,  0.5139, -0.1659,  0.4853,  0.2025, -0.0507,  0.0220, -0.2582],\n",
       "         [ 0.1786, -0.0938,  0.3968, -0.2059, -0.0451, -0.0701, -0.3632, -0.4442,\n",
       "          -0.2435, -0.4445, -0.3260, -0.3669,  0.3480, -0.4940, -0.2186,  0.2794,\n",
       "          -0.4696, -0.1340,  0.0889,  0.3186, -0.0245, -0.2973,  0.3898, -0.3912,\n",
       "           0.3120,  0.3733, -0.0429, -0.5304,  0.0496, -0.0762,  0.1489,  0.2959],\n",
       "         [ 0.1441,  0.2465, -0.2794,  0.5298,  0.1818, -0.4208, -0.2333,  0.2303,\n",
       "          -0.2726,  0.0357,  0.4593,  0.3748,  0.1910,  0.5283,  0.4029, -0.2348,\n",
       "          -0.2271,  0.0350,  0.0498, -0.0704, -0.4248,  0.2213, -0.3331, -0.4643,\n",
       "           0.3163,  0.3623, -0.2025,  0.1500,  0.2379,  0.4059,  0.4125,  0.2971],\n",
       "         [ 0.2135,  0.1148,  0.0411, -0.4213,  0.1475,  0.2535, -0.3928, -0.1510,\n",
       "          -0.4573, -0.4600, -0.2478, -0.0338, -0.3964, -0.2728, -0.3017,  0.2831,\n",
       "           0.2473,  0.4607,  0.3263, -0.3431,  0.1516, -0.4060, -0.3365, -0.1539,\n",
       "          -0.1442,  0.1935, -0.0102,  0.4599,  0.1750, -0.2095,  0.3673,  0.2765],\n",
       "         [-0.1604,  0.2186,  0.2285,  0.4997, -0.2969,  0.1255, -0.4738,  0.0634,\n",
       "          -0.3871,  0.1468, -0.2154,  0.3085, -0.1898,  0.4191, -0.0633, -0.0327,\n",
       "          -0.0627, -0.4328,  0.3827,  0.3538,  0.3542,  0.1247, -0.0747, -0.2172,\n",
       "           0.1713, -0.3972,  0.0620,  0.3712,  0.2977, -0.2696,  0.4406, -0.4652],\n",
       "         [-0.3796,  0.1601, -0.5405,  0.1957, -0.2561,  0.3361,  0.0348, -0.4152,\n",
       "          -0.3202,  0.0351,  0.2156, -0.3202,  0.2278,  0.2326,  0.0011, -0.2128,\n",
       "          -0.4363, -0.4330, -0.0020,  0.2960, -0.0228, -0.2841,  0.0481,  0.2626,\n",
       "           0.3094,  0.3751, -0.3658,  0.2223, -0.0226, -0.0377,  0.3559, -0.1261],\n",
       "         [-0.2336,  0.3778, -0.0890, -0.3293,  0.4204, -0.2637, -0.3938,  0.3022,\n",
       "           0.3845, -0.2236, -0.2328, -0.4345, -0.1588, -0.3239,  0.5580, -0.1468,\n",
       "          -0.2124,  0.3579,  0.0779, -0.2371,  0.3244, -0.0826, -0.2746,  0.5241,\n",
       "           0.4663, -0.0754,  0.2642, -0.4266,  0.0605,  0.0082, -0.4343,  0.2463],\n",
       "         [-0.5899,  0.0479,  0.4076,  0.1428,  0.1046,  0.2194,  0.5341,  0.2373,\n",
       "          -0.3444,  0.1540,  0.2242,  0.1249,  0.0477,  0.3803, -0.0819,  0.4619,\n",
       "          -0.1376, -0.2556,  0.0673,  0.1680, -0.0995,  0.3847, -0.4767,  0.3726,\n",
       "          -0.2821, -0.4039,  0.3756,  0.2540, -0.0969,  0.0664,  0.1000,  0.2428],\n",
       "         [ 0.3476,  0.4543, -0.0526,  0.4526,  0.1550, -0.3160, -0.0622, -0.3306,\n",
       "           0.2825, -0.0210,  0.2212, -0.3897,  0.0298, -0.3216,  0.1069,  0.3214,\n",
       "          -0.1120,  0.5427, -0.1638,  0.5077, -0.2618,  0.3641, -0.4408, -0.4186,\n",
       "          -0.4167, -0.3538,  0.2686, -0.1232, -0.1253, -0.0682, -0.3008,  0.1853],\n",
       "         [-0.1483,  0.0956,  0.3471,  0.3535,  0.4236, -0.0479,  0.0085,  0.4106,\n",
       "          -0.4218, -0.3240,  0.3817,  0.1092,  0.1328,  0.1122, -0.0441,  0.4131,\n",
       "           0.5023,  0.2269, -0.1586, -0.2234, -0.0351,  0.0660, -0.3250,  0.1700,\n",
       "           0.4266,  0.4552, -0.1254, -0.0750,  0.0112, -0.0035,  0.0586,  0.1545],\n",
       "         [-0.2952,  0.2970, -0.4292, -0.1713,  0.3671,  0.4048, -0.2157,  0.1894,\n",
       "           0.4727,  0.1699, -0.0949,  0.3091,  0.4019, -0.2228,  0.1038,  0.3209,\n",
       "          -0.3126, -0.2467, -0.1849, -0.0533, -0.0695, -0.1582,  0.4109,  0.4492,\n",
       "           0.1504, -0.5032,  0.1065, -0.4633, -0.4752, -0.0800,  0.1498, -0.3362],\n",
       "         [-0.2413, -0.2629, -0.1804, -0.1968,  0.2745, -0.1584,  0.0912, -0.1650,\n",
       "          -0.1015,  0.4338, -0.2942, -0.1950, -0.3209, -0.5143,  0.1098,  0.4244,\n",
       "          -0.2654, -0.0199,  0.2046, -0.2862,  0.4878, -0.4456, -0.2567,  0.2776,\n",
       "           0.2393, -0.0412, -0.1154, -0.3646,  0.1043, -0.3034,  0.1689,  0.4576],\n",
       "         [-0.5464, -0.0460,  0.0049,  0.0637, -0.3368, -0.4549,  0.3593, -0.1827,\n",
       "           0.4533, -0.1314,  0.3590, -0.3934, -0.4090,  0.1727, -0.3831, -0.0061,\n",
       "          -0.3776, -0.0593, -0.4302,  0.2666, -0.5334, -0.1446, -0.2606,  0.2546,\n",
       "           0.4435, -0.4288, -0.0832,  0.2300,  0.2415,  0.2468, -0.3642, -0.0154]]),\n",
       " 'net.layers.4.heads.0.linear_block.0.0.bias': Parameter containing:\n",
       " tensor([ 0.0143,  0.0114, -0.0391, -0.0602, -0.0634,  0.0209,  0.0366,  0.0187,\n",
       "         -0.0722,  0.0398,  0.1127, -0.0019, -0.0597,  0.0062, -0.0919,  0.0257]),\n",
       " 'net.layers.4.heads.0.linear_block.0.2.weight': Parameter containing:\n",
       " tensor([0.8730, 1.0432, 1.0400, 0.8886, 0.9895, 0.9508, 1.0054, 0.9488, 0.8833,\n",
       "         0.9736, 1.0425, 0.9900, 0.8869, 1.0556, 1.0102, 0.8849]),\n",
       " 'net.layers.4.heads.0.linear_block.0.2.bias': Parameter containing:\n",
       " tensor([-0.0393, -0.0223, -0.0113, -0.0462, -0.0223, -0.0120,  0.0026, -0.0168,\n",
       "         -0.0585,  0.0176,  0.0374, -0.0096, -0.0436, -0.0202, -0.0504,  0.0078]),\n",
       " 'net.layers.4.heads.0.linear_block.1.0.weight': Parameter containing:\n",
       " tensor([[-0.3166,  0.0973,  0.6656,  0.5064,  0.1783,  0.5528, -0.4960,  0.6029,\n",
       "           0.0443,  0.1628, -0.5169,  0.1280,  0.4964,  0.2515,  0.5787, -0.3217],\n",
       "         [ 0.2940, -0.4714,  0.6931, -0.1047,  0.2046, -0.5082, -0.3708, -0.2665,\n",
       "           0.3916, -0.1111, -0.5787, -0.2939,  0.1932,  0.0037, -0.2871,  0.1056],\n",
       "         [-0.0866,  0.0116,  0.3738,  0.5510, -0.3977,  0.5233, -0.0264, -0.5678,\n",
       "           0.5173, -0.6758, -0.6167,  0.6716,  0.5679, -0.1012, -0.4026, -0.6170],\n",
       "         [-0.4246, -0.1881, -0.1869,  0.3188, -0.1345,  0.2172, -0.4782,  0.4276,\n",
       "          -0.6815,  0.1803,  0.2713, -0.3107,  0.4826, -0.6422, -0.2912,  0.3323],\n",
       "         [-0.1659, -0.3984,  0.6463, -0.1486,  0.1964,  0.3450, -0.4135,  0.6210,\n",
       "          -0.3450,  0.5348,  0.4681, -0.4821, -0.6626,  0.6016, -0.3119, -0.4986],\n",
       "         [-0.1029,  0.0285, -0.8009, -0.1304, -0.5691,  0.1518,  0.6123,  0.0990,\n",
       "          -0.3911, -0.5219,  0.7726,  0.3208,  0.4287,  0.0877,  0.2784, -0.0070],\n",
       "         [ 0.1238,  0.0200, -0.0661, -0.1776,  0.7180, -0.6390,  0.2812,  0.4800,\n",
       "           0.3603,  0.4731, -0.3718, -0.5741, -0.0473,  0.0339,  0.2466,  0.5549],\n",
       "         [ 0.3706, -0.1776, -0.6062, -0.5569,  0.6383, -0.7115,  0.3974, -0.3920,\n",
       "          -0.3417, -0.1982,  0.3647, -0.3257, -0.3809,  0.3811,  0.1942, -0.6701]]),\n",
       " 'net.layers.4.heads.0.linear_block.1.0.bias': Parameter containing:\n",
       " tensor([-0.0345, -0.0003, -0.0148,  0.0483,  0.0108,  0.0391, -0.0466, -0.0256]),\n",
       " 'net.layers.4.heads.0.linear_block.1.2.weight': Parameter containing:\n",
       " tensor([0.9994, 0.9860, 0.9058, 0.9907, 1.0222, 1.0271, 1.0099, 1.0466]),\n",
       " 'net.layers.4.heads.0.linear_block.1.2.bias': Parameter containing:\n",
       " tensor([ 0.0115,  0.0096, -0.0108, -0.0114,  0.0065, -0.0161, -0.0076,  0.0040]),\n",
       " 'net.layers.4.heads.0.out_block.weight': Parameter containing:\n",
       " tensor([[-0.4989, -0.8744,  0.3403,  0.8070, -0.8227,  0.2966,  1.1587,  0.1306]]),\n",
       " 'net.layers.4.heads.0.out_block.bias': Parameter containing:\n",
       " tensor([-0.0086]),\n",
       " 'net.layers.4.heads.1.linear_block.0.0.weight': Parameter containing:\n",
       " tensor([[ 1.7297e-01, -3.8574e-01,  3.3804e-01,  2.9325e-01,  3.4257e-01,\n",
       "           4.4139e-01,  2.0597e-02,  6.5701e-02, -2.2464e-01, -3.7165e-01,\n",
       "          -2.4600e-01,  3.1355e-01, -4.2074e-01,  7.1384e-02,  5.1989e-01,\n",
       "          -3.8925e-01, -2.8892e-02,  2.0921e-01, -3.7555e-01,  1.4762e-01,\n",
       "           5.0512e-01,  5.9261e-03, -2.9207e-01, -4.2581e-01, -8.3991e-02,\n",
       "          -3.1531e-01, -2.0859e-01,  3.8341e-01, -2.2971e-01, -2.7271e-01,\n",
       "           6.2375e-02,  2.5072e-01],\n",
       "         [ 2.3265e-01,  2.2144e-01, -6.6527e-01,  1.5660e-01,  1.2381e-01,\n",
       "           3.8551e-01, -4.5768e-01,  4.4672e-01,  3.4395e-01,  3.5845e-02,\n",
       "           2.7454e-01,  4.5306e-01, -2.2483e-01,  7.2891e-02,  6.8983e-01,\n",
       "           1.3901e-01, -1.4825e-01, -6.4295e-01,  2.5312e-01, -1.6991e-01,\n",
       "           1.2592e-02,  3.6743e-01,  4.4540e-01, -2.3903e-02, -1.4459e-01,\n",
       "          -2.1334e-01, -3.1582e-01, -2.6704e-01,  4.1709e-01,  1.0114e-01,\n",
       "          -4.6628e-02,  1.6645e-01],\n",
       "         [-4.0890e-01,  5.3379e-02, -2.3728e-01,  2.6707e-01, -2.0222e-01,\n",
       "          -2.5948e-01, -2.0064e-01,  1.1054e-01,  4.0311e-01, -4.9349e-01,\n",
       "          -3.8275e-01, -3.1727e-01,  5.0526e-02, -2.1049e-01, -3.2937e-01,\n",
       "           2.3411e-01, -3.2005e-01, -1.2991e-01, -1.0093e-01,  4.4542e-01,\n",
       "          -5.7283e-01, -1.6633e-01, -2.9679e-02, -3.3604e-01, -1.2443e-01,\n",
       "          -1.9523e-01,  1.2154e-01,  2.1478e-01, -1.5600e-02,  1.9118e-01,\n",
       "          -3.0966e-01,  3.9755e-01],\n",
       "         [ 2.4085e-01,  4.2227e-01, -4.9350e-02,  1.4161e-01,  1.7556e-01,\n",
       "          -5.9528e-02,  1.8866e-01, -3.3017e-01,  4.0259e-01, -1.0033e-02,\n",
       "          -2.0483e-01,  2.6439e-01, -4.2940e-01, -1.3741e-01,  4.0891e-01,\n",
       "          -2.2517e-01, -1.4813e-01,  3.5670e-02,  1.9561e-01, -1.5148e-01,\n",
       "          -2.0261e-01,  7.8713e-02, -1.9004e-01, -3.9463e-01, -3.9293e-01,\n",
       "          -1.0758e-01, -8.2491e-02,  1.5150e-01, -4.1254e-01, -2.4779e-01,\n",
       "          -3.4040e-01, -2.3282e-01],\n",
       "         [ 1.2528e-02,  2.2371e-01, -1.4103e-01,  2.9513e-01, -4.8497e-01,\n",
       "           4.4642e-01,  2.6416e-01,  2.7693e-02,  4.9795e-01, -4.7636e-01,\n",
       "           2.7240e-01,  1.1329e-01, -1.6459e-01,  3.6757e-01,  5.9892e-01,\n",
       "           3.5446e-02, -5.5793e-01, -2.9479e-01,  3.0316e-01, -1.1856e-01,\n",
       "           2.4849e-01,  4.5297e-02,  2.6892e-02, -1.6117e-01,  2.4925e-01,\n",
       "           3.2495e-01, -1.0862e-01, -2.4417e-01, -3.8741e-02, -1.6732e-01,\n",
       "           1.4444e-01, -5.7965e-01],\n",
       "         [-1.4791e-01, -1.1755e-02, -3.3276e-01,  1.2633e-01,  4.0125e-01,\n",
       "          -2.8792e-01,  9.6784e-02, -3.7951e-01,  2.0022e-01,  1.4986e-01,\n",
       "           1.9178e-01,  1.9324e-02, -1.3677e-01, -5.2360e-01, -5.4826e-02,\n",
       "          -6.6862e-04,  3.0970e-01,  4.9736e-01, -3.4518e-01,  2.5434e-01,\n",
       "           4.7170e-02,  2.7625e-01, -3.4071e-02, -4.4287e-02, -2.4457e-01,\n",
       "          -7.7664e-02, -2.5062e-01, -3.8482e-01,  5.2578e-01,  5.5675e-02,\n",
       "           3.1574e-01,  3.0989e-01],\n",
       "         [ 3.6868e-01,  2.6899e-01,  2.1885e-01, -2.8683e-01, -2.6339e-01,\n",
       "          -3.1801e-01, -2.3108e-01, -7.7869e-02, -5.0068e-01,  2.6952e-01,\n",
       "          -1.2460e-02, -5.5114e-02,  3.4647e-01,  1.0455e-01, -2.2841e-01,\n",
       "          -4.2548e-01, -4.0412e-01,  1.8396e-01,  1.8046e-01, -5.2358e-01,\n",
       "           5.1928e-01, -2.3082e-01,  4.6226e-01,  1.3533e-01, -8.8320e-02,\n",
       "          -5.6696e-01, -1.7854e-01, -1.8742e-01,  4.2130e-01, -4.4596e-01,\n",
       "          -1.7476e-01, -6.6240e-02],\n",
       "         [-2.3932e-01, -1.4161e-01,  4.4608e-01,  4.5663e-01,  1.0143e-01,\n",
       "          -3.4785e-01,  4.6689e-02,  4.8440e-01,  1.9490e-01, -3.1931e-01,\n",
       "          -3.7412e-01,  7.6419e-02, -4.8448e-02,  4.6554e-01, -4.8278e-02,\n",
       "           2.7050e-01, -4.8223e-01, -3.7226e-01,  2.3498e-01,  3.2877e-01,\n",
       "          -1.9533e-01,  1.5450e-01,  3.5258e-01, -6.6143e-02,  1.8604e-01,\n",
       "          -1.5660e-01, -2.7991e-01,  1.3825e-01, -2.1820e-01, -3.1182e-01,\n",
       "          -2.2252e-01, -4.8097e-01],\n",
       "         [-2.3027e-01,  4.4907e-01, -1.1176e-01, -1.6989e-01, -1.1659e-01,\n",
       "          -2.0905e-01, -1.8295e-01,  9.7155e-02, -3.7850e-01, -4.7795e-01,\n",
       "           3.8663e-01, -1.9352e-01, -1.2869e-01,  2.7577e-01, -6.8569e-02,\n",
       "           6.4246e-01,  8.2988e-02,  4.1787e-01,  3.0266e-01,  6.1569e-01,\n",
       "           7.1636e-02, -1.0855e-01, -5.3757e-02,  1.5634e-01, -5.4048e-01,\n",
       "           3.6537e-01, -3.3860e-02,  7.0581e-01,  6.4138e-02,  1.5708e-01,\n",
       "           5.3076e-02,  4.3497e-01],\n",
       "         [ 1.0048e-01, -1.6395e-01,  2.4054e-01,  3.0296e-02, -1.5791e-01,\n",
       "          -9.3646e-02,  1.0364e-01, -4.9196e-01, -2.5267e-01,  8.0739e-03,\n",
       "          -1.4284e-01,  3.9780e-01, -1.1432e-01,  7.0513e-02, -4.8003e-01,\n",
       "          -2.5883e-01,  1.8912e-01,  1.0796e-01,  4.4542e-01,  5.6392e-01,\n",
       "          -1.1716e-01, -4.1819e-01,  1.3058e-01, -2.6280e-01, -3.7242e-01,\n",
       "          -3.6353e-01, -3.0331e-01,  6.2106e-01, -7.3850e-03,  2.6846e-01,\n",
       "           4.2539e-02, -9.4445e-02],\n",
       "         [-1.9917e-01,  2.2476e-01,  3.9035e-02, -3.2475e-01, -6.6277e-02,\n",
       "           2.3265e-01,  4.2003e-03,  2.3301e-01,  3.5003e-01, -4.4953e-01,\n",
       "          -1.6816e-01,  3.5605e-01, -2.6043e-01, -5.1027e-02,  4.6144e-02,\n",
       "          -4.1523e-01, -3.3723e-01, -6.4206e-01, -2.4900e-01, -2.2377e-01,\n",
       "          -2.1418e-01, -2.4108e-01, -3.0543e-01, -1.9351e-01, -5.2857e-02,\n",
       "           1.8650e-01, -6.4794e-01, -5.4633e-01,  1.0664e-01, -3.7318e-01,\n",
       "           1.6407e-01, -1.3987e-01],\n",
       "         [ 4.9908e-02,  4.6477e-01, -3.3370e-01, -2.0321e-02, -9.2211e-02,\n",
       "          -1.5475e-02, -2.9751e-01,  3.6127e-01, -3.7333e-01, -1.7854e-01,\n",
       "           1.4070e-01,  3.5133e-01,  5.2097e-02,  1.6140e-03,  4.4850e-01,\n",
       "          -2.4951e-01, -5.9877e-03, -9.9544e-02, -7.2605e-02, -2.9844e-01,\n",
       "          -2.5578e-01, -1.7789e-01,  5.2446e-01, -4.4785e-03,  2.7119e-01,\n",
       "          -1.5640e-01,  2.1198e-01, -2.4075e-01,  8.4396e-02,  1.5073e-01,\n",
       "           6.9853e-03, -1.9368e-01],\n",
       "         [ 2.4091e-01, -4.5701e-01, -1.2428e-03, -2.7665e-01,  3.2732e-01,\n",
       "           3.8301e-01, -2.2550e-01, -7.9034e-02,  1.3055e-03, -3.9990e-01,\n",
       "           1.1992e-01,  4.3074e-02, -1.6176e-01,  2.6370e-01, -3.2065e-02,\n",
       "          -2.3039e-01,  4.1561e-01,  4.3740e-01, -3.9541e-01, -1.4960e-01,\n",
       "          -4.1048e-01, -4.2983e-01, -4.3220e-01, -1.0366e-01,  7.2663e-02,\n",
       "           4.5546e-02, -3.9856e-01, -4.1632e-01, -3.9119e-01,  3.2669e-01,\n",
       "          -2.0245e-01, -3.5139e-01],\n",
       "         [-1.1320e-01,  2.8648e-01,  2.3279e-01,  4.1759e-01, -3.3881e-01,\n",
       "          -1.2570e-01,  3.2807e-01,  1.3224e-01, -7.0638e-02, -4.0318e-03,\n",
       "          -2.3460e-01,  4.4364e-01,  3.5855e-01, -1.2474e-01,  9.7949e-02,\n",
       "           3.3764e-01, -2.2169e-01,  2.8687e-01, -1.2881e-01, -1.6453e-01,\n",
       "           2.2480e-01, -3.8407e-01, -4.0156e-02, -3.8704e-01,  1.4420e-01,\n",
       "          -1.0746e-01, -2.2572e-01,  1.0584e-01, -6.8222e-02,  4.2629e-01,\n",
       "          -6.8424e-02,  3.5323e-01],\n",
       "         [ 5.5399e-01, -5.4357e-01,  3.2655e-01,  2.6741e-01, -1.1026e-01,\n",
       "          -7.4273e-02, -5.5076e-01, -2.4942e-01, -7.0972e-02,  1.2262e-01,\n",
       "          -3.9277e-01,  2.3006e-01,  2.5718e-02, -4.9245e-01, -2.6717e-01,\n",
       "          -3.3660e-02,  3.6524e-01,  1.6293e-01,  4.0846e-01,  4.4835e-01,\n",
       "           9.3579e-02, -3.4911e-02,  3.1036e-01, -3.1907e-01,  6.0266e-01,\n",
       "           4.4760e-01,  1.5553e-01, -5.5398e-01, -3.7996e-01,  3.2391e-02,\n",
       "          -1.5284e-01,  2.2069e-02],\n",
       "         [ 3.7439e-01, -1.4052e-01,  2.2532e-01, -2.8654e-01, -1.6603e-01,\n",
       "          -7.7781e-02, -2.2644e-01,  2.8366e-01,  7.9883e-02,  4.9433e-03,\n",
       "           1.9599e-01,  2.0578e-01, -9.7355e-02,  3.1257e-01,  4.9471e-02,\n",
       "           1.5787e-01, -1.7591e-02,  4.1992e-01, -3.7248e-01, -3.3425e-01,\n",
       "           2.4003e-01,  5.3825e-02, -8.0969e-02, -3.3413e-01, -4.4901e-01,\n",
       "           4.8847e-02,  1.3318e-01,  2.1760e-01,  1.7269e-01,  3.3391e-01,\n",
       "           3.2740e-01,  6.2025e-01]]),\n",
       " 'net.layers.4.heads.1.linear_block.0.0.bias': Parameter containing:\n",
       " tensor([-0.0153, -0.0224, -0.0921,  0.0231, -0.0829, -0.0125,  0.0336,  0.1135,\n",
       "          0.1365,  0.0961, -0.0481,  0.0269, -0.0800, -0.0184, -0.1717,  0.0541]),\n",
       " 'net.layers.4.heads.1.linear_block.0.2.weight': Parameter containing:\n",
       " tensor([0.7565, 0.9716, 1.1201, 0.8799, 0.9698, 0.9819, 1.0483, 0.8186, 1.1776,\n",
       "         1.0920, 1.0602, 0.9545, 0.9735, 0.8851, 1.0809, 1.0694]),\n",
       " 'net.layers.4.heads.1.linear_block.0.2.bias': Parameter containing:\n",
       " tensor([ 0.0063, -0.0498, -0.1116,  0.0380, -0.0517,  0.0356, -0.0234,  0.0727,\n",
       "          0.0934,  0.0755,  0.0241,  0.0010, -0.0119, -0.0298, -0.0808,  0.0336]),\n",
       " 'net.layers.4.heads.1.linear_block.1.0.weight': Parameter containing:\n",
       " tensor([[ 0.1903,  0.3642, -0.6201, -0.4680,  0.2943,  0.2797,  0.2668, -0.0358,\n",
       "           0.2517, -0.4422,  0.6428, -0.3046,  0.4866,  0.1635,  0.1863, -0.4893],\n",
       "         [-0.1951, -0.1487, -0.0346,  0.6234, -0.4592,  0.3299,  0.3782, -0.6565,\n",
       "          -0.4304, -0.7030, -0.5120,  0.0819, -0.0621,  0.3985,  0.3650,  0.1630],\n",
       "         [ 0.3904,  0.0731, -0.8192,  0.5142, -0.2861, -0.6718,  0.4513,  0.7070,\n",
       "           0.1235,  0.1761, -0.5123,  0.8729, -0.2515, -0.1991, -0.6882,  0.2689],\n",
       "         [ 0.0777, -0.2196,  0.3942,  0.5380,  0.6054,  0.7654, -0.3067, -0.5312,\n",
       "           0.3066,  0.2251,  0.0264,  0.5236,  0.3748, -0.2902,  0.4083,  0.1601],\n",
       "         [ 0.3711, -0.5942, -0.4251,  0.5958, -0.0123,  0.2093, -0.2249, -0.3899,\n",
       "          -0.6502, -0.5213, -0.4077,  0.7403,  0.1317, -0.4485,  0.4274, -0.2509],\n",
       "         [ 0.1110,  0.2420,  0.5030, -0.3651,  0.3372,  0.0205,  0.1598, -0.4708,\n",
       "          -0.2838, -0.4963, -0.1402, -0.0033,  0.6820, -0.0629, -0.2727, -0.0406],\n",
       "         [-0.2475,  0.2429, -0.6361,  0.0149,  0.2747, -0.1592,  0.1275, -0.2600,\n",
       "          -0.7794, -0.6017,  0.4725,  0.1019, -0.0321, -0.5607, -0.0422, -0.2827],\n",
       "         [-0.5343, -0.6015, -0.6549,  0.3184, -0.7181,  0.4766, -0.6670,  0.1881,\n",
       "           0.3574,  0.6615,  0.0682, -0.3248, -0.4644,  0.0282, -0.7207,  0.4973]]),\n",
       " 'net.layers.4.heads.1.linear_block.1.0.bias': Parameter containing:\n",
       " tensor([ 0.0235, -0.0271,  0.1184,  0.0206, -0.0034, -0.0307, -0.0565,  0.1344]),\n",
       " 'net.layers.4.heads.1.linear_block.1.2.weight': Parameter containing:\n",
       " tensor([0.9201, 0.9862, 0.9694, 0.9849, 0.9524, 0.9629, 0.9345, 0.9717]),\n",
       " 'net.layers.4.heads.1.linear_block.1.2.bias': Parameter containing:\n",
       " tensor([ 0.0587, -0.0518,  0.0449, -0.0508,  0.0598,  0.0609, -0.0525, -0.0604]),\n",
       " 'net.layers.4.heads.1.out_block.weight': Parameter containing:\n",
       " tensor([[-0.7103,  0.9887, -0.1703,  0.5886, -0.7154, -0.5442,  0.6406,  0.7531]]),\n",
       " 'net.layers.4.heads.1.out_block.bias': Parameter containing:\n",
       " tensor([-0.0557])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(dict(trained_model.net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHLitModule(\n",
       "  (net): SequentialLitModel(\n",
       "    (layers): Sequential(\n",
       "      (0): EncoderLayer(\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (embeddings): EmbeddingLayer(\n",
       "          (embeddings): ModuleList(\n",
       "            (0-1): 2 x Embedding(20, 8)\n",
       "            (2): Embedding(7, 8)\n",
       "            (3): Embedding(6, 8)\n",
       "            (4): Embedding(1, 8)\n",
       "            (5): Embedding(4, 8)\n",
       "            (6): Embedding(14, 8)\n",
       "            (7-9): 3 x Embedding(20, 8)\n",
       "            (10-12): 3 x Embedding(2, 8)\n",
       "            (13-14): 2 x Embedding(7, 8)\n",
       "            (15): Embedding(6, 8)\n",
       "            (16): Embedding(5, 8)\n",
       "            (17): Embedding(18, 8)\n",
       "            (18): Embedding(17, 8)\n",
       "          )\n",
       "        )\n",
       "        (out_linear_block): Linear(in_features=158, out_features=32, bias=True)\n",
       "        (num_bn): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): PositionwiseFeedForward(\n",
       "        (position_wise_layer): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (2): GRUSeqToSeq(\n",
       "        (gru): GRU(32, 32, batch_first=True)\n",
       "      )\n",
       "      (3): ConvPooling(\n",
       "        (pooling_layer): MinMaxAvgPoolings()\n",
       "        (agg_layer): Conv1d(3, 1, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "      )\n",
       "      (4): MultiTaskLinearBlock(\n",
       "        (heads): ModuleList(\n",
       "          (0): LinearBlock(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear_block): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                (1): Tanh()\n",
       "                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "                (1): Tanh()\n",
       "                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (out_block): Linear(in_features=8, out_features=1, bias=True)\n",
       "            (cls_layers): Sequential(\n",
       "              (0): Dropout(p=0.0, inplace=False)\n",
       "              (1): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                  (1): Tanh()\n",
       "                  (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "                  (1): Tanh()\n",
       "                  (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=8, out_features=1, bias=True)\n",
       "              (3): Tanh()\n",
       "            )\n",
       "          )\n",
       "          (1): LinearBlock(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear_block): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (out_block): Linear(in_features=8, out_features=1, bias=True)\n",
       "            (cls_layers): Sequential(\n",
       "              (0): Dropout(p=0.0, inplace=False)\n",
       "              (1): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                  (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                  (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=8, out_features=1, bias=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       "  (train_metrics): ModuleDict(\n",
       "    (tanh_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "    (gelu_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "  )\n",
       "  (val_metrics): ModuleDict(\n",
       "    (tanh_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "    (gelu_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "  )\n",
       "  (test_metrics): ModuleDict(\n",
       "    (tanh_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "    (gelu_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "  )\n",
       "  (monitor_metric): CompositionalMetric(\n",
       "    true_divide(\n",
       "      CompositionalMetric(\n",
       "    add(\n",
       "      CompositionalMetric(\n",
       "    add(\n",
       "      0,\n",
       "      BinaryAUROC()\n",
       "    )\n",
       "  ),\n",
       "      BinaryAUROC()\n",
       "    )\n",
       "  ),\n",
       "      2\n",
       "    )\n",
       "  )\n",
       "  (train_loss): MeanMetric()\n",
       "  (train_branched_loss): ModuleDict(\n",
       "    (tanh_output): MeanMetric()\n",
       "    (gelu_output): MeanMetric()\n",
       "  )\n",
       "  (val_loss): MeanMetric()\n",
       "  (val_branched_loss): ModuleDict(\n",
       "    (tanh_output): MeanMetric()\n",
       "    (gelu_output): MeanMetric()\n",
       "  )\n",
       "  (test_loss): MeanMetric()\n",
       "  (test_branched_loss): ModuleDict(\n",
       "    (tanh_output): MeanMetric()\n",
       "    (gelu_output): MeanMetric()\n",
       "  )\n",
       "  (val_best_metric): MaxMetric()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(trained_model.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metrics import GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelBatch(numerical=tensor([[[ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
       "         [ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
       "         [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.6800,  0.8012,  0.7182,  0.6959,  7.2181,  0.0000],\n",
       "         [ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
       "         [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.0400,  1.1128,  0.8969,  0.4422,  7.2181,  0.0000],\n",
       "         [ 2.2800,  1.3662,  0.9791,  0.2032,  7.2181,  0.0000],\n",
       "         [ 2.8800,  2.2093,  0.8030, -0.5960,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.2000,  0.4866,  0.4677,  0.8839,  7.2181,  0.0000],\n",
       "         [ 2.6400,  1.8312,  0.9663, -0.2574,  7.2181,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 3.0000,  2.4223,  0.6588, -0.7523,  7.2181,  0.0000],\n",
       "         [ 2.8800,  2.2093,  0.8030, -0.5960,  7.2181,  0.0000],\n",
       "         [ 0.1200,  0.0587,  0.0586,  0.9983,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
       "         [ 0.1600,  0.1297,  0.1293,  0.9916,  7.2181,  0.2500],\n",
       "         [ 3.1200,  2.6531,  0.4693, -0.8830,  7.2181,  0.3333],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]), categorical=tensor([[[ 8, 12,  2,  ...,  4, 11,  0],\n",
       "         [ 8,  6,  2,  ...,  4,  0,  3],\n",
       "         [15, 19,  2,  ...,  4,  1,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 5, 13,  2,  ...,  4,  0,  3],\n",
       "         [17,  3,  2,  ...,  4, 10,  0],\n",
       "         [ 3, 11,  2,  ...,  4,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 9, 13,  2,  ...,  4,  3,  0],\n",
       "         [ 7, 14,  0,  ...,  4,  0,  2],\n",
       "         [12,  3,  2,  ...,  4,  1,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3, 14,  2,  ...,  4,  2,  0],\n",
       "         [19,  8,  2,  ...,  4,  9,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[14,  8,  2,  ...,  4,  0, 12],\n",
       "         [13,  0,  2,  ...,  4,  4,  0],\n",
       "         [ 6,  2,  2,  ...,  1,  0, 14],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 4, 14,  2,  ...,  4,  3,  0],\n",
       "         [ 5,  2,  5,  ...,  1,  7,  0],\n",
       "         [ 2,  4,  2,  ...,  4,  0,  4],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]]]), targets=tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]), sample_indexes=['205752', '79395', '237004', '233274', '176497', '220761', '197006', '165157', '228883', '175573', '155502', '195609', '195726', '58738', '171916', '193082', '11649', '1116', '175727', '34714', '202912', '103650', '106129', '136174', '224524', '148490', '30124', '158412', '174236', '68798', '82200', '155277', '219993', '215575', '81732', '592', '193218', '231031', '16741', '118495', '214495', '104164', '99691', '10936', '180521', '101774', '106907', '20267', '35367', '66714', '103116', '200972', '96991', '64278', '189668', '70112', '158102', '144628', '191553', '66367', '65547', '146623', '527', '175564', '124653', '74817', '111847', '100079', '44827', '188182', '113297', '4869', '181560', '95904', '126643', '214624', '112306', '243763', '144068', '35462', '2477', '46625', '179391', '174178', '68917', '5686', '118464', '241625', '31124', '86201', '71228', '29394', '62751', '188514', '97880', '248371', '131067', '37967', '109722', '156417', '51795', '110407', '99115', '226683', '200117', '190791', '240985', '199927', '13278', '46056', '33870', '35143', '110621', '102285', '91293', '3257', '242937', '149155', '10684', '95783', '63452', '181734', '239771', '145718', '135222', '56459', '116006', '104710', '98669', '153555', '228660', '111249', '73343', '95823', '219240', '118536', '58976', '184242', '103592', '236517', '137659', '80327', '33891', '211857', '140486', '4907', '206821', '10109', '241423', '196897', '21048', '188219', '175083', '9831', '116893', '42824', '162608', '13425', '17442', '115767', '241378', '129945', '204266', '107253', '119214', '155669', '152369', '244473', '183061', '220889', '91925', '23594', '177934', '206804', '229225', '164330', '237477', '229686', '214521', '189351', '48147', '19441', '237414', '214093', '28746', '238566', '124189', '246181', '167099', '199457', '48771', '214689', '204663', '243149', '83258', '120993', '200224', '92608', '99918', '90682', '230522', '161590', '172970', '221955', '32842', '1606', '18685', '59628', '43467', '136628', '59477', '187683', '2106', '203808', '103854', '238966', '194149', '199769', '240135', '146730', '104313', '164764', '30768', '245188', '183602', '172451', '107623', '135183', '217383', '56237', '47009', '194819', '18839', '1110', '152975', '156845', '171881', '121382', '139979', '32286', '23512', '246355', '175544', '190984', '85308', '78489', '221515', '56325', '115746', '28895', '35474', '24032', '186406', '238104', '227549', '237752', '77775', '3392', '173115', '186763', '245788', '156042', '177084', '7740', '197251', '190313', '25322', '112403', '133746', '32539', '62098', '195214', '200951', '63778', '155155', '117726', '157843', '4488', '138242', '172563', '48333', '170458', '87653', '167105', '40184', '195783', '60874', '92987', '219194', '189659', '64400', '128680', '163134', '237927', '65421', '174452', '77466', '68299', '222277', '124557', '188881', '148494', '165936', '179561', '46354', '152912', '208370', '61808', '113636', '66607', '178105', '32829', '30492', '159497', '23854', '141125', '64985', '46564', '98477', '119059', '18889', '54070', '241211', '5768', '176484', '71416', '137117', '187574', '91155', '118395', '174574', '82794', '122712', '145020', '243294', '142252', '191788', '224812', '210496', '13089', '99403', '47694', '205631', '103689', '197626', '59925', '142951', '4042', '39538', '115533', '85440', '91426', '120165', '133712', '206278', '235205', '144972', '43737', '5728', '232278', '16644', '232089', '150265', '36348', '236708', '54953', '9990', '94189', '149403', '238091', '240440', '76786', '192640', '207840', '170523', '15457', '42052', '22558', '205925', '51910', '43235', '179006', '243298', '26498', '34024', '168065', '213611', '47642', '168869', '23667', '124118', '3159', '170315', '23874', '97054', '188049', '103861', '124395', '141673', '214013', '31573', '32322', '171671', '196324', '224463', '47371', '49281', '83579', '72943', '28626', '144306', '116489', '115223', '223884', '108693', '183937', '46820', '126061', '61814', '132482', '80407', '217865', '37379', '37660', '78917', '57044', '9085', '41871', '22731', '151699', '199', '228698', '119289', '199568', '76739', '237527', '209227', '52575', '52460', '204787', '192041', '247233', '55629', '107100', '97948', '197242', '139957', '150316', '54323', '211505', '235714', '177588', '100058', '203421', '144995', '245435', '201325', '132776', '152545', '183379', '5838', '144641', '203302', '223178', '100563', '199745', '20636', '200515', '197843', '189221', '234207', '93664', '171214', '65924', '200432', '145755', '238913', '182835', '30412', '91493', '44696', '242025', '108151', '214922', '160323', '126108', '232573', '118820', '67838', '80689', '171242', '132606', '90608', '94218', '191262', '158445', '52203', '83025', '105719', '18081', '113191', '200089', '114204', '14672', '143288', '240014', '8057', '192675', '131314', '247863', '88271', '151424', '125935', '146031', '173521', '5791', '51682', '130575', '156599', '33780', '35149', '187106', '233760', '164149', '14763', '45791', '13018', '33841', '99973', '16886', '169121', '16783', '60475', '170099', '114294', '148856', '218425', '83199', '125777', '147484', '229820', '236069', '49900', '22080', '76928', '66081', '85373', '3911', '167496', '121083', '127062', '186034', '139791', '216629', '172020', '95056', '202134', '135128', '188895', '21653', '47676', '208852', '155777', '44901', '217292', '126824', '87256', '119392', '144175', '181784', '60541', '162579', '83653', '152340', '73066', '144326', '34459', '84731', '230728', '15307', '147508', '10292', '136439', '175250', '24177', '115576', '44005', '239927', '26509', '102837', '151255', '9660', '97662', '167285', '4518', '217136', '233757', '93083', '151980', '338', '229424', '141199', '188526', '218512', '203330', '226076', '217820', '35637', '67426', '69421', '191146', '164843', '17044', '46289', '200046', '201374', '193900', '33243', '86150', '54135', '129040', '240198', '100991', '240677', '17122', '128027', '18836', '220647', '113203', '215372', '34897', '161655', '25879', '133292', '29777', '211499', '55494', '176530', '112643', '130212', '211701', '68563', '2731', '133912', '230197', '34954', '227979', '69152', '184807', '89409', '248727', '217039', '187654', '173697', '205870', '176494', '99708', '108477', '55460', '237568', '24096', '23259', '89432', '2124', '238640', '113517', '28311', '64565', '58560', '164771', '245899', '221651', '66875', '208738', '147231', '194147', '154369', '176432', '178571', '97781', '80146', '73576', '147175', '65857', '190366', '158046', '239718', '184855', '18376', '190862', '191746', '241430', '148786', '181919', '109101', '61534', '175881', '79678', '83045', '230518', '148538', '86864', '182008', '76104', '125962', '114446', '165681', '151114', '192424', '65267', '167467', '29802', '117388', '149461', '32871', '158367', '48649', '245972', '6711', '39704', '208653', '101804', '42705', '71943', '115369', '63217', '107568', '197640', '117237', '158526', '65115', '181730', '119899', '238872', '231569', '234472', '243334', '40211', '175846', '177602', '199531', '110566', '93829', '124385', '10409', '225352', '130650', '216531', '226459', '103392', '80993', '19142', '236353', '218031', '215852', '27798', '108269', '248406', '1544', '181165', '42066', '87161', '54277', '13124', '43614', '48085', '72051', '82128', '135340', '42515', '84869', '142530', '8853', '168197', '40437', '192007', '79593', '150699', '23983', '154058', '193121', '162763', '57024', '97878', '183378', '213724', '238323', '197003', '140223', '203189', '152365', '242874', '168044', '209640', '58121', '54930', '141818', '182490', '134655', '207865', '3096', '201968', '94510', '229127', '190409', '161228', '17848', '78926', '45771', '116344', '130947', '175792', '74973', '192457', '132505', '62166', '45740', '149389', '90461', '202100', '213791', '20078', '92097', '169079', '104984', '233345', '209250', '95135', '238604', '187637', '214292', '45545', '166502', '124529', '136787', '189215', '14170', '248125', '129495', '216793', '149042', '105948', '30650', '165424', '70824', '202280', '36290', '166890', '34453', '51974', '183355', '102876', '155981', '105171', '50701', '155215', '201350', '249803', '185963', '217022', '80084', '57221', '190259', '89368', '49231', '135265', '91893', '220513', '103537', '73663', '218958', '2907', '61422', '40099', '28096', '58418', '122343', '138074', '201038', '47048', '232828', '78959', '120845', '224337', '31666', '7510', '35621', '221693', '232724', '67763', '60784', '66963', '43166', '63046', '141383', '175157', '22572', '53400', '74389', '119271', '103164', '152342', '232096', '24830', '124997', '206703', '34645', '19022', '245150', '227374', '120586', '172973', '151381', '125104', '36398', '162355', '65213', '128783', '231957', '96050', '211550', '87958', '66621', '88457', '18100', '10326', '99839', '204355', '118460', '68417', '116575', '119080', '44178', '125635', '178875', '222731', '81717', '30664', '51509', '76864', '88411', '191026', '179721', '45380', '152854', '118539', '61517', '57229', '111099', '230394', '227328', '107861', '86781', '103717', '13064', '11511', '112072', '214887', '219416', '10217', '72287', '31073', '219222', '233474', '136802', '94823', '139897', '181820', '48030', '59974', '32879', '234697', '138451', '225424', '138911', '23982', '178825', '206219', '173887', '214946', '212644', '111094', '73619', '26400', '232971', '221286', '39183', '41119', '72638', '113586', '98882', '122355', '12794', '189559', '145655', '83217', '9445', '212992', '165514', '75268', '65341', '178565', '152254', '141965', '67852', '33480', '38822', '157964', '162183', '1906', '162302', '35876', '131894', '183942', '32647', '100906', '173732', '101491', '17680', '225397', '141666', '20045', '74125', '234333'], lengths=tensor([12,  6,  3,  ...,  2,  4,  3]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(54.0041)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(55.8003)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sample = next(iter(test_dataloader))\n",
    "d(GINI()(trained_model.net(test_sample).logits[:, 0], test_sample.targets))\n",
    "d(GINI()(trained_model.net(test_sample).logits[:, 1], test_sample.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [\n",
    "    trained_model.net(sample).logits.ravel() for i, sample in enumerate(test_dataloader) if i < 5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(plt.hist(preds, bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(plt.hist(torch.sigmoid(preds), bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thunder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_trained_model = thunder.jit(trained_model.net.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterpreterError",
     "evalue": "Encountered exception AttributeError: module 'dis' has no attribute '_parse_exception_table' while tracing SequentialLitModel(\n  (layers): Sequential(\n    (0): EncoderLayer(\n      (dropout): Dropout(p=0.3, inplace=False)\n      (embeddings): EmbeddingLayer(\n        (embeddings): ModuleList(\n          (0-1): 2 x Embedding(18, 32)\n          (2-3): 2 x Embedding(17, 32)\n          (4): Embedding(16, 32)\n          (5): Embedding(20, 32)\n          (6): Embedding(7, 32)\n          (7): Embedding(6, 32)\n          (8): Embedding(4, 32)\n          (9): Embedding(14, 32)\n          (10): Embedding(4, 32)\n          (11-12): 2 x Embedding(7, 32)\n          (13): Embedding(6, 32)\n          (14): Embedding(4, 32)\n          (15-16): 2 x Embedding(2, 32)\n          (17): Embedding(4, 32)\n          (18): Embedding(25, 32)\n          (19): Embedding(5, 32)\n          (20): Embedding(26, 32)\n          (21): Embedding(5, 32)\n          (22): Embedding(27, 32)\n          (23): Embedding(7, 32)\n          (24): Embedding(19, 32)\n          (25): Embedding(9, 32)\n          (26): Embedding(5, 32)\n          (27): Embedding(15, 32)\n          (28-30): 3 x Embedding(20, 32)\n        )\n      )\n      (out_linear_block): Linear(in_features=992, out_features=32, bias=True)\n    )\n    (1): GRUSeqToSeq(\n      (gru): GRU(32, 32, batch_first=True)\n    )\n    (2): ConvPooling(\n      (pooling_layer): AllPoolings()\n      (conv_layer): Conv1d(5, 1, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n    )\n    (3): MultiOutputLinearBlock(\n      (heads): ModuleList(\n        (0): LinearBlock(\n          (dropout): Dropout(p=0.0, inplace=False)\n          (linear_block): Sequential(\n            (0): Sequential(\n              (0): Linear(in_features=32, out_features=16, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n            )\n            (1): Sequential(\n              (0): Linear(in_features=16, out_features=8, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (out_block): Linear(in_features=8, out_features=1, bias=True)\n          (cls_layers): Sequential(\n            (0): Dropout(p=0.0, inplace=False)\n            (1): Sequential(\n              (0): Sequential(\n                (0): Linear(in_features=32, out_features=16, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n              )\n              (1): Sequential(\n                (0): Linear(in_features=16, out_features=8, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n              )\n            )\n            (2): Linear(in_features=8, out_features=1, bias=True)\n            (3): GELU(approximate='none')\n          )\n        )\n      )\n    )\n  )\n):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6557\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   6555\u001b[0m     populate_attribute_wrapper(wrapped_cell, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_contents\u001b[39m\u001b[38;5;124m\"\u001b[39m, fn_wrapped)\n\u001b[0;32m-> 6557\u001b[0m interpretation_result: Any \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_fn_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6558\u001b[0m interpretation_result \u001b[38;5;241m=\u001b[39m unwrap(interpretation_result)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6543\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_.<locals>.getfn.<locals>.fn_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_2\u001b[39m(args, kwargs):\n\u001b[0;32m-> 6543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/sequential_model.py:19\u001b[0m, in \u001b[0;36mSequentialLitModel.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: ModelInput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelOutput:\n\u001b[0;32m---> 19\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(inputs)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/embedding/encoder_layer.py:66\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: ModelInput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SingleForwardState:\n\u001b[0;32m---> 66\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(inputs\u001b[38;5;241m.\u001b[39mcategorical)\n\u001b[1;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/embedding/encoder_layer.py:29\u001b[0m, in \u001b[0;36mEmbeddingLayer.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m---> 29\u001b[0m         [embedding(x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]) \u001b[38;5;28;01mfor\u001b[39;00m idx, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m     ) \u001b[38;5;66;03m# size = (batch_size, len(cat_features), embedding_dim)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/embedding/encoder_layer.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m---> 29\u001b[0m         [embedding(x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]) \u001b[38;5;28;01mfor\u001b[39;00m idx, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m     ) \u001b[38;5;66;03m# size = (batch_size, len(cat_features), embedding_dim)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5601\u001b[0m, in \u001b[0;36m_unpack_sequence_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   5599\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[0;32m-> 5601\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6046\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6045\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_lookaside(lookaside_fn)\n\u001b[0;32m-> 6046\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mlookaside_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6047\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1831\u001b[0m, in \u001b[0;36m_next_lookaside\u001b[0;34m(iterator, default)\u001b[0m\n\u001b[1;32m   1829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n\u001b[0;32m-> 1831\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _nil \u001b[38;5;129;01mand\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1829\u001b[0m, in \u001b[0;36m_next_lookaside.<locals>.impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimpl\u001b[39m(iterator):\n\u001b[0;32m-> 1829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1966\u001b[0m, in \u001b[0;36mSequenceIter.__next__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_reversed \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_pos \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms))) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_reversed \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_pos \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 1966\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[1;32m   1967\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_pos]\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6301\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m-> 6301\u001b[0m     exception_table \u001b[38;5;241m=\u001b[39m \u001b[43mdis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_exception_table\u001b[49m(frame\u001b[38;5;241m.\u001b[39mcode)  \u001b[38;5;66;03m# type: ignore (_parse_exception_table is undocumented)\u001b[39;00m\n\u001b[1;32m   6303\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dis' has no attribute '_parse_exception_table'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInterpreterError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mjit_trained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:194\u001b[0m, in \u001b[0;36mThunderModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 194\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:611\u001b[0m, in \u001b[0;36mjit.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m cs\u001b[38;5;241m.\u001b[39mlast_trace_host_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[1;32m    609\u001b[0m cs\u001b[38;5;241m.\u001b[39mcalls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 611\u001b[0m cache_entry, inps, pro_to_epi \u001b[38;5;241m=\u001b[39m \u001b[43mget_computation_and_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m cs\u001b[38;5;241m.\u001b[39mlast_trace_host_execution_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[1;32m    614\u001b[0m result \u001b[38;5;241m=\u001b[39m cache_entry\u001b[38;5;241m.\u001b[39mcomputation_fn(\u001b[38;5;241m*\u001b[39minps)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:262\u001b[0m, in \u001b[0;36m_with_cache_info_ctx.<locals>.cache_info_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m tok \u001b[38;5;241m=\u001b[39m _cache_info_ctx\u001b[38;5;241m.\u001b[39mset({})\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     _cache_info_ctx\u001b[38;5;241m.\u001b[39mreset(tok)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:498\u001b[0m, in \u001b[0;36mjit.<locals>.get_computation_and_inputs\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m     prologue_trc: TraceCtx\n\u001b[1;32m    497\u001b[0m     computation_trc: TraceCtx\n\u001b[0;32m--> 498\u001b[0m     prologue_trc, computation_trc, \u001b[38;5;241m*\u001b[39mmaybe_epilogue \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharp_edges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msharp_edges\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maybe_epilogue:\n\u001b[1;32m    503\u001b[0m     epilogue_traces \u001b[38;5;241m=\u001b[39m maybe_epilogue\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:175\u001b[0m, in \u001b[0;36m_general_frontend\u001b[0;34m(fn, args, kwargs, sharp_edges)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_general_frontend\u001b[39m(fn: Callable, args, kwargs, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m, sharp_edges: SHARP_EDGES_OPTIONS) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[TraceCtx, TraceCtx]:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthunder_general_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharp_edges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharp_edges\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/jit_ext.py:1386\u001b[0m, in \u001b[0;36mthunder_general_jit\u001b[0;34m(fn, args, kwargs, sharp_edges)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m general_jit_ctx(ctx):\n\u001b[1;32m   1385\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracectx(computation_trace):\n\u001b[0;32m-> 1386\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mjfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m         prims\u001b[38;5;241m.\u001b[39mpython_return(result)\n\u001b[1;32m   1388\u001b[0m         process_recorded_modifications(ctx, epilogue_trace)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6566\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   6562\u001b[0m     traceback_str \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlinesep\u001b[38;5;241m.\u001b[39mjoin(f\u001b[38;5;241m.\u001b[39mformat_with_source() \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m runtimectx\u001b[38;5;241m.\u001b[39mframe_stack)\n\u001b[1;32m   6563\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   6564\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m while tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mlinesep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6565\u001b[0m     )\n\u001b[0;32m-> 6566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterpreterError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   6567\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   6568\u001b[0m     \u001b[38;5;66;03m# NOTE: Wrapped functions are valid to assign new attributes to.\u001b[39;00m\n\u001b[1;32m   6569\u001b[0m     fn_\u001b[38;5;241m.\u001b[39m_last_interpreted_instructions \u001b[38;5;241m=\u001b[39m runtimectx\u001b[38;5;241m.\u001b[39minterpreted_instructions  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mInterpreterError\u001b[0m: Encountered exception AttributeError: module 'dis' has no attribute '_parse_exception_table' while tracing SequentialLitModel(\n  (layers): Sequential(\n    (0): EncoderLayer(\n      (dropout): Dropout(p=0.3, inplace=False)\n      (embeddings): EmbeddingLayer(\n        (embeddings): ModuleList(\n          (0-1): 2 x Embedding(18, 32)\n          (2-3): 2 x Embedding(17, 32)\n          (4): Embedding(16, 32)\n          (5): Embedding(20, 32)\n          (6): Embedding(7, 32)\n          (7): Embedding(6, 32)\n          (8): Embedding(4, 32)\n          (9): Embedding(14, 32)\n          (10): Embedding(4, 32)\n          (11-12): 2 x Embedding(7, 32)\n          (13): Embedding(6, 32)\n          (14): Embedding(4, 32)\n          (15-16): 2 x Embedding(2, 32)\n          (17): Embedding(4, 32)\n          (18): Embedding(25, 32)\n          (19): Embedding(5, 32)\n          (20): Embedding(26, 32)\n          (21): Embedding(5, 32)\n          (22): Embedding(27, 32)\n          (23): Embedding(7, 32)\n          (24): Embedding(19, 32)\n          (25): Embedding(9, 32)\n          (26): Embedding(5, 32)\n          (27): Embedding(15, 32)\n          (28-30): 3 x Embedding(20, 32)\n        )\n      )\n      (out_linear_block): Linear(in_features=992, out_features=32, bias=True)\n    )\n    (1): GRUSeqToSeq(\n      (gru): GRU(32, 32, batch_first=True)\n    )\n    (2): ConvPooling(\n      (pooling_layer): AllPoolings()\n      (conv_layer): Conv1d(5, 1, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n    )\n    (3): MultiOutputLinearBlock(\n      (heads): ModuleList(\n        (0): LinearBlock(\n          (dropout): Dropout(p=0.0, inplace=False)\n          (linear_block): Sequential(\n            (0): Sequential(\n              (0): Linear(in_features=32, out_features=16, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n            )\n            (1): Sequential(\n              (0): Linear(in_features=16, out_features=8, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (out_block): Linear(in_features=8, out_features=1, bias=True)\n          (cls_layers): Sequential(\n            (0): Dropout(p=0.0, inplace=False)\n            (1): Sequential(\n              (0): Sequential(\n                (0): Linear(in_features=32, out_features=16, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n              )\n              (1): Sequential(\n                (0): Linear(in_features=16, out_features=8, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n              )\n            )\n            (2): Linear(in_features=8, out_features=1, bias=True)\n            (3): GELU(approximate='none')\n          )\n        )\n      )\n    )\n  )\n):\n"
     ]
    }
   ],
   "source": [
    "preds = jit_trained_model(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: ModelInput",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrained_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcredits_history_lit_model.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1405\u001b[0m, in \u001b[0;36mLightningModule.to_onnx\u001b[0;34m(self, file_path, input_sample, **kwargs)\u001b[0m\n\u001b[1;32m   1402\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_before_batch_transfer(input_sample)\n\u001b[1;32m   1403\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_batch_transfer_handler(input_sample)\n\u001b[0;32m-> 1405\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(mode)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:1613\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1610\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1611\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1613\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1628\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1629\u001b[0m )\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:1135\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m   1134\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1135\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:1011\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m   1007\u001b[0m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m   1013\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:915\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    913\u001b[0m prev_autocast_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    914\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 915\u001b[0m trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    924\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/jit/_trace.py:1296\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1295\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m-> 1296\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/jit/_trace.py:105\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 105\u001b[0m     in_vars, in_desc \u001b[38;5;241m=\u001b[39m \u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# NOTE: use full state, because we need it for BatchNorm export\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# This differs from the compiler path, which doesn't support it at the moment.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     module_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(_unique_state_dict(\u001b[38;5;28mself\u001b[39m, keep_vars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: ModelInput"
     ]
    }
   ],
   "source": [
    "trained_model.net.to_onnx(\"credits_history_lit_model.onnx\", sample[0], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
