{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from IPython.display import display as d\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.dataset import CreditsHistoryDataset\n",
    "from src.data.components.targets_indexes_reader import TargetsReader, IndexesReader\n",
    "from src.data.components.data_reader import DataReader\n",
    "from src.utils.sampler import SamplerFactory\n",
    "from src.utils.metrics import GINI\n",
    "from torchmetrics import MeanMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randint(0, 4, (5, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 3, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Embedding(num_embeddings=4, embedding_dim=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[ 1.2962,  0.5405,  0.5765, -0.8487,  0.2105,  0.0374, -1.7631, -1.2126],\n",
       "         [ 0.2306, -0.5026, -1.0136, -0.8195, -0.7585,  0.4862,  0.5229,  0.2072],\n",
       "         [-0.2808, -0.1399,  0.6364,  0.4589,  0.8277,  1.0517, -0.7562,  1.4967],\n",
       "         [ 0.4944, -0.2382,  0.6527, -0.6246, -0.8596, -1.7815,  0.0119,  1.2357]],\n",
       "        requires_grad=True)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(dict(a.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2808, -0.1399,  0.6364,  0.4589,  0.8277,  1.0517, -0.7562,  1.4967],\n",
       "        [ 1.2962,  0.5405,  0.5765, -0.8487,  0.2105,  0.0374, -1.7631, -1.2126],\n",
       "        [ 0.2306, -0.5026, -1.0136, -0.8195, -0.7585,  0.4862,  0.5229,  0.2072],\n",
       "        [ 0.4944, -0.2382,  0.6527, -0.6246, -0.8596, -1.7815,  0.0119,  1.2357],\n",
       "        [ 0.4944, -0.2382,  0.6527, -0.6246, -0.8596, -1.7815,  0.0119,  1.2357]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe701280bd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a(sample).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 1, 2, 3]), tensor([2, 3, 4, 2, 3, 4]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(torch.concatenate([torch.stack(item).T for item in a]).unbind(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int = 128, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.position_wise_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, input_size)\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(input_size, eps=1e-6)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "\n",
    "        x = self.position_wise_layer(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooModel(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int = 128, max_seq_len: int = 50, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.position_wise_forward = PositionwiseFeedForward(\n",
    "            input_size=emb_dim, \n",
    "            hidden_size=emb_dim * 2, \n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.linear_layer = nn.Linear(emb_dim, 1)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool1d(kernel_size=max_seq_len)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.position_wise_forward(inputs)\n",
    "\n",
    "        x = self.linear_layer(x).squeeze()\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_batch = (torch.randn(size=(32, 50, emb_dim)), torch.randint(0, 2, (32, ), dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_model = FooModel(emb_dim, emb_dim * 2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa614b19890>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAADxCAYAAABrjNUKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACCjUlEQVR4nO19d3hc1bX9nl40mhn1YlVbtiT3bssdkDHgUG0ChIQS0oghlFSSl+QlgZjfey8JKUAaAfICAUxophkX3HCXe5MlWb23kUbS9Lm/P/wyZ9Y2GJwEocBe3+fvu9v33nPP2afM1V3r7K3TNE0jgUAgEAgEgmGC/qOugEAgEAgEgk8W5OVDIBAIBALBsEJePgQCgUAgEAwr5OVDIBAIBALBsEJePgQCgUAgEAwr5OVDIBAIBALBsEJePgQCgUAgEAwr5OVDIBAIBALBsEJePgQCgUAgEAwr5OVDIBAIBALBsOJDe/l4+OGHqaCggKxWK82ZM4f27NnzYT1KIBAIBALBvxE+lJePZ599lu6991764Q9/SPv376cpU6bQsmXLqKOj48N4nEAgEAgEgn8j6D6MxHJz5syhWbNm0W9+8xsiIopGo5Sbm0t33nknfec73znnvdFolFpaWigxMZF0Ot2/umoCgUAgEAg+BGiaRl6vl7Kzs0mvP/e3DeO/+uHBYJAqKirovvvui/2fXq+n8vJy2rlz51nXBwIBCgQCMbu5uZnGjx//r66WQCAQCASCYUBjYyPl5OSc85p/+ctHV1cXRSIRysjIgP/PyMigkydPnnX96tWr6Uc/+tFZ/z/x098ng9lKRETeAjxnGsAvIqEE9fFm3kVH4dy2HRPBNvfivcGUKNiWTnxbm/6pY2Dv3oYvRtEcf+zYWG3Deo3xYdkn8bxvVBhsa9oQ2CkOtLv2ZIJ95ad2xI5fe3YenItYwSR3Nbaz/ZIgXhBFv+j0eH1q8gDYXr8ldrwg5zSc2//HKWAHkrBs++JOsC1G9EPzCRw77pN4v+OaVnXtkSw4lz2xDeyugQSwfV4L2L8oexbs/3zkJrCDiWBSeMJg7Djaiv1pGMJ6Lig/DPamE6Vgp6f3gd2/Ow3sUBL2gWO0ur6/D5+dmYZl6Z5IBdvkRR+3lqEfNAt+ALW1YluKrqmKHR9uHAXnwj5cRlypg2CH9iSh7cRnuSZ2g93V5gRbb4nEjk012O4llxwEe/3uyWBHbRGwE9Owbv5KF9jOCT1g63Sqrl0dWC8K4lphGDCgnYtzhjS29rCxaErAORkaMMeOM0b1wrmOata/bE00lfZjWSex7kE3+oUM2CeOalPsOJCK5+6/4mmwf/zkjfjsMvRhZEsyPiqA5Q3kYVUoR62bJguOW/6dPtjkwP9gf2xrerzB1I8XhBJxjs2aVh07Prh5HJyzTfLgs8PY35ETuFhE2RocTgqBnbkJ5413pTd2nJ+E/X2yEdfE5SX4O7e2YhrYOjbuScccx0gFU5MaiwlNeK6vGO9NaEAfZm1RdQ1HArT1xK8oMZEtnO+Cf/nLx/nivvvuo3vvvTdm9/f3U25uLhnM1tjLh551oiGEnotalXPMDjOc01vxZoNFx85H2Xl07PuVR/b4e/FcxI6dxs/rbTixDHasizEBB5CBPdviUAsEL5twXSOjCcvW29gs5S8fBuaXBJw4Br16APfR3/tN1Q3LNiRg5YxGnMRn9ZkZ7zfG3c+vNbKyDVG09WG83p7IfjDOqjuYFLXH9QmvJ/PhWWPHxq5P8KPNxw8fm3Z1vT7I241l6UzsPHvBM1ixYVELH6vsxyxBtUVvZ+OYLSMGOz4rela72LPsrI+Yn/RW5XPuI3PcHDhzLZsHbBHmdTtrrLG6xL988HqRAeeQnv0Y8Wdp7OVDH2bttrPyIsrnfM6c5aMwm2P2ANgRK197zv3yYbAov+pZf501Zyzn9iHx8+wNgq/vFLduGiy47pzlQ97f/OWDtUvPXhj1Npxj8eOcr7e8XQbW33w9IF41G15vNPF5o14+4+tBdPacs/Bxz8bD+b586OPWA4OZn+NjA31o5Isk0QeSTPzLXz5SU1PJYDBQe3s7/H97eztlZmaedb3FYiGL5ezKm6/piP2QmDbjfYO5zLFxi37lTyfAqcjlOHh9GexHuB2fbe1BR/si2MnZM1rBzkxQf2GcXl8M54YC+Ffa1CuPg32gFf+CtGzAv06ai/Gt3lCCf0k9++YCVW/W1+GJeG37eBwwptNYt2A2+unLM7aD/eenl4Ktm6X+0j7UnQ3n+sZiXYj99eFtc4NtrcPRnjy7C6/34l953bXpsWMTGwqte/BLiKHEC7ZrP/b3PbW3gR0Yh+MjfS+W32dSX1KMeCkFXdjOvhD7OrEBp9vku5vBXl+M/W9oYV9pJj4XO/78tlvhXLINv5IdX4k/PlYr9m/iq+jz7sV4vXsLLpR7TxUqg61jiSewrHAl/qU77vIqsI9vLgLbvxG/+Biy8AGJ9ar8gBufXdmfDnbuePzy1XAK/2J0Pok+9s/A8vybcawlXKhE8rZabGeAfTXNmIRrXs8OXLfM+NGFUhvZWhTCH5DmK9XLS/cBbGf+rBaw65ux3omv4xedyDKcB18chwP7T+suBHugUE0s5ykcC9989maws8qxLsHHsN2hz+F8tv3RDbYvE+dFWopaW27OQ6p+Rx+Ona2nJ4GdMw3rUleD/Z9ylM3R0Wyc1+fHjt3T8Yucbk0K2J7FOKespbjmRobwt8PA/gDsmInnTRXu2LHvAuyv0lwc13u78sFOPojt6JnBXhj62YtSNv6x4pyi2hrsxLGkC2NZE1aeALvKUxI7jgT9RPhR5j3xL9/tYjabacaMGbRx48bY/0WjUdq4cSOVlZX9qx8nEAgEAoHg3wwfCu1y77330s0330wzZ86k2bNn00MPPUSDg4N06623vv/NAoFAIBAIPtb4UF4+rrvuOurs7KQf/OAH1NbWRlOnTqU333zzLBGqQCAQCASCTx4+lDgf/wz6+/vJ5XLRmD/fR4b/E9l8dfxWuObRZ5bjTXEt8OUwQZmfMUspyG07KpCXT16OPHzDUdQQ5E1EzUdzhdI7RJhoT8dEYIn1aFs8bAfKQhQw2OuQE3QvRt6vtTKOB3ajUn7eWNyBsns77rQIJyNfaW7DZ6Xvx7q1Mg1BsksR2IankAsdyOFiVjT9aWxnRTv6ZYhx/tEMfHbx/yh9w6lvYv8ZG5i4kYmnIolMJMKEG44U1E5cnIc7tF59Y07sOJjFfOhguxU6sG76ALaT1yUxAzljI9tx1NuhFOS5uchHG9i1fNxqJqajqEEOuL8Y543Jg+dzZ6p50VCBWqWMKah16KzAPzKSp2NwwZ79qF8IJ2DdnFU4fryjVdvszexcEdY76QjWO+hiAkW2yctbgn2oMzPRd4saQBMXVMO5mr+huGkwF+8tnIZrSXU1aiFsDTjnAqW4Oy5es5fABMV8N0Trk4Vge8qxLPNRO9hRfDQltDCt2yVKy+YbRO1R6ka0XTfh9oh2L2rVBmvZjqIatuPkQtypNTVT+W3PFrZuOdHHtkycM9pBfFbQjdenjceddp29uCsjMc7PUzOw/7bsxZ2Olk4ca4HRuE7petHJWjIOPksNE0/HbVCacC3qKnYeQ60LHzv+Inz22Fyckw3bcEvRlKW4ru3Zr8aypRvbpY1H/UnCBuxfY9zQjAT9dOCv36O+vj5yOtnuMAbJ7SIQCAQCgWBYIS8fAoFAIBAIhhXy8iEQCAQCgWBYMWI1H6OfVJoP5+vIMXUuRu5MH79/ugv5yLRxuMe8i3F8OhZ8xXIYuVHzPOTWg2HU6A52qeuTK/Bc9DLkZft6Mdom97zJygJBncTr0+ah3qSxJi4+AnuNNLJ93TxglYvt3R/MwcqEkrAuPAiZqVfdn9DMgowwM+Bip5kGZCgfn6ULsMYkYX8b4+JfJNbipSwMAE2cjdqXzoeRG+8txmdpbDt8QhP6pXeisvnY6t3P4lUwjUfYxrQuHSziJaNIP3UVxjh48aSKHBsZYKS9kemNWJA4zi/bZp57XNst6POe42rvv7mPBVPDYJrUX4RaFlMG6g9CAaZz92Bbin+PGoDKb6h5wHl0Rx32X38JjiVLCj47UsciYjI4mC7L1q382DsOn8X1BJYeNpbYMJ6w9BTYXNPT9sAYsIdWeWLHvrdxbJkGsL81PdbbMxP7L2Un+s26AjUBzQ2o24oPOsYjr0abcI3MmYxatKbDqG3RWHfrmOxKPwp1VvpK1Ucai220dHQl2K/tx4i2SQfwYe7TqOlpXoh+SJ753nqkYAbTdLXivbpirBuPqxWuZXGaCvD6cAOu79H0OD/34bNceTgnPB0sgigLvGlrZb9FrA8COUx/0qyed9a4ZhoQwxQWTXmXWuAjAT9VPvRd0XwIBAKBQCAYeZCXD4FAIBAIBMMKefkQCAQCgUAwrPjIE8u9F4KDFtL/X1Kw/tF4zlaDug7faMVf2brwfardhhk1zZ3Y5FAu7o/+xi3Pg/0/x1lOkx0oYLDMVnugNT1yfJ62c2f2M/ViXUx92K6UE8hf+2fj9bYWZQdKkNu2VuO1AxOwrKEM9NPCJUfA3vM35FIHCvH+qYsUf13VjXy0pwe5zIUlmNvjWBdywr5u9JO9jvGVXahX8I9RfdaTjlznkvHICe9twf3t0bHYbl8O8rrjilBXwxF8TZXXO3BujYcvG322cg7m03jltblgT1iMcSQ2/Q7Pm+Pa+q0bcZz+tXk22I29brBDLClWbxf6PDkNhRvxGg8iInO/ejZvl6OJxQWwI6lvPIjzQjcN4wZQL/Zv/VWYG8ZSp479+ThfQ4ksERzjvgP9eL54ZgPYnYM4VnutuF544hKPOVj8EWMr+9ttngfMAQ/GeenyoR/qm9DHqRk47rsaVF3cKIsgay9qPpJvr8Nn7ykAO/uzKI6q3IbaJyuLSRQepx5oOsziOrAcNY9d+xewy5vvwgsiWHZyBo41rjeaslTlwDr5OMb52LAUM83yTMEDmPKEPBNxbOpC6Lf2TlzPZy9R68dpD+pghpIxaNBgG44dA4u1xHNahRvxep4MUOtW5TtHe+BcX50bbNMg3nv1pagPe/kVzHI+fxlm2N5Whz+qgSxVno3Fl7LNRW2bbxeOW2t/XPLF4AeXkMqXD4FAIBAIBMMKefkQCAQCgUAwrBixW22v33gjmR1nPkNtO41b0IxVLFRw3Jan0CB+GjN24yek3A34mb3us2wL6m78BNzHUqwbfCxEtl2d17HwuRlr8ZNv8u31YPcH8FmW+91gT/3lQbBffhM/w4ddcXVLYFsMT+OzsxdhCOSmnRgiO5SM7Sz6C4ZzbrwYPxnqJqlPp+YtuKWqbxr6wZ3Ct6Sx7astLPzyCbadOQ/rpstSdUty4TfgJCvST/Xv5IIdyGRhxBOxrqbD2M5AMtvSGPdscxULzV+GWw79L2KY8Z5pSEfYmrCdYQc+y9rJw84rP2gs5LzVju14bNqfwf7Mq1/F69tZGPIJ+F0//WUcm4lfUuOnZR1SWYO52C6DD/+mibC6pmzGsdl3MT47xOjHJVNVqOmDf8EU6nwbd+pR7N/WeSxM/Hr0U8OluD5YGG0bcqo+ydqB7ewej/0XSGJpAcxs7KTgs7UI+9uPUUbxfxrmv4Sn6lfinJg1tg7svUdwzVw4FcNptw/hnPX+PgfPqywCFE3gKQmwXaWjMY39qX3IfTiLe8Dm8z1+2z4RUShJPe+GObvg3F8PIL2YnY1ll7hx6+z2DTheiP3aRXn6hSw1VseOwrICEezv+kZGTbL0Cs51jNJDBolMA++9ZV2/BNtVmIRb470hnJ+17UgRaSw0QvEDuAZ3zcG692LkeED8bxwRkZ3RrJY4CjAS9NORP0l4dYFAIBAIBCMQ8vIhEAgEAoFgWCEvHwKBQCAQCIYVI1bzMfqJ75L+/8KrW3fgVi8fS7mecljZbYuQn7pv8atg/+4XV4LdO4GlGmfhmgdYmuzEWsYJx1XNxLagTbz+ONjVHsazsXDcYxfUgX3sFPKw1haWgjspTgNgYammU5FH97cg/2jyYjt4yOMg29JIHiRHU8YoTnJwN7YrUIy6C62XEasMOeOQW23udGNda1BbYW9VfdY7CzU8SXvRR71TmR4hEa/PTUdutY5tf6QA8pvGPmWHk1FfYEzAsrNSMAwxhMMnIms7csjFF9aA3fQX3A43eLHibRPexDlRchum4C5PxrH3441Xg21rxnb5stBP+iByxlnblc9bFuE5Qyb2t2MrarIGcRiTnmkbgkVsvDC+2nFQ8dsDBVhPrl2xzkFuvK8f66KxcWzNxEkbDGKfRAbVeDK3nVujU/Jr1PzkPIMhzDdumYplJ2JbzCxFe8SuytexbZlcuxBOYSkKLGxCsxD2pj4WKj6F9X9cigOuVdGxLaRRLwv1z+pmz0AfJ1ixPAMLM99xUs0TXQZqz1yJuK4Ft+F8jbClJqkS29U5DdudPwe1cM1vK42YbQ5uMc1woG7ixCnUzRnZ2pLyGuoyzAPYztb5bBtwXFXtLdjf3jF4r2ZiaUHS0S/29SzswyL0o7EO6xaf8iI6DvuL6yjTMnFdy3R4464N0luX/l40HwKBQCAQCEYe5OVDIBAIBALBsEJePgQCgUAgEAwrRqzmY8Erq8iYcGa//2AQOSf/G+lgewsVYWVvYyGQ5yOnH2HheI1vusH2ZeJ5P4sLwWMz+NPUs40ZyLtNHoX738c4kEN8dQ2GwPVlIj95Fs/LTEuu4iD9zSxVuAv5Ry2IfnEfZvFPrsXU83Uvo94g7TLkRls9is/zM07QWo18YmAcC/1+HDUchjm9YFuMzA9rcA97f1wIA64fOCtdN4t4PFCMfjF2Mx6f6Th0IZYmPS7VeNbbeC7va5gyvaIe42FEujF+RWIuhpnu70ZdjrET+8gQ1xZdKfLPOcketBPQrliD8Q6ijKY3z0OtxMAQ1lWLxrW1ifUfi31jnoL9OdCH1+dk4nnPuiywTYMs3klcHIG+6zE0e6AKeeVwCvav6zCOTe9sHIuJe7BufaXY/84s9bzSNNRwVD5dgmVdgaH5Ww9iGoGbL30b7KefvRBsaze2u78oLn6CG+vlTsP+HziJYeETmrBPHrzrMbDveubzYAdTceK4jql5kXoU9QLts5heYB7259WFGMr7uVPTweap5gnlDKSPqwrXcEyegykITrSjj3UHMW3Arz//O7C3DmCfrVmzGOxQovI5j9NiL8D5qtvuxntZszgyFzSD3bYdNSPBOA1f5jssFlIJ6kPsLXg+5GAakXHYn0l52EeBd1ArMzhOLS52F86R6GGMyxIuxt+5+JpEh/xUf9v9ovkQCAQCgUAw8iAvHwKBQCAQCIYV8vIhEAgEAoFgWGF8/0s+Gox1dsZyu/CY+judqPlIK1Faio5kljfgMHKhFg/TfPgZv4yyDMqYhzEomgaRY3SfVOV5krCe3X7k8CuqCrDe8zvBDh5BHm7BkqN4fxsGTPCfdMeOTUzrkHgUyVKuhSAm9ancjim2zUgxUtcAtiXZoXi/6BokO8M2LDuQjPoBDv9xN9gDCXi/sRivt3Uon/ePR44/fTv2QedslpunDxsWTmK5Xrrwfh3jo+N1N0MZOJb2HBiL9WxhORB6GI9rQn5az3KiGMcgr++Py3liPYL31qRjPIuOHOwT71hsJ7E4ECUsd8QRXzbYCQmK94+047P42LokH2OO/G0j5iRqDKOGZ+VnMR342rVlYA/ESWeCHTgOHeMw5oC2y402+/NqSVEV2PscmPtH70U9w8CAsmcUYW6mQ0uQs/c04PzVs1gMf371ArCdHXi+6JZKsPdUF8SOb5q6G8699ptFYEcm40DtZ3Pmt81LwE7EplC/Acdq2lWNseOasTgWjGkYB8LFNFrPV08FO8RipxiZRihYiJqSSJ8SJKXsxw6sbsU5lnwxxlZpTcfx8cVtt4BNLK/UxKWodTu+R62DRpZ7Rb/VDba3iA18B9OTWXDO1VVjrqeMGuwzR7PSXXSPx3Hoy8ayND1bp9j01qxYN5MBnxVGWQfZq9TvxRCmBSLKZ7m6Elh/bU1Wx4EP/j1DvnwIBAKBQCAYVsjLh0AgEAgEgmGFvHwIBAKBQCAYVozYOB8zX7grFuej7ThqPKJJLJ9HiuLGg2Hkwn455Rmwv/GzL4OdfA3Gr+BofRt1FskLkWNsrlU8r4npCaK5yI3ZKzCmgH8Wcqfudcild85DIm9KcQPYYxxKM7LpMeTVPRPx3uzN+J7ZdgXmbvnFnGfB/q/vfA5scx+W17JQ6Q9S5qBPBvyo8fB6sF2W0yzeRT0OwZ5JTPMxiHXPLFPxU5oOowbHkMtyP/Qid6r3s3gnY1gcmLeQt++bgnxn6f9T1/f88tzv7i4L9n/9doz7wWOQpBxHnrZpGYszUK/G9lA+9sfoIuyDjrdw3AZnoH4k0oDcuPsk1iX1Rhxr8bqr+lbUbBhasD/1OD3JjTIL8ixnuT7exrpY+rHd3ZMU9569Ddvd9QXs78F2LCt/DGq2WvdiTJEoV73xnClxcV/GjcE4Hqf3oV7EUIg+tuxEXc5gNiuc5Ujh+ZbMcaEZhti9YZYXxpqGJH6wGf2QchD1C67P4bqXZUftzJ63JsaOea6PRAc+Kxxh2qaX3GBzbVQwCduiK2RJsU6pugczsL/NPB/SolqwqzZifKIo093klGGsjfqOZLC1trj1gk3vzBIcSz07cO3JX4JCmrouLFvH4jSFT6MuK37eBDNxElkbUMMXGY9jLdrEdFgsRtSo6Th223aijic+t098LCMiIjKhXsTixN8OZ7webChAB1f+XOJ8CAQCgUAgGHk475ePrVu30uWXX07Z2dmk0+nopZdegvOaptEPfvADysrKIpvNRuXl5VRVVfXuhQkEAoFAIPjE4bxfPgYHB2nKlCn08MMPv+v5//qv/6Jf/epX9Nvf/pZ2795NCQkJtGzZMvL7/e96vUAgEAgEgk8W/inNh06noxdffJGuuuoqIjrz1SM7O5u+/vWv0ze+8Q0iIurr66OMjAx64okn6Prrr3/fMv+u+Sj567fIYD/DJQ9VueGaCMvfoPMqHtAQQK7L2ol2fOx+IiKTF88nVSHH2JePHKOvDLm2kFfx3RPGIo96eiPGzvAVIsmfkekB2zOAmpCAB/UKPLfLuNGKx2t5E/UE/hTGq7J4FWEn/oe5B99DJ16AX6sONyNHSHE5ciayHDYHKgvAzs3D4Cl5iZhnYEcFBiXQEpDPNvRiH2TF5T1gqXqoeRm2y16HSUy4HsG6GOvm6UfulOdjcZ5S/Hb4AuTJoxUYY4b318VX7wF7w3OzwU69CP1YX5sGtiWe72YN53koEhpZjIJLsZ2fLjgA9lM1M8H2+9Fv8eN81DocKz3XI2cfqUStg2WCB+w0B17f1ofXB+rQtjer53nH4xxypKDmw7oW+8AQRL/4k7HuA3k4XpzjcGz2dqm66PtxHC6Zi3F49rSyOXgK6xLJRK7cchrnN8+Z4dihxmJ8/ioiotz1OEfabsM/7iZl4VgqSsCYQp1B9PHGfRPBtmaoPvJ147qUshf9sPzOrWDzXC62TahtGMgHkyIW7KOoM24NZnEjnr0U/+j90bzLwW65GjUfrnqc8H1fwtxAfQ3YR0kFqv/TEnCcnu5ArVO0EXU1kVQcm+PyMBdQ1VHUYXFcMEeNp62bMRdT2In9XVyC2pXKalyfJ4zD36LqLfhblHYIy8v9uspLNRDGNa/R4wZ74ATGzor/bYn6/VT7o+8Nv+ajtraW2traqLy8PPZ/LpeL5syZQzt37nzXewKBAPX398M/gUAgEAgEH1/8S18+2trOKO4zMlgkt4yM2DmO1atXk8vliv3Lzc191+sEAoFAIBB8PPCR73a57777qK+vL/avsbHx/W8SCAQCgUDwb4t/aW6XzMwz+57b29spK0vtp29vb6epU6e+6z0Wi4UslrNzfwSDBjIY3716o7IxNkNLleLGw2nI8YWHsOz0/ch1NS/B96/LP7ML7OdPTsPyGBdur1V2xzsFcM7tR57WNwqf1dmNvCsxfYE5CznghM3IMTanKL4yyDQehtGoTbEz3lW3HLlt3QHkM+v/hDkUjDlsr75TPa/lNUwGoCvDujQ2Y9n0MmoZbDdhXd0JGEcgowh52s7titdtX4k8uj6K9XQuxLHSuxdjxmjbMa5HXjnT7fTjXn7rpWqvf3szcp8Z8zEOQHsd7vN/eQ9y4U4W58OzFnlbC1aNwg41nnIm4b791t0Yv2LS51CPsPcN5PRPZ2DhptfdaF+OuV48LUp/0DsWx7GvC3UypjHIlXs7WZ6ZdjYWWR6KlKPYh/4rPLFj2z6sp68P14jBaUwbsQ7Hoi8V6546HrUwgddwfNjjaOvscvzDaPMO9CnPWWJmuUGoDzUewYk4v7NSUEPUka60FvpReG3TElwLTCxnyeGNqKPam4ucvyMJy9O5cDBGTqi1yTAG52PfhbjGVg7gl+5INetvrvFIwD7K3oznx35T5bg5+GfUPtzaeBfYc188jHXz4Bf2pm7UdGg1brRZzKjVpS/Gjr+86RY4Z+7EsRZJYrldwiwPTQuuc5qZJ4pCbK5Sa65tHMoPbHq8t74b1xbnMfxdat9ZAPbKu7aB/bfoQrD7OtU6N9CEWo0vL94E9l83LAU7XvsWGcL1+Fz4l375KCwspMzMTNq4cWPs//r7+2n37t1UVlZ2jjsFAoFAIBB8UnDeXz4GBgaouro6ZtfW1tLBgwcpOTmZ8vLy6O6776b777+fxo4dS4WFhfT973+fsrOzYztiBAKBQCAQfLJx3i8f+/btowsuUKmh7733XiIiuvnmm+mJJ56gb33rWzQ4OEhf+tKXyOPx0IIFC+jNN98kq9X6XkUKBAKBQCD4BGHE5nYZ+42fksFy5oXF2oVV7EM5AkXi94Wz+AeGROT0IkP4vuVMQ71BeDfy+L5RyOvpk5AbdSYq7lTHeFfvMdQ6cEdHbCwWB6MQHaORAw4cduOzZyi+urMVuU33QcwF4BmP8UvIihyizYlxAvyDeH/ydtSj5H1Off3qWV0A5zqnshgRk1EDEA5gH0wsxD3rJ3YjPx12Yd2NcXE/IonYjsRTmGciuRL7v3s81m1oBvLZSRtY7AUbjifLp5Sug+duqWlHHYWuEeMjRLKQDzW0ok8jDmyLjsWsyditjid9/RCce+voBLBNNhbQpB51GbY2LLt/IotBk+3BusZxzi2tOEe+OGM72M88eRHYIZQnkBVlFuSdj31gPol+i4/NE07DeqZtwXE6+ouVYB94G7UPSdMx3kVHLc5RayuOH5qquPdwFWq0tHysd+paNnZuRL1RVxty6Y5KrPvAGBzn1hRVfrgWdRRhx7lzu2S4UCdl4JqBdhazIoLjYe4YlTPl2HOlcI7Hr9GWoH7M24Z+MnnQp2E2Z9N2I/vfUabaVj79GJzbcHg8PtzI4rQwLYu3D8fSFRNRI/Ly4SlgG7rV+mDMw3UrwOKd/PCCl8D+0dYrwebxUHoX43phMGDd9XE5bVKPYP/2lKAPfTk4VjLzUaPVXo1rkWbH8tIy8bdFH/fblZmAYyfKOvzoESbiib/W56fGb3xfcrsIBAKBQCAYeZCXD4FAIBAIBMOKEUu75D/2H6S3n/mMaTuIn4zvvvUFsO/frkLsGlhae42FNJ6Qi1sUm5/CT/xzvohhp9dtn4rlpeBn3/gQyUG2JS39Dfys3j4fXa3Z8FOYez9+hrVchls3e73oh2C3evbCaZgTfdtJxk2xLag6libZ2Ix1NQ7h9Xd/5iWwV2/+VOw4Yzu+ww5dyz7pbcTP9H2TWXh8M/rhJ3NfBvvHaz4Ndig+NLwLy3K4sA+8PfjNv7QQw05bDXh/ywDSV92HcbtcPMbMxrTzRYnIJxzsHgV22xHckhjNwLFpS0Db78PxoG9R/W3pxv7xZWB/zpmD9MOuA+PA5uH0edoBCz+foM7bSzxwLhDEz8taFVIEWbNwzvW9jFuKh7Lw2aEklsI7XX1Kt25modc78dr+G3CLomkd9ucARkAn23gP2Jx2DaSq8qMsDDhPPW5KYp/VT6AfAmk4zh2nca0qux7Xnl1/Vdv8B2chnZDkRLuXpQVYOLoG7IrncMuqdxyjYdmvwPwpKtz2zj0leCmjnvVdbN3qxrHDUxo4mrDPPOPw+vhw6+n78dqWT2G9tRDeq2Ph2BPq0cfWbmyovQP7pGWhuj6Sge3UgqzsGqRwIzORrtDvx7G68votYD+1Abe7xvvN0cQo+euRLuzy4Ngy1CAllH4A/dbGQhJwiUDIE5c+oRDXsdEutI//CSnewYuVdCEy5Keam1YL7SIQCAQCgWDkQV4+BAKBQCAQDCvk5UMgEAgEAsGwYuRqPn56P+n/HhuE6RUMLCy1tUOdj7JI7RGkI8l1GrmwgAvLdlyF4XmHnsfw2l/7+hqwHzqlthWOTsLtTrV/Qd1F70R8tmEQ3/14eOZ5l+K2sN0vTsa6jVccc0ke1rumA7damfchR8hTyXexrbrWRuQz+davjpmq7pEC5Lqfn/dbsK95BUMik5vHFcdO+twSDAXMudHJsxSfXbUWfTw4AbnN9HS2XZmFzx5ahFutLbtZaOgSJKzjQyzrwmzsNOBUuuYuDEv8x7cvADt9LPZB3x6sW95C1JQMhpSfmlswvLLeg7qLqBu5cZ4O3sDGWvIU5JTbW91gUxy3nrIPefSeSdhuWxsLv16C4+OsrZoBLM9+GsdeIFmVH7XhHFoxbw/Yr7wxF2zXVDbOa9BvWiLTPjAkVKoFZbAQx4KR+ZxvlXaMQv2JtwU1AFMm1OP1Jhy7Ow6obcLWNvSRYy72V88J3DrLdRcWD/ZRkK178WsJEZGxSbU77GTb8luwLvOuxG3f297E7asmnGIUno3aCBdLpxAMq/JXFhyEc88/eiHY/hRsR8oxXKfa5qIf0g6gHzouf+9w4NmpHrAb61i+AyOWpWeh/g3ZqMsJ9eGPkz0Vz/ua1dqzYgGO6w2PYYRwzzRcQ90sZITdgufNBvSLxYDjvupwXELXFPSJ1ovrs2bCdmcWqN+9yGCAKlY8JJoPgUAgEAgEIw/y8iEQCAQCgWBYIS8fAoFAIBAIhhUjVvNRcqcKr+5PxSr+4trHwf7aq7fEjqMsjKzrCPLHQZQ2nBXSPHEhxtboPoJxHlImMa71kDo/ft5pONf0v6PBtq5sB9vJwnOfasE4EPYEFvL8pBvs+FgPwZmM89uK2oUoy+ITZVoYjUWVjo/rQHR23A99nN/CGGKA/LlM08H24hu8+DB9LoYxvmzscbBf3o2p6O0Z6nr3M9hOPetPzxh8lj8F22UtRk1ISgLysA2tqBHIy1Ihs+trWPr1RnRy8SVVYB/bVgR2OA/717UDw3P3TmGNiaPeMwowdHd7A9ZTx8Jl85gUOhtyvq49LN07o2vj411EWLh7HjPG5UYf9te6sS5upp2wom1l9kCDqoxmOXdacmsLznc9G4q+YuSzEw8gDx9moeDj582C5UzbUI/z+6Hpz4F9+4abwTb2s5gTXdhHA2NY/Bu/un7uTIzbsvM4jiWLC8dSJIzP4nEdUl7BuBAdy9EveRlqfNU1odah+uI/gD3tZ3eAnbAU1znDH/H+jpVYV/sOdLq3UPUx18GZSlFHE2SpGni72hdguw0DLFZHMxcgqcO+KTh4TAmsf07jwmdga6S/GNuZtp6NNawqaZ9SPg9tRQ3PQBHOOUc1tpuve/2lWNfiIoxvVNWCa1c0Lu0Iv5ajYSOGV9fFTclIwE9VP/uuaD4EAoFAIBCMPMjLh0AgEAgEgmGFvHwIBAKBQCAYVoxYzcesF+4iY8IZjqxnALk1XycTGVgV4eVw457xhOeRd+pejjycbR+W5R2PPF/Rk0im1XwaxRIJDYpb5RxeYAw+a3w+5rioeqcA7Egh1t10CusWGodcerRT8fTfWroWzv1s7RVgpxxh+9uXsrwFPuQQE+rQ1rFwCOE5aq9+SiJqNlraMD8G6ZnegNnUhVzonFnIb+/ei2nRs0qULoePDTqI/Z21pAnsxn2Yb4UPfr6HPRXTbVBHueJSNR/y6vH73YmI2pqZH8IsD0WQxa/xnzsnRihH8fKGdhbQhsHWhmXby1HL1F6PGpGEDJY+vIqlf69X5Xlm4NixNuKcCLpRl2H2sNwdJahPCrNU5UmHmUboChWrIxzBc556N9i8/wrGoP6g5zXsf38Z1iXKyo/EzTFDGs7njGTUH7itOH+bn8e8UQGsKt183Xqwf7tjCdj2eqVfGSrAwWDqZvNzNPafVos6irAd+yTlALaz5yJsmxYXe8fUx+IRDTBtw3hsN3Xj2EwvRp2c9SGcF21lOH6McU0ZnIj1MllxIYqydiYfw6rYPodrbkMbjnuLDf0arUQNWTxCLvQh11Hdu3gd2L954TKw9SwukD8bn60fUuvJtJnVcO7QToxnFHbi71JCOvZ/+CjO36CL5SWyMpEIk77Ew1HNctigSeG4vFBRv59qf/g90XwIBAKBQCAYeZCXD4FAIBAIBMMKefkQCAQCgUAwrDC+/yUfDdpOp5LedoZvTcxBbrVsGsaB2N+eEzsO7EFOr30+coTGJuSXucZDN4guaV7M49pjeUOjFA9oyERNBnXhszofKwD7c998G+wn38DcH4HRjO+swfKMxYqv/vlLqPGIZGO7OqxI1C0tPQH2+t2YN+YsMcR8D5iJZsVX+l7E+CSJl+K1/iNusINpyDca0rGdB9aVgp15guWVyVS8bKifaR/ykUftei0H7Ms/uwvsvT+eCXZbGeo4uidi8UaL6v/0zF4411KDMWHSWCwOrlfo96JexcbiusTHtyAiSt2k2tpdjtcWZSOvnpPgAXvLtklgO5uQ5DXnshgG3Xjeu0CNbdsxrHdCGeZP6e1DHj4yhDFEQl7sM54jJ7AM5/tgo9IIJFax/BlpTE/Exm17H+ZTCWWzC1ifZD2H810XUfO76dNYT88QzsfunZgHyhbBZ2XtxDn5u7SLwNazECaJDfHxLnD+Rhd5wD4rPg2Lf0H9LP4J03C5nHi/YaPqM/8VLD/SSQyWFB3Asq29TCPyB4zz0XAp+nHJXMxhteloSex47G9x7mf+vA7s3VQA9kAfaja6D2OfGJnOyj4JNT99NjV2o6nYX5YaHMcmlFnQb3pQ48FjIwVSsINH5aNGrKVKrR96NpAjVqaj6mSxkjJZzrJ09Ju1heV+smDd0var+6fftx/OrevENbKwDHNOtT+v4n5EgucQjzDIlw+BQCAQCATDCnn5EAgEAoFAMKyQlw+BQCAQCATDihGr+cjaSmT8PyoxmOCGc/tW4LXL89Xm7jWDmAfE0II8naMYefo+D/LX7pPIWTkbkAtvciPXllyqeDvteeQ2uy/AfAkDuViXP7+GGg/zOOS6h9qRO+d8dsCjynNPwHaNSUYevuIY5qF4+zTuG7/nwjfB/sOfloPN9QdDKapt2jxsp9aN9baPx3a5XmGxV6aiXyI2bGjrYjDJWKfKN+UjVx1pRR5+9vWYj+OtZ+eCPbiUcaPt2P9RFjci2KPqGmF5JMZ8oRns+g7UH43Lwlgb5ucw3sHgCvQjuViOk7jxU5CFfHGrF7UNp2qR677ywr1gr92GPG60wQ22je3l/92c/40d33Xoy3DOaEAf5j2Of9M0fh7jQHDNiI/pdMJHUFOgS1Ll81xMfKxoLLdTAtNomcZ5wHY8jc9quw7rGo7TThibcZzaT6BtvqEN7G4vzgNPCdr3lL8B9p+qy8DuSFZ+MtejTibYh2PP+TT2Py1C03kK163Bq1HHYXgbc4mkf64+dlxZj2Np9HrUQjQvxroFmKbL9TXUCPS8hfFPan6EGi+6Us3Bmuuwnb7/wmtDF+KtiV04HoZYThStj+VfSkat1AGvWsP9drzWX4jzM9yB+iCeq8fehnXJvAhzprjMONbaB5V27thrGNvIidIUcizHscb1R6Ye7O9QMT4r0YG2fq9ak01skiXW4bNrjHlgZ12pYqmEBwNEmPrnPSFfPgQCgUAgEAwr5OVDIBAIBALBsEJePgQCgUAgEAwrRmxul6vW30KmhDOc2p4DqE9IGOUF2+eL496YxiPnbeSvfCnI43XOwv3RugjydkWTMDdIyzrku4JO5b5QIuOfHcg3Whs4RwgmBVko/Ag2hYwsjMjQeBXrwX4cL045js/uvQ195m1lHLER6+46jKR//0yW+yEuHkpyrgfOmQzo02AY+UcdE68M7UOtTN4i5Ihr9+aCbe1UfRRwY1nhAqxnNIDPNrdiu3LKUKfhDSB/PbgdY3cMjVF8d9o2LKt3PJiksVd7rlfQsbgOq1c+BfY3192A5cXpT5ZMxTgtW3ZPwGtt+DB7LdZ1aBzy1+692G7PZBw/8TlSOr0YSyF0HAduxMpiFDhYQ1luH1syyw3CMDVL9VF/CMf5qZ0FYDsmYGyVoQOoZaBSnAdXjj0C9toX5oHty1Z+mDWpBs4d2D4ObCuLjcLnr3UW6nQGj6AmyFSK2ijdDqVHcTSjD9suxP41JWJ/Wq1ML9SIfWRvwnkRnoF+McTN4SGmLykuwHwp1QdwfvJcMK4arHvnLDBp9CScg7UHVP6diAvbmVSB63fQhT7n617QgXVpu5gnTMLz8fPEwCRYvky2vrOQFqYCFGYYd+MaOzABCzR2shhSo9TaFenD+apLwHZZTuPgss3AsRXajuPe1o5171yA5aXsUn4dHMVyTqHE56x2+0pVvaM+PzV+6ceS20UgEAgEAsHIw3m9fKxevZpmzZpFiYmJlJ6eTldddRVVVmIGUr/fT6tWraKUlBRyOBy0YsUKam9vf48SBQKBQCAQfNJwXi8fW7ZsoVWrVtGuXbto/fr1FAqF6OKLL6bBQRVn9p577qG1a9fSmjVraMuWLdTS0kLXXHPNv7ziAoFAIBAI/j3xT2k+Ojs7KT09nbZs2UKLFi2ivr4+SktLo6effppWrlxJREQnT56k0tJS2rlzJ82dO/d9SlSaj4vf+FJM83FiF+4Lt7cg6TRmRVXs+MBxvFbvQI4v73+R6+z8MvLNhm24739oFgotLIxLddnV/X2bcT/8WdwYi79v8LH8GmNZnI9OjAvAufILJyve/+0K5PzTd2LZXZci31gyCveJnziYD3b6Hnx02wKse2mp0sLUv1UA5wKT0GcZydiulibkuvVWxl+zHDYJ01Ec09OluNTUbciberEqZEd6mnon4bP0idiflpP47Mhk5HFn5DTGjuu9GKejfyP2/1AW+iz5KPZJ91Q8n7cO7frleL3eH/e3Qjr2J/eZGcM4kHccS+ZhZDoMpnUydyG3HrarsZfQhH+zeEvQh9ZG5Ku1iagnMO1BLtyXwTQgRVj5/CQVw6buDZzfpnmo8fBX4Nji+hN9Efan/girSxb6ydyt1osw03QlF+GzozwOzzuoZQpMxnmRl4738zxEAbc6Djmxv6Iu1p+s//QDTGfF9EaGXKxL0IvzaP746tjxgbUoZuJapkAprqF8LAYysK6jNmBde0qxrta4WB39C7Hsl+c9CvaNP/862H2TcCwaEtC22VDAENnvBtufqvxsYTlq/PlMBBLE80lZuM4ZmfatqwbHZsoBvL+rTPkpZS/Ov34c9hRKZfFruvH6UDq2O/EY9q+9neWCSVJ1MfhxIPcsxHa73Dh2rHF5viKDAapY8dCHr/no6zuzSCQnn3FqRUUFhUIhKi8vj11TUlJCeXl5tHPnznctIxAIUH9/P/wTCAQCgUDw8cU//PIRjUbp7rvvpvnz59PEiWdSf7a1tZHZbCa32w3XZmRkUFtb27uUckZH4nK5Yv9yc3Pf9TqBQCAQCAQfD/zD4dVXrVpFR48epe3bt/9TFbjvvvvo3nvvjdn9/f2Um5tL1TvzSW89s51Ih1/laNRVdWAf3V4UO9blsE9ELFV0yyL89OV+CT8Rd03Dz1H6BvyEaGjD0NDdyerTUqCAfQplNInjFD5rYDReH+7GsnmI3Pw5uO138y6V791V6IFzvaVICRhqcWvWMS++5Dny8YtTB+Ens+RDWJemmoLYcZClNTewz426P+J2Vf1V+OnTUYE+9k7BPgzWYlsS61VdZt2O6Z+3No4BuzcDfbp6yfNon7gEn52FnycdFvx8ueug2l45ddJpONeaj+20N6LPumaxT6V9eL7hOnxWeTGKuTdvmRw7Dvtw6lowuj5F2cxOzETqY1neSbDfqMNP634H+uHPZY/Fjr/w5zvgnI59fjZNx8rotmD/5V5ZC3bVtgKwB1uQCjnWo/pQz6is5awdaxrmgG1mcyj9aRxrjZewOWth/MQ4tY1wVg7Ov0tSjoL9wH5MqW6bi364Ni4NBBHRcxvmg+1kn7uDcSnYjf3oY2cV9o9nItvW38Eogwz0W6QR54WBccQ7Tql5dMk1OMf2/3Iq2N0uXFuMbOf0lXOQw31+COl3zcTCIeSquurbsezfdWHceN1FSF1RJ24Dj4bRDwMdSGUbHejzrO3K7i3BoovyMD1C8yZcQ/sTcWxlpzDu043z21OK29sTTqvfh95F6ESnE+2BEzinnNVgUl8+jgfvWOaHKSzsfNx6Yk7CcAWmU+iz2aW4zd9pVNcHBkJUQR8M/9DLxx133EGvvvoqbd26lXJyFE+ZmZlJwWCQPB4PfP1ob2+nzMzMdymJyGKxkMVieddzAoFAIBAIPn44L9pF0zS644476MUXX6RNmzZRYSGqYGbMmEEmk4k2btwY+7/KykpqaGigsrIyXpxAIBAIBIJPIM7ry8eqVavo6aefppdffpkSExNjOg6Xy0U2m41cLhfddtttdO+991JycjI5nU668847qays7APtdBEIBAKBQPDxx3lttdXpdO/6/48//jjdcsstRHQmyNjXv/51+utf/0qBQICWLVtGjzzyyHvSLhx/32qb+7OfkN52hu/T7MhPXTP5ANgV3SrkeWM7cmH5T+LHHX0Em9t4EUtVnYbPMvayLYdJeD4hTWlKhrxYlsOFPF1kD9Zt7DIM13yqEzUD/kHkdY2tWH78dioDq+fC+cgv8/DbluxBsM0s9biXhVTW9WBdkscqrrWnCnU09gLUjwx42DZQO3KfZjM+e6ge9SZRJ563x/HdQbatN8I4XmJhivXJqDeJ9mK71n7qIbB/3rYU7Ld3K52NcQjng60NbT/TwjimYAhkD/ObtQvrHh+6n4jIMFptEy3JQP65oc8N9sAxLJtvvZtTgnqVE88jwa1fglx6X5Pagq4LsZDWB9H+4X88Dvbdz98KtvsUmNS3FPvQUIkcs2Gy4s7TEnGrrPn7uDW+/4c4rnv2pYOtMf2YVoBzdFSqB2zf/2bFjv3J2M7BPNRR5E/BlOm9LM354GGmN2N+6J7CwnfHbafWenDumz04Vnio/mkXIy+/fyP2L9/+amBbc0dtVgU2fRrHzoQ83L9+vCkLbGLpE3jMgdQ3sC0dS3FOWk8pnYdhpgfvdWD/1tVi//I0AlHG6AcKWFqBZBxPva1q7UmsxLLC83Bdy/kZ+qz6y7gGW2vYes30JSmTOsHuPKW2ZsenUiAi+sMlfwT7vpMYO6urjq3BWdiuQBVbU1n5Ubvq78RT2I7BXKaDzGCpNuL6Nzrkp/ov/OQDbbU9ry8fH+Q9xWq10sMPP0wPP/zw+RQtEAgEAoHgEwLJ7SIQCAQCgWBYIS8fAoFAIBAIhhX/VHj1DwN/13zk/OpHMc0Hj5dh8CBbZPArzsk0Hnm5LBfahm8gD1X1OYwpYAgiPxnORD5S87MU7Z3KNk0497Nb+/DZg2zPucmFfGSkDTljSy7yeHRQladNwTgO/m68N2Mbvmd2zEGfjpmAfHXN0VFg8z5w5SkefuAkalmSjuOt/cux3qZ96PPwLKx7gGldaBD7O2uM4koH3kAt0TWf3wz2up9iXIDWpch1J55g4dnHsxgklXjedaEKlqf9CfnmXraXPsTCcUdzkCvN/Su2a979u8F+/k2MA2HqjxvnbCjol6KepK8G+8RRx/QkKJUgMwssPDgK627MVw8Mslg3mpktIYzzd1Qhdz40BXUWURazJGU32vprVHj9zmY3nDM5cc447Gh7GvD66+djpOX1zaiF6D3JwrPHceHEJG/OLBy3wRDWe0wapgU4vQF3BybMxfOfLsAICY9uVHqjebMwnsnejaVgJzZg3YLLPWCbXneDnXsjan7qn8P4OMG4pYqnlo8wHYU/jYV+t6PtOs7Xaxa+uwznnP2UeoB7MQanbGnEVPGJaTgRortw3A/lsrgtDBpL7aD3xtU1lTWcDfNoCH8LivIxgWp9B44ly35c7ydchX16ojMjdjwpHXU1h9qz8dl73Vg1pmUK27Cyll4cvEaUWZEuLjdA73RcIzNzUP/V3oGLh/2E0uhEAn469fPvfvjh1QUCgUAgEAjOF/LyIRAIBAKBYFghLx8CgUAgEAiGFSNW8zHunp+SwXKGS0psRA6xbSHa2ZsUn9U+F7ktC4udkNCCzeX74wdy8f6hPOS/8kez+P4H1R73cBpylxkZGNu/vd11zvODb6OGwDSAdY0s84BtNCi+0vpn5DpbUepA6btYDIpk9MvQfOROnRuQn+ydwHQ3cTobHkNiUhHmwDhyCnMgJNSgBsCXiZ2Q+xbysNnfw8QFe+oKVD3qMPdDiOX24fFJNAOLpWDBZ48eg7xt5+uY5jx+z7txAH2aPBPHRvch7E9bK17fPwXHi96M7TafQt2OPs7NvmJs59WTMPbN23/EHCe9M1mq8R7sg0gKni8uQM65YVN+7DhQjJoNHfsTRutEUQD3uTkDCedAF7aTWJ/o4/KtjErzwLmOXRhjgsevcNSg3oDHTtGzmCWR8UxD0KT0Lel7sZo5d1aBve9gEdip+9AxARc+yzuNaQoYTE1q7PJ6horRh9EgI/2ZRivhCM6ToWz0sSGLiQDisLgQ4xFtqUV9SMJWzKdSeiPGGKl4G3U1Ji+2JZCEdS18RdWl7lMsB42f9ZedtbMU8+l4q9xg33LxZrBfqJsCtvUptY62XoJzggLo49xCjNPR5cU1M3ICtW08LhDXhCVOUrqtlJ/inKj+DPYfObFul43HuE4hDcfe+l2Twba1YVuctWo8LL9vM5z709bFYOvcTBe3V9U1EvDTiUdF8yEQCAQCgWAEQl4+BAKBQCAQDCvk5UMgEAgEAsGwYsRqPkY/8V3S28/wXCHGCacwLrX7AsWdTi/EDe/H3xoHtj8NefW8N5D7bLoQOeIo03GkpOLefotRccwtNZibxXkSebVx11WCvff4aLDJhHVxHEfuvPBTuDc/HlUbsayzYkywvfdjS5rBbn09D+wQ0pegNyAiuuxaFS/h9TWYsTjMchgUlmGfVB1CDYi1k4sG0BzKD7/n+dLfoG7G+Aja1evRLxakhMkzFRvmPoBaCM9kllemXo2PkOvcUyeUgvembcex1Tser49koQYgfR3qVdrLVV2dB3FseGdgDJHM1/DetkVYV577Qa/H8RHehxqirCVKx9PhRY4/xOIdhBsZ9+3EOWfow+uTSzFGSSSK3Hhwi8p5wfVB/3PlX8B+4KefA7sf5Qlk6WF5aS7FeZBmQ7/sr4+bF23o84RGHLfeadgHJXkYo6KhF33K85S0eVAjYDIpvxWnop6oqhvXmv5uNmEZTAm4jhlOYh/aW3F8pH66MXZctxPnaygJ+yDvVbTrP830JExfFJ+zhujseBnxSDyK4zgwB/vHaGRxPPahro6Plz996vdg/+SLmHco6FJztPlKnL/pG7Ad3ZNxLFm7WO6fiTgejCasa7gHdRxpu9V48hTDKYjxQ0SUXIl1a7z83D6fOhf1ST0/yge7dZ4a2wH2G5nQiP1jXYTxabq71LiN+vzU+JUfieZDIBAIBALByIO8fAgEAoFAIBhWyMuHQCAQCASCYcWI1XwU/OQB0lvPcGIRC1Zx8tRasE91Kv4zHMb3qQjjE+0O5BsDJ5AjDKUhl8bzyBgxxAEF4/jPxFxMkGF+xQ22B+UnFGU5MUxerDvPqcB1F9mXKC3F6QrkZcMsboOTcae+dHy2rdQD9mAN+uWRKx8D+/etau/30VaMtRBsRf7Z2oHtCk9Ertt0GK+/6TPrwX7y2aVgx+exMZmwv8anYZyOffWoZbHvw7gBYUaVx+93JyKKGpFrnXenCvbw2oZZWC8jiyETxntHTcPYGYEIjk3/2gw8j2ksaOIypRlq+28UM7QsYuPegbytqRvHcWIdlh2+zEPnQiQaV/4eHBsFl+B8rH8dc5gMsvwafJ4MDaGWwvEO9lHoIqXjSXgJeWSN5VuJrET9iOUvmF+jbSHTvmSjhkDbi20LxsWgGDOTJVBhqKzEfEhpeSgw6qrDuvC8Is4UnBeDcTEquFYl9QiO+6z7MBYOx+4TqH3iOYt8U3FhsxxVOrugG3121dJdYL90EmNluDegRs9TjmWH+/HZph6cBw4lNyHPXFwEDa04VnjMkOST6FPjl3E9aGjDPvjC1HfA3tGj/FT3Jo5jPtaGilBHY2nCdoWcLIbQS9iW6s/inNQF1RzTubDsrBexbNtXMReX90849rqmYV31LGdZ+VKMC7T3EXXD0Kdwfup34ZwYzGc+TlX9Gx3yU+2tPxXNh0AgEAgEgpEHefkQCAQCgUAwrJCXD4FAIBAIBMOKEav5KP2qyu3SX8LiPOhYlePiAtiamUZjJov134n729OyPWCn3sWe9Qfk6bqexP3R8bEa7OOwLMuLbrA75yJXNmMixu1o/TXmhmibi1VJGI0xLAb6FLdqP4F7xt1LMMYAj0EyfgLy12fx9KOQr+Q5cJKOKZ8PZvO8E8jxJuxFDjiCtC0N5aFfxpQgn9n+OupZvBMUH2qwYn+lupHDz3agzxqfQB8n39gIdtNG1IjwuqYeUXVtY3mEIonYDv0Qctl5E1HzUXcac78Y+nHsFr6CcQLqblfjPuxBDtjehPf60xjfPBnjWQyFMA5AS10q2LZUzPWh26/4W/ciHFspNrz25A4cS/mzMddP25vYn0NsrEWtaJt6lR+5/it5XA/YSatRL8J5+qa7sI8iVbgeRPPR5xGferbeiz7mGh9yoc7KWolz0peDYzWhDsvj+VbsuUrb5Pdjf/FcLtdOqQD75bUYeydlNmofOg6ivuh7V/0N7P96amXs2FWD9Rq4lmkCNrvBnv/Z/WBvfX462Lydjnr8G9iXqfxq7cAODGP3khmrQkPZ2CcuDG9B9pU4dhvZuNf5lV8T8rDwwSaMw7J41nGwW4dQ41B9AMe5LoJtyXoHx2LntLjxMAHjSYXqUZymsdAohkxcc7V6dJSLSYJ6JmMfaPEasQD2R856lovnNpxznXE5y6I+PzV99T9F8yEQCAQCgWDkQV4+BAKBQCAQDCvk5UMgEAgEAsGwYsRqPkZ/Py7OhxWr6D6BHJRpSJ1vvxT3R2t+JMdmjUedxf4G5OWivUjy60L4LEMm48JrFBf3rWtehHM/O1YOtq8LeThrCvJ0fhbr316HPK+9Hf2Qf6siNCuOI8/uOob3RlAicJaWgedjOSvuxyDWLT4OgAnDE5xdNko+iBgPn1yGPOzAm5lgf+lLa8GeZFU6jVt3YG4GrRsfnjIG+cmhAPrF/Qxy/l1T8X08/1Xs7/rlcX04Fhse9OCzef/5RiHHq+nR585s5Hm9DciZGtPVeAl58VmpWaht6erAe3UG5HhtTI9gmYvxMbwnMR5C2B2nV2D9x2PhJB/F8yYftjN0Mz6rs8kNtuso+m2gTPWBgbWDqpEL149DzU9yIsufchx1Nloy6jSMVrRDHuUnkwfXEi0P56+NxZBZdAPqMLasmQF28eWnwD799Fiw+8YqvzlYHpn0/fjs9hk4ybzjUF8Sr5shOlsLUzALdTlN29S6eP3Vm+HcE+8sANt9FPvfEMD+9mXgwyYtPwn24ddLwLZ41PGjX/81nLvtD3eCHbHhs8YtZjFnXsL4JuY+vD7tc/Vgtw+o9SC4FfUgFg/e21uKdkoxG9f1mMtn4TRs985arFvYr/yoZ/ovay6uDfrdGHvDn4x1mVCGv3OLUlD88ptNGDspPn9L7mV1cO7kUfyNTDqCY9E0qJ4dCfpp/3P/IZoPgUAgEAgEIw/y8iEQCAQCgWBYIS8fAoFAIBAIhhXG97/ko4HBpyPD/8Xv4Lxe9wLUdVjrFP89ZlQnnKtrxwQZNf+LCVYsKYz8nIHceegU8lb6StQIBOJywfz3mqvhnG0KxhjR1aO77TkYQ8RvQh4/OAn1Br4sPD/0umqLgXF+fZNYzAE3xi8oTu8A+9R6zBUydMoNdvp+LL91qeqD0flYVufrOWDb2/DeoBN9bjdhXTuy8PqHjy8GO3JC7bdPYuk2HC3IdfcVIm87xPxiyEUuPOREXUbVzehza4uquyMBfcpCDlDQhf2t92O7jYP47MEh5HFdYz1g+yuUDoO5jL65eB3Ye7ORT+ZYa5sItseD2glTPmol9K1Kz+CsZnlkmMbHU4z9Z2BxA9x61G3omR98GYyXX6t0F+2X4Nw3s/w5ERZLoXM/xrPQRuGcs55C7YsfZRfkyFAaksEgxnnISEIevicFdReBKPZ/gOVIOfkarkWBhTjfjTWqvCjKYKhlHj5raDQOiHUXPwT2pX/7OhbA/uw83YLzZEa5yiPUy4Jr5OJQIw8uHdTH8rEYzTgnq/9UDLaFacIG8pSfDgdQb5DYiGOnfQHaJ1tR03P1TTvA3vgwxj+p3olxm8x9avwMFeBakFCImg7qxvHQ3Yu/DQY2rrfvLwVbs2H5Bc+q4/obsD/tFrQD8/C3xbgf9SVV67BTDo1GP7qqsG59U9W8OtmImjtzLw6W3ino88TquDg8gQ/+PeO8vnw8+uijNHnyZHI6neR0OqmsrIzeeOON2Hm/30+rVq2ilJQUcjgctGLFCmpvbz9HiQKBQCAQCD5pOK+Xj5ycHHrwwQepoqKC9u3bRxdeeCFdeeWVdOzYMSIiuueee2jt2rW0Zs0a2rJlC7W0tNA111zzoVRcIBAIBALBvyf+6a22ycnJ9N///d+0cuVKSktLo6effppWrjwTmvfkyZNUWlpKO3fupLlz575PSWfw9622eQ/eH9tqy8Mt69mnHVubssddhluKDpxin9Xa8ftl1g78JOj+1rnTZh8+WgB2/KezglykfIIsZXqU7W8L/Q0/EXpKsCtSx3eB7fgvpIDqLlf7Z80e5hO2LXfUjbgFzWrAz3i9Afy0WnsAUzQXTccw5NUVcWHIR+G2vzT2Obp/G3761s1EakvHwuXrtrnBXnADhmt+c8fU2HH6WPRRbwWGkTcOoc8Ll6Efat7GLcqJs7EPLY/hltPWMuXnJIyuTL50fBYPG6+xdt44byfYT+2fA7aOhWc396hnL1x2GM5t3I00Sk4xUmFNrSydO6MrbHW4F5tvb8/cpdrSNYmFBR+Hn9nH5eHXztP78JOvnmUwCKagn+wNWH7CfNUnodexf4s/g9sXj3XgJ+OBTqSTiG1vLp90Aux9T2J6eH/cFA2kYj0pEeeQxY62vxcpnVF5+Nl+KIhrkacWP50n1qn+zr8Kt05WdaAfbJvwk3/vdHQyp10DbSz89klGfcW12z0Lx5JnAHkS6zakH3JWsDnWiZROoBWfbenBZxviqjqUhWu/hVEAOkY/8nH7qct2g/3Kepxjl5bvA3vj32bFjtMOY+H1l+OcScrGday3GWnTs7Y3v8+f+pEE1VZ7M6Nki3GO6U3oF2MtjjV9CW45p6PYR45ZuG56K1Qf6Scggey049hpb8RxWvS0GmvhsJ+2bv/Jh7vVNhKJ0DPPPEODg4NUVlZGFRUVFAqFqLxcxbYoKSmhvLw82rlz5zlKEggEAoFA8EnCeQtOjxw5QmVlZeT3+8nhcNCLL75I48ePp4MHD5LZbCa32w3XZ2RkUFtb27sXRkSBQIACAfVW19/PZXsCgUAgEAg+TjjvLx/FxcV08OBB2r17N91+++1088030/Hjx9//xvfA6tWryeVyxf7l5ua+/00CgUAgEAj+bfFPaz7Ky8tpzJgxdN1119FFF11Evb298PUjPz+f7r77brrnnnve9f53+/KRm5tLk295gAzmMzzWwFLkrwIDuLfPZFPcnPkQcryjHsStVtUPofbE0onvX7kXoubjVGU22AVjkc/u9Cqu9TNFyB8+dnge2NZjPM44YqiQhXruwQ9TUTPrqjgKkutizMnI0znZttBFWZhj+cVjU8GeORrDDtd6cMuy4RmlIehZjpqP3DTcBtb3V9SPcG1EgG0THj8bOeOjtXi/sVXpE0LJyG3fNBf7+88VuLXOkYTbGTWmw4nuR95Wx2j+UKKqa8o05MJdFvRxQw9yo/5m5OV1LFJ48lgMBT+4C7nyyZcqfcOefbhN087CL0cOsvDLOTi2nCz8vj8N+0AfRL/E3+9Mx/k44EW+2ViHtsa+r4azcLts8jbUm3guwvEUiQs7bU7Ae8NMP8Bh6cb5bZmJPu7vxzkZ9WFldVY1AOwO5N2HWH/qU/C8+TjWzVmLHT64Er/ypvwB166xP1R/1AWiqAGo+cV4sHvGYzsN6EIamoBjk29/DQ1hH8Tr1+qqUbPlOoE+ilzgwbI3usGefdMBsNfvnQw2TzPgPqbKH1qIYy3SiD6NJGE7uE6KpwJwnMbzeVewcOyvKg1YIBXrZe3Ewh5d9Ruwb3rnNrAz1+LvVH8+9lHQheVPWaLC7R/cjvPbVuIBe2AA51h0CPvE3IE2T59hb8G6DBQoP+r9bGs8W5d0r+BvQShB+SUS8NOJR747POHVo9EoBQIBmjFjBplMJtq4cWPsXGVlJTU0NFBZWdl73m+xWGJbd//+TyAQCAQCwccX56X5uO++++jSSy+lvLw88nq99PTTT9PmzZtp3bp15HK56LbbbqN7772XkpOTyel00p133kllZWUfeKeLQCAQCASCjz/O6+Wjo6ODbrrpJmptbSWXy0WTJ0+mdevW0dKlZzLk/eIXvyC9Xk8rVqygQCBAy5Yto0ceeeRDqbhAIBAIBIJ/T/zTmo9/Nf4e52PJ2tvJmHCGM6vdjSLUSC7ylxSXRt3ajkySNgN5Vfs63O/cz0IDG8Ygx1j4n8gxV9+I8RIMcSGzg2ORaDVXI58cKka9ga4Jz1uKsK6D3chv2upZjJKdimPuKUV+0dzP0lqnIl/pnYT8tOME3u+bgm1JdKCd7lB+avWiT71dyF3rAsizzp6KsVjmujGGwWOnUCsTqXCD7U9T3Hnhy6hlqL2acZ8sLgCLeE1uzGpOkRUYi8FTw/o7Q/mBh1fvq0aNh46F+k6vYCHqy5GvztiMleueiPeH3Up/oLOzYBlsFltOIyecXoHXN65EMYuOparXt+D91y3bHjt+ehv2z+i/YR+cXonj1DCEfTClDPt//0GchF9YvBnsx9+8MHYcZuHvkw6xWDom9FnKFZgqPvhwFl7/ZYzr0rMT44QY4qbJYD76MGsLtmvpfdvAXvMcpgXwj+O6C2xLtBnXg4g9rk8MjLNna8GYZTiHjlRjigNTB14/cxHGR9m1HzUGpn7VNoOPpQWYiZqu8F4c98EJuM6Zj+E6FkjDseY6ieX3TovzcxTP6R041qJsbTGweRHxYrvNblz3Qn6cc8ZWtQ6GM3Ht5/jDwifAvvvRL4M9mM/mWBKWZ+K6m6Cqi6kGxwKPjRMYh+txdJC1s5uljRiFz9b14vXRRPWA1Ez8HRoK4LW+Qfyt0BtVf0aH/FR/2/3Do/kQCAQCgUAgOB/Iy4dAIBAIBIJhhbx8CAQCgUAgGFaMWM1HzsP/SXrbGd7ZXo170H2jWM6MuDj3F087Cuc2VJbgA9i+7+JRGLej/q0CsA2M9uNpsWmcSj1u3of7/nmqcROGYqD+ichf8j3qPHZDhhPtlq2K1+WcoOs08qpt87Hejjq2H57Bz/a4p01DP/V4la4jyHjTKONZE2tYXADsTgpOQo7YVsH28rPrtbiqmzDzO9Fi5KO9Dcg7jp3QDHYb06v0d2If8lwg8TlQfPk4OAwsRXbmi1jxwUyWxroYr88ei/oD7U+Y+6dlqbpeP4BlJTTi3xE8Lf2kMozrcuo1zB1/4bV7wb49dQvY1z/0jdjx4Czkm+1M++JtQ59yvUL+i3i64RKse34pRkSua1R5TLh2IW0/09EsQJvrTazFmI+Dw/YyxkfxpakFw7wI82EEt2IclsxLWP6jKtSXGPuxz/T5OHiDXjbQmd4hHjoLWwODWHZSBc654MVMT+ZBTUHOq3i/pyguTTq6nPzZ+GxbJovFEUGfBzyoH+IxKCKjcTzFa+G4j6ga9WRRVjdTH/MZMwPFbOweQj8EZ6m28NhIuucxvkXPRBxr8blZiIgcp7GdGfuwvGW/xjn2+1cvjh27UBZFHvYzFklkehIb/gDw3C8RtkbHx8YiQu2LbgCv5XlmIjPwd8jtUOt3ZDBAFSseEs2HQCAQCASCkQd5+RAIBAKBQDCskJcPgUAgEAgEw4rzzmo7XEhI8pHh//a5D5awfeG7kUP0TFPn3zoyAc4l70FSsHcilrVgcg3Yp6chr0cs/sEdJdvB/vm2ZbHjrKUtcC7H4QH7ncMsXj/bq+8rRA1BsBI5s/5JbI97XK6X4FjkEw1+5DKdLJ6FjklXVt/9GNi3v3Uz2KFnML+Df4Gqi6MSuWqeJ4TrDwrWYl2rC9AP3rHIXzpZLon4V2Yfe9aVeRi/4M3tGNq/dwz6pb8bOWRLK9OvjEPOWTdVccaWo6gPSJiOmoDu67Ad0UrUk6SOxpwJvVsxxsTQUqYJiosLkfcmtrv5AvRh/hsYz+BoHuYo0lg+nS1/mQX2pkU4Vn35ah6MzsR2cm0Dh8mB47phGfaBbRRyyKMTMdZKU6eqe84GLKv2GhbnwYU+u3QeasBePT4J7MQKXEv6L8O6uNaqPus5hmtDeDz6uKYpDWxLO44l9ylcS/qGcDxYJ+CzF+Urnc62BoyFwuMVdc9gGhADih0G23Gcm5JwDjZfhXU1tKpJBvFGiMjSyXw+iiUpqsB5YZrMNCFM+0Kt2AfZW1VbOm/Bsn1p545v46jDeWDvwvtDTfisL3/7BbD/59lrYseDEewf/4Xos4SjWNbAWNYHZagvqpuGdfvD2ovB1sdV1XsxrjvRdpwzZtYH+jDT+CRhu50FWBeeG8ZarwSK2QswNo7nCObWGjiJfukhZUf9LAbXOSBfPgQCgUAgEAwr5OVDIBAIBALBsEJePgQCgUAgEAwrRmycj2k3PEAG8xleqr+Axfef8t579c0bkW/sm428bFIK8qoeD3Kh/zXnb2B/Y+P1+AAji/sQp9vQMeozbMdrTQPYjqHx78OP9SNHeM8Fb4L98+3IGcbDeQLv7R+HXKmlk3GEKchXZrzDNsjfhDEoCp1Kr7DzEMaMyNyG77Tdk7EsF9Of+K/A/jS/iX3oXIlamroGxa2bmZ6Ax1oJI1V61tiJRrGukWq8P+RCv5A1rpNZ7hZi/X/5jINgv1ldSudCuAsrqwtj+bnjVfwLqxG1DVXNGBPEzHJDJNaxac7MzoVMX+JDTtnkUX4yslwf7ir0Ufvsc/9NE01jeSaM6LjSHIzzcXpjoTJYvUMO/A+Nzc+IA8vmXHnBPIzNUf8O5pGKjyMRzcP5Gu1BrZM+BdeaSD+ef7T8SbD/3x03ge2/CzVAnb1K12Gswtg30WLUUYQG8VnLJx8BuyOA43pfBc5ZLgKLH3uuU9jffcUsz0wL9ndoFq6xgV7UF1w45QTYu1+cDHa8z3XTcL6GQth/4Xb0i6vAA7b/AOZmChSyNZetsca0uDggdfjboLHpPnZ2Pdgn61H7pOth+VOYdkYXYHnILOq8zopzKmUL9q/5Ooy71N6Na2ZuOo4ljoZjWNfMHeo4bGX9XYT3BrJxrdB71W9J1O+nhu/8h8T5EAgEAoFAMPIgLx8CgUAgEAiGFfLyIRAIBAKBYFgxYuN86CMa6cNnuEX7LNz3X+hGPut0r9p/72hBbcO10zEux4sNU8B2b0M+8j8PfxZsxzwP2APtTBOQqPhPnmfCm4/vdgOFWDddH8+BgnymxYPl/bF6OdjOOGrOW4QcYX8JPmtKKfKTh07kg71kKvKwR/dPBNvACM9oXNIEUzLL7ZGPPjIUIQfcnY3tXpyFvPvRy7HuzfswRgWlK86R55HQMYlGxMpyfexBbtTP+kRvwet5Pg7NrfQKuWmYR8ZlRj+s3TsN65aAz3I4Mc+E14zJgIxenJ7fGf1G7Phn9aj3MTbgOPZn4rP8+eiY+H39RERWF+oVNEbXBklx65W3/Q7OFb75BbDtVeizi1Zg3pgNdcVgZ7kx78ixaowrQNmqLckHWYyIqTi2TEZsZ/BAEtiB0dhH/UH0Q8iJ/R9NUOUtHI0xgbb1Y8KNxHdQf+CZjNz4V3fcCLbhJjyf+DLqdmZ/TsWsObYX9UJJyeizxhaMEfPaPlzniOX6IAuL3cFiksTHrOlJxDmTuQn7oGsa+mxCRgfYDZtGg705AfUm0dFMbxSndzBU4UC0t+M6xPNnZU1Gv9QHUPNhT8RxXjK6AeyKo6qul5fvg3Pv/H4m2HUDBWCb2FqjjcacVaOZDiPNirqd3adVefpmnM8crR1usA2t6IikXHz2geOFYOduxv5vma/6tOA19FHHfDbnQrjmRm2qrCgXvp0D8uVDIBAIBALBsEJePgQCgUAgEAwr5OVDIBAIBALBsGLExvkovuunZLCc4b2GWO4AwxDyfvHxMwxsG7e9A+8dWon7xocGkVuzHMP4CENjMCbBtLGonTjRrrjWSBVqHWwdWM9VX34J7P/35hVgO2vwXbBvJnJvPB6CuUrVNTAGG+5yIefX14t71p37kSPsH4dc+cRJ2M76F5C3DcfR2yuv3wLndncXgN24HvUlljLU8NDryMv2zkC9gpnx0fH9/ZnPbIRzT56YA3bmX7B/m5ewuB5s772e7b3Xp6Nfs55V++0HM5AL7ZmN3HXBGjCpcyru1Z94BeahObgBNQTuKqzbYLaqmy8dz1m7sN78vGZisRlGId9sfwW59c552AdJmYpLD23HHCf6eah9iTJ9kH6zG2zvDPSpNoj9m7oH/er4jIrz0v0m6kGCc1DzETmNc5DH+TAOoJ8sPVjXpEpsd+84VTe+DulYmpFIMv7Ho4v+F+zv/uzzeMOlqAFI/D1qK1o/q/zE43jcOGM32E/txBxGReNawW73ol+07aiF8afj+HDGyVsev+8XcO4zv70Xn3UpamEOHy4Am8ercY3B8eI9ifPf3Kuuj07H/p2S3Qz2sRdxzuhxCpJ3Oo616yejjuOZw6jj0IZUfycfwHHouxjrYtiNc2agCB9ubUFtm78A1/P0t7FPOxap+91pOD9nZqIu7ngv5tpqP4Z6oSib75oZbWsbzrlJ5ZWx44EQ/jZU78b1e/rCSrAPvaX6IOL3U82D35U4HwKBQCAQCEYe5OVDIBAIBALBsGLE0i75P72f9NYzn8wNfvxsN3Z+HdjtTxbEjn0ZLJV0AX4KnVSKW6t8Yfw01v18Dtjpe3DrVvN/oLviw/0G+vFz1bRxSF0Eo/ipy6zHuh1uxGcn7EMKKFDGPjGH1bP1BvwkHGVbUMMe/MSXUYCffIeC6AfrS26wO8t4Kmvl5+UzDsGpQz+dinVhG7r7C/Bzpq0DfRq42gN2eS5+5ntlo6JW+Kdvje0KSyzFdvZV4+dmUw6mro7U4udp0xj0ua9L8U22VKS2dCxEdaAW057bi5Dy851y4/lmHLu+Mvz0Gm1Sz86fiiHn+59GOsJbACblzz93GPFAKtJueif7hBxHR/K0AekHcOy1sfDqzlqsS/9i3GKcmsR8/Dp+Uh7MUc+zdqKPgklYl4K52M6GLXlgR9lW6kgh1qUkG8NWd/uUz39Z8gycW9M7G+zn9+InfB6POyEdx1roBH6WNpbgWhM9omgYHaMTzOiys+aBbwleYDbjBYYNOA+ibN5El3hix0P1WE8tGanoxeOqwN73/CSwIyzFQdJ8DJ/v9bPtzqG4BeMIzqEIG3shRnXNGn8a7L2VuMW0rAQpom4/0tG9flXZzgb00W3zt4L92L4FYBOjbA0DzKlsfeBh6eOpbG0K9l/aX9CJ7nvxd+xIJc7nhBpcz3kaAv6bGr9uTroY19u9VQVgm9rwt6RorvqdCw8GaOPy3wntIhAIBAKBYORBXj4EAoFAIBAMK+TlQyAQCAQCwbBixGo+ch7+T9Lbzmg+9H0oGjAEkK8KJyrOObsIU7/3bcSww0akeClrRR3Yvb9Hjth7LXJv+u24HS48T/G0vj4WEpd5tnQM8vSBCLbrdC1y3WYnbs1KsKE9MKS4Uuse1Cr4Z6NeQGPpoVl2aLIUs1Tze9xg55Qjx1i/XfnJgjvnKLER9QO//J9fg/21yuvBbjuB28QSmliqafaKnF6h/NA7DvnH3qn4bJ0dOeH8LNzmW9eQBra1Hsvz5yO/nZmtGtv3DvaXLxuflbqPaVuuQ667+QTez6Hp33tq8q1zjmq2HXkQzweXop7AZkYRQXBDKth8i6KxSY21UBq209SNz47k4L2WSuSrn/j8L8G+7u3bwXbvwz4IutVxFKlsCicwHr0VR/ZQFp7P2oHjo/i+Y2BvfQvTu0fiwrHr9ahtSdiOcyqAEgEKuvDZ5n6sm78I/VQ4qgvspm537HhMOp7j6dtNjegzrYjpkaox9HtkDNPduHG9GO1S82TfFtzOavFgO7iewNKL53nqB1MPTmgjC50QSFF+dp/Ec5aVqMnpOIhzKJKFa6SxBfUklm72rJnY7lEpah0cCOC94TdxjvQX4XhIOsb0hqPQNk/FhdJ/zA12MEn5yd6Ic8rSy/RkSawP2FiL/00kIjJ62SJagPqji8conceJPrYurcY18vS1uK4Z4ravR/1+qv/ef4jmQyAQCAQCwcjDP/Xy8eCDD5JOp6O777479n9+v59WrVpFKSkp5HA4aMWKFdTe3v7ehQgEAoFAIPhE4R9++di7dy/97ne/o8mT8TPlPffcQ2vXrqU1a9bQli1bqKWlha655pp/uqICgUAgEAg+HviHNB8DAwM0ffp0euSRR+j++++nqVOn0kMPPUR9fX2UlpZGTz/9NK1cuZKIiE6ePEmlpaW0c+dOmjt37vuWHdN8/OLHMc3HwqkYhnpfM+oy7p6wKXa8etelcG7sH5FvbLoH+epwmKVkr0Eel4dyD01ALjX9JaXzaMfI3jR+Zh3YbjPem2ZGvvHV17EAQ5DFfShA/UG8PiHMeFeeWp7zqjz8rp7paOws9gbPlNyzUNVlKktLXfMipszuH8eCEBiwbPchJPLD5R58NNOf2Ocr/nvoHeRhdayenHePFiDX7dyKeoS+YnZ9ItY9PvW8vxvvNfYhF8pDt/OQ5jluD9injmOcF83I+iBOA1LwAp7qHs/itPScmyP2pzCOmGknrlq0B+wXDk+LHc8owvg1FScwloLZhbx7KID8dd6z6KemG1F/ksnSxbd1K52V+23UVQVdjFfvx3b4UvF88kmcGK3XYl1TX8PyQw51/6W3b4dzL6xZCHa8VoGIKJqIzzIybYx5LLZzqA/H04Xj1brXPIRas5o25OE50pkPw08jjx9cgfqDvgYsn6Kq3VoCzoHbZqMfNrYXg93UieKXcAD7Oy0d69Z7lM3huC60MQ2PaQj7t3cxy6fBly32bHM7Ew2x6+PD7adciqHcLQb0w6km9GnR77D/+W+N8yXU5YUSsG0Ri7KH5uFaEQ7i2OHpM6KbMER9GH/GyF+K654tAX9LDNtU/0cWov7Pz+IV6SKs3nHrXNTnp8ZvfP/D03ysWrWKli9fTuXl5fD/FRUVFAqF4P9LSkooLy+Pdu7c+a5lBQIB6u/vh38CgUAgEAg+vjC+/yWIZ555hvbv30979+4961xbWxuZzWZyu93w/xkZGdTW1nbW9UREq1evph/96EfnWw2BQCAQCAT/pjivLx+NjY1011130VNPPUVWq/X9b/gAuO+++6ivry/2r7Gx8f1vEggEAoFA8G+L89J8vPTSS3T11VeTwaB4tEgkQjqdjvR6Pa1bt47Ky8upt7cXvn7k5+fT3XffTffcc8/7PuPvmo/iu35KBsuZF5zAdJYToQ/3X8fHcoiPR0BENHvJCbD3vzYebNtc3D/PYTUhb9fWhdxo8Y8VTXTi28h1Pn/hI2B/+uWvgW3uZXoTJo1wzu8AO7gWeV7PRMW15b3O8mvMwY9aPK01j83hHc1SsKcgJ5joRM4wHJc7JlCHnKCZ7eOfvvw42Hs3loI95YJTYDcPoI9b6jGFu6VN8bZly47Aua27JoCtS0dO2LkNefVFX8AveId6MEdK/SmME+PKUXxodDPyrNfduhHsxzZeAHbUjhqAa2ZWgP3WX1ETlXoE+8AzVml8BhcwTrgD26UPMY0Py2liTMX+THqdxaxws7wkl6kvlyVuHJf13xkH9mAWxpxI+TJqRE40oU+XFGFukNNe7O+2bapPdJORlg0yLnxyDvL0p15H/dHgOPTp/JJqsN85UQS2bkitdQkNqB8IJTJdTS6WreNxWlh+JR6vKGMy7gpsOaXmu7Manx1egrz8YC/TH3WitoHrhzJ3MY0Y00qZv9oaO27ahXPC1o71dizHr9rth1ALwcvmuZ4iqeg3vSeu7qmoyZkzug7sPbtQb5IwBv1Cm1kuJy/TBF2G40m/U609g4Us35EP2+2sQdt2JfZflOX2MbDcLitz94P9VK3KFRQMY38HDrvBzpzbCnZ9HdMAsf62u3C+61igJ0NcDBtvM8s5lIL3Gk6gdiWYFKf58Pup4dsfLM7HedEuF110ER05gov9rbfeSiUlJfTtb3+bcnNzyWQy0caNG2nFihVERFRZWUkNDQ1UVlZ2Po8SCAQCgUDwMcV5vXwkJibSxIkT4f8SEhIoJSUl9v+33XYb3XvvvZScnExOp5PuvPNOKisr+0A7XQQCgUAgEHz8cd6C0/fDL37xC9Lr9bRixQoKBAK0bNkyeuSRR97/RoFAIBAIBJ8IjNjcLvk/vZ/0/ydqtXShhmAoH8URtmb1DmVguVsGivDahDp83+JxIKydLC/BBOQjTR2MS427PJyG8QoSj7E8Ien4LBdKHSjoxGcP5DOylPWULlPpGaK9qHUxJCFXarFi3SwmltsjzDQijJ8M72PcaZwMh1GblNiE9e5agXvSXUxf0DOJxyhhuXuSWM6UbMXrmv6CuovOK1DjYT6COS2s3fgsfwo+i+f+Sb8cBdAtG3JVvVhsDK0ItUkWC9Z7oIttvmc+1g1iH+ixi8DRUQv6eOncw2Cf9mLshK4XcsEezMFnR2xo501gnHKL0mF8ZgrqZJ7ahZSqLoDz1dJz7lw9KXNQM+ALspglT6uxN5CNN/P5mbEJfdh+EVsrnDg+El9BvVLvpThWryxWft36EH69TboF49tUHUYf8xgx+n6sm70F28Lz1sTPd+s81Kb59mD/8jg8ARbXwWhC/UKkEedFymG29lyptBBDTE+SnIE6iZ525PZ1PtQrjJvQBHbnMxiniedAscY1ddx1lXDu+FrUePCcJ94LsP8SHegHPxtb4ZNMlxA3h/XHUNvA53veOhx7jeW43o+ei+PjllE7wK4YLAD7hS0qzhPX6OiD7x1bg4jI1MtiDOXhOOcaj8gAy5eWqBYb0ykcG2MvOA32sQNY7/hxHvX5qWnVf0puF4FAIBAIBCMP8vIhEAgEAoFgWCEvHwKBQCAQCIYVI1bzMfrJ+8hgP6P5+NX0Z+Ca29feBra5T71DRRlXZhxEsit9P/J0bV9AbcSkrBawOceoZ7E4fBnqeaVzauHc0bpssG0OfJbfhxyh+RRyq665GE9B+yvu5fat8MSOvW3IXXNk5PWA3bsfywqmM37ahvaodA/YjbXqftdx5A/7ZyDfmHAUA9INFKGYwZ6KPK3VjOf7j2PcB0e96tOEK1Av0NyEGpDUHcjxOlqwXQ3LkCudNRuFOCfWlIA9NFvVlefP6NqH8Q1Cedjf1Id1mT61Buy2QeRI/WuwvO4y5RdrE46dSDHTmxxAfUlwBsYFWToaufTXDk0Ce3QBjr3aJtXfehPyzRHWLn0Q/6aZMh3beWIjxt4wecGkEBvKztNqjqV8nsUMqcvCi1muptIijPvR6HGDPVSPPjePQj/mJauAOPXvoKZj8oU4VkoTcSz+77YFWDe20i6ehfFvNh/CsRYfqyEpDZ3U24b1NjlxrH1lIuZfaQ/h9a8+Nw/soJvlNDIr296KPg1MZzFm/Nj/KalY1/gYEkREHR0Yx8dxGPVq8Wts33icr+XTjoGdY8WARU/sRJ+n5njAHtqBWhnjbLzftNYdO+6exXLz9ONaYR2LMUW+P+E1sH946Aqw6QgObH8OrnOmuNw/YTv2h6mfxQzheb/yWYwZltMmvbAb7I5aXFON/aqPDSyeCde62Io9YHs7lDYm6vNT09d+KJoPgUAgEAgEIw/y8iEQCAQCgWBYIS8fAoFAIBAIhhUjVvNR8OMHYnE+zEXIrdM+5Ax9JUpj4NqN+gLPFBYsgQWlSNmH3Fj/aLw8nINcqqke+cmwQ7kvvaQTzrUzbpPDtZdpIeah9iESPve7oaFV1cXaje0aykSe1TnGA7b/AGojzqpbFd7fvoCVl6V43cFqbGfScbYnHV12FqbdjCH7D/0R9Qdzv4w5EHa25ceOjWuQu5x1J167ft10sDl/+ecrMQDeql/cAbaPxWbh2ph4mJzIu87OR33CvibUDAT6sP/z83H8tO5BPYM2Ro0P2y7UdCQtR61SpxfPx+esICIKz0Fe3sxyGAUOYVyXeA46mobt1FhcFh4LJ20/jh3dbdhO+gPqj6750Xqwf73rQmWEcE6k7sX5270Y56vtJPo4ysZi9gKMQdHqQZ7a16N0WGUTMA9M5ZOo0eidjO10nGa5YDBsBOgqiM7Ox2OKk1YktLBAHjehDzuPoQ953iiNhZP8j888C/aPDy4HO+8RVffOyahF65uIa2r6diy851KMrWE9gHEjLrgO48Rse2IW2OGLPLHjwX7sv8w3UOs0mMXyY6FMg/qL2X8w09bK4mPExbvhOgsjLs/kQ0kW3XoNjts/HJkPdmICauF8AZwnwVY1ZzUHzsdpY3EtObRvDNiWPNThJFhxjna14vx3HcZn+9NUu2eWYz60HdX4o+g4hH0Sv75HAn6q+p/viuZDIBAIBALByIO8fAgEAoFAIBhWyMuHQCAQCASCYcWI1XyM/r7SfHCePTEd+S3fKXfsWJeH+/SzWSwG79+QR7dd3Q52985MsINFLEdCHfJd9slqn7j+NeTJe2YjN+o4iXzlg1/5E9h3vXwL2NEUvF/nYckftPc4JiJLN75XOudj3IbOk7jfPcpyBbiz0G+T0lFTsKu+QD26DvUFZsaVOusYX80QNTC9yjW4f978BvKV8flYEhYw7rvJDbZ+iO3N72BcOJ4mXy76PDkb6xJZr/x25W1b4FyDD3U0R7twrA3uRJ/7s5CAnjoZcyiceg3jYQyVKj1DyhYcS4YQDgCu0SkYg+O8fw3GoPFeiPPmrslvY/lxyUN+ceQiOGc8iGIGXw62K3Mb9m/bAqxrQh12wkAp8tUGqypPa0fRRjQJ+8tgwWdnsPnffgSJelsR9u9AKxNm2FR5eiP61GJj+ZEYhx8ZYvmS2FicPRPjhBxpw/FifluNez3rX08p2vPnYMyQxgFci1p7kX/PTfGA3ftMDtgRk+qzgXx81rT5WG/vqnSwGy7DZ/O8Qf95HcZt+t6eq8COxsWo0LP+1LXh+mtg632ai/02hJgepQtjbYzOxfWjvkPN4YWjMT7NjvWY0T3kxHYZ/DjOyxZhTBKLHtty5FeobWu/UP3OuQ7i/DYtw9w+tj+6wR7MwLGVdh3mlak8NQrsxFPoF22hJ3YcqMT11lriAdvbg+u947iqayTgp8pfieZDIBAIBALBCIS8fAgEAoFAIBhWjFjaZeJtD5DBfOYTW8SGn7P6J+N2OoNZfQ6NsLTkSQfQHsSvzXTt5RiG+LnXMTzvXVe9CvZvnrsc7LQylXq88x38bMq3dYZd+NmNhyX/4lfWgv1S61Swq08jJWRtUp957TPxs5x3ALfHWSrwU5kRd32Rt4zlkm9h26kSse7Zm9R7axtmVKeoDT9PW9uwnWEr+mVCGdINNT24fTbVgZ9Wtbjt0qE/4Gd0/00YLnlhNpb98r5pdC64M3ELqu5N/IQccKtnuxdjOO3OXvyk60pEnzp+jZ8h665kqee78NOpYQLbYl4R9zmUzdqhfKQmzawsrQh9uLAA/bLpUCnY1makEKYsOxk73n2oCM6ZknA+hrtw7KTvwvk74c6jYL9dMQHsqZOwbgdq4lKws63yzkP4edrPtkZnzWoFu2sTLgCDzG9jnkXb+ePG2PHh3dhuI5syQRc+W7PhnLlx9i6w32hEn/fW41jTx33GjySx/m1jFCyDxv6sNATQb/7Mc4+XeKok4mD7U1kKC7MDabJII26tjbKqjtqC9zddhuWbEhSdZdmP61bhp9ha0YVrReQoUgZTy0+C3T6Ec7S+GalQS52i9cxTcS2J7ML+4SHpQ8lsG76BpfpgKSsm5WDof29IzZvqOlzXHJU4znm6hHAQ+++7M98A+1eVF4DtYyHxLfsU3cipaG02UpOJNpzv7XWKqor6/NR07w+EdhEIBAKBQDDyIC8fAoFAIBAIhhXy8iEQCAQCgWBYMWI1H7NeuIuMCWf4t+gTuJVrIBvfmYquqoodH25kW8ZYamF3BXJnnmnIV2Zke8D2bsdnhyYhdx7uUNoKzvEm7UetQ8q1GMq55ihuf5o7E9Oc7zowDmzDILY7alFdZ2s993sk3xYWZbxeOCPI/gPLMyUiz+d+U3Gx8ToIIqIoC+U85nKeOh551+hzGBq6a9q5uXPSq/M7Ln4ITn2m8kawu99EHw9OZTqMCtTGBJLZdGAaA0scDczDxq/4DG69ffmxxWDbLsXtru2nsN2uU+hznlo+7SLFEdfVICds8GKHmgZZGoG5qE/hWxD9LNX4vTe9APb925XWydKK90ZQ4kEJjUyjNQsFRon7mZ5oEXLKviGco7r47bWse/SjsD952PnB2Xg+2o1lJ+SixodvtTX44vqEPduQi/G2tVp89ujZ597uSGzrrs6HffjE8t/Fjh/vWAjntlSMB3vprMNgv/MCapsiM7Cd0ZPYzmAam2MmVTdjN+oDokzzYWQp2LUxuEYmbkK/8DD0eqZH0WerPnNuQv1Idxlub7Y4cF0an4nj/PBeDENuZPMigsMBdXkWrKetBi/2FTHtIdsWrHXgONfcWPeEY7iArPzs5tjxE7sxNLvOyvqHhV3QWF25LsfawLRRBVj3zExP7Li9GtcCWwuOS18pzueMNDV/I4MBqljxkGg+BAKBQCAQjDzIy4dAIBAIBIJhhbx8CAQCgUAgGFaMWM1HwY9UeHX+iqRjXGs0jpc3ViOHH0xBLszYz3h1tjfb2MtiUjAthLkJuTOHCgNAiY1YVvck5OVmX4O87IEO5ICznRjXoT+AnGHXdowj4ixTIdNDL6F+YBClL2fFINAxitBZhX7xZeL1lskerFubEiSYepiAhEHPtr/bMVI7DSxBjjjkRS7UUcX2pPeouhmvwfDI7W1usHl6d3szcr5947FyReMwLkRNE/rVflz1iW8S6gm0bqx3QiP6lMegCLPYDTz8Ng/XbO5Ttr2Vh9sGk8Is7b1Oz3h6Cz47HGDhlqP47Pgw1LUncRxyLYTRy+ZYBguBzuZY1jtYQH8eS0Ufp33xjcJ6XzzjCNgHHp4KdudcFp47wvQJjEu/cCLGhdjRWBg7Npnw2UODOD8Td+Da01/EtA1BfLajhMWkGYXaqFd3TVf1ZP1HWBRNGo/6kqMHC8DWTFiXnA1YgOtreH/vI/mxY88Y7E8Dk4cNTEL9QMn9PWB3LMb4RFy3MWVsI9jNT6oU7t2L8GHOCpxjE2/AsPIH23BNNWzDuB9cj2ZehPGRehrdsWNLKs5vridJseDv0IYDGK+m+I94vnIV1t3YzkKoD8TFdbFgf6fvx/5rn4N9wq83+LhWjfV3LdOQfEHN76EgrpnhzRhLZWgG01H1qHZEfX5q/Ob3RfMhEAgEAoFg5EFePgQCgUAgEAwr5OVDIBAIBALBsGLEaj5y/+cnpLed4VSNKbivOMpiLyTYFefY3417yhOSkJ/KcXvArtueB3aU7fu29LB074zndySqumX8P7y58zvIhXqr3WCbe5jOohD5TTurO89bEEyK4+3YHnJTA9MfYBoBilixXSHcTk/O+R1g9w0inx3Pf3Pum+fXSdnN9ARXdYMdfZOlmkeKkRLnoK6jLy5vzefH74RzT9fMBNvCePquWkx7r3Ojz11O5Gn7qjGfQ9SlytObkTd1OrG/wu/gs7jmZ3v9aLDzUlED0LIhF58d16WZ87FDNTYneA4TA8vl409leSncyCk7clB/NOBRA8RxBMdWgOW44CnULYUYYyJYg1ywqwpMGhyFbbnxmk2x48c3LIFzCaMxRkiyHfuAp5L/woR3wP7doUVgG+pwLFsneGLHQ5VuOGcZiz5yPouBWVqX4tgzeFh8lBScswU5qD/o2KT0C/b5eC7KVu2eDmxnUQHGlPGFzp0LJsGE86C6VWmd9CzP029X/B7sr/3xy2AHJ+EcCnvx2eYO9EPIxQVoym/O/TjWuEYrYxuuoe0LWVlM62Kyo8/HZ6OO49AxpXUxDGHZ42agLubEaZxjl07GnEWHu/F8Sw3qx3g+nXgEU3BtST6IdTH6cAD0jmexUkJoB53oBy2ZxUuJy2mjYxq98qv2gv3W67jGhovUnIsO+an+tvtF8yEQCAQCgWDkQV4+BAKBQCAQDCuM73/J8OLvLFDUr74TR4fOTbtESH0yjLIQxRELS/dtQjvix7I19tUuwkL/8rpEDKq8cBhvjgzhp8woe1YkwMKl+1hqasu56xr1xYcCxs9oUT/7FM62x0V0zIfsC2BkkD17iH3WM6lnR/ErK0V97PNykNEuQ1h2NMj9wurCr4+ri38gdM5rI4x2ifrwWToz87mRPYv73BxXXhg/jfJ7IwG8NzjAxgMbS2Hu8wAf9+99Ladd+L3EfMrHR9THxy7zQ1yY8UiA3cvL0rGxx8vi84CPTbbFOL6Pz7qXlR3W+FjB6/0D4XOe1zG3xZf/vs9m1EbUx7ZS+43sPI7dc/X/WT5ktAsf17yscIgtbAxh0znGJvPJoJeNez5O+Xrtw+uj3A9mTpUov5011phPI0G+hrKy2JocJfR5aJC1O86POj+WzX3Kfc7n9/tdH/G/N+3CfcbbqQvyOci2kDPahftYY2MvEjeHdWwXbpCvsXxNjOvvqO9Mmz+ImmPEaT6ampooNzf3/S8UCAQCgUAw4tDY2Eg5OTnnvGbEvXxEo1FqaWkhTdMoLy+PGhsb31e4IlDo7++n3Nxc8dt5QHz2j0H8dv4Qn/1jEL+dPz4Kn2maRl6vl7Kzs0mvP7eqY8TRLnq9nnJycqi//4yS3Ol0ymD7ByB+O3+Iz/4xiN/OH+Kzfwzit/PHcPvM5XK9/0UkglOBQCAQCATDDHn5EAgEAoFAMKwYsS8fFouFfvjDH5LFYnn/iwUxiN/OH+Kzfwzit/OH+Owfg/jt/DHSfTbiBKcCgUAgEAg+3hixXz4EAoFAIBB8PCEvHwKBQCAQCIYV8vIhEAgEAoFgWCEvHwKBQCAQCIYVI/bl4+GHH6aCggKyWq00Z84c2rNnz0ddpRGD1atX06xZsygxMZHS09PpqquuosrKSrjG7/fTqlWrKCUlhRwOB61YsYLa29vfo8RPHh588EHS6XR09913x/5PfPbuaG5ups9+9rOUkpJCNpuNJk2aRPv27Yud1zSNfvCDH1BWVhbZbDYqLy+nqqqqj7DGHy0ikQh9//vfp8LCQrLZbDRmzBj6yU9+AvkuxGdEW7dupcsvv5yys7NJp9PRSy+9BOc/iI96enroxhtvJKfTSW63m2677TYaGBgYxlYMP87lt1AoRN/+9rdp0qRJlJCQQNnZ2XTTTTdRS0sLlDEi/KaNQDzzzDOa2WzW/vSnP2nHjh3TvvjFL2put1trb2//qKs2IrBs2TLt8ccf144ePaodPHhQu+yyy7S8vDxtYGAgds1XvvIVLTc3V9u4caO2b98+be7cudq8efM+wlqPHOzZs0crKCjQJk+erN11112x/xefnY2enh4tPz9fu+WWW7Tdu3drp0+f1tatW6dVV1fHrnnwwQc1l8ulvfTSS9qhQ4e0K664QissLNR8Pt9HWPOPDg888ICWkpKivfrqq1ptba22Zs0azeFwaL/85S9j14jPNO3111/Xvve972kvvPCCRkTaiy++COc/iI8uueQSbcqUKdquXbu0bdu2aUVFRdoNN9wwzC0ZXpzLbx6PRysvL9eeffZZ7eTJk9rOnTu12bNnazNmzIAyRoLfRuTLx+zZs7VVq1bF7EgkomVnZ2urV6/+CGs1ctHR0aERkbZlyxZN084MQJPJpK1ZsyZ2zYkTJzQi0nbu3PlRVXNEwOv1amPHjtXWr1+vLV68OPbyIT57d3z729/WFixY8J7no9GolpmZqf33f/937P88Ho9msVi0v/71r8NRxRGH5cuXa5///Ofh/6655hrtxhtv1DRNfPZu4D+iH8RHx48f14hI27t3b+yaN954Q9PpdFpzc/Ow1f2jxLu9tHHs2bNHIyKtvr5e07SR47cRR7sEg0GqqKig8vLy2P/p9XoqLy+nnTt3foQ1G7no6+sjIqLk5GQiIqqoqKBQKAQ+LCkpoby8vE+8D1etWkXLly8H3xCJz94Lr7zyCs2cOZOuvfZaSk9Pp2nTptEf/vCH2Pna2lpqa2sDv7lcLpozZ84n1m/z5s2jjRs30qlTp4iI6NChQ7R9+3a69NJLiUh89kHwQXy0c+dOcrvdNHPmzNg15eXlpNfraffu3cNe55GKvr4+0ul05Ha7iWjk+G3EJZbr6uqiSCRCGRkZ8P8ZGRl08uTJj6hWIxfRaJTuvvtumj9/Pk2cOJGIiNra2shsNscG29+RkZFBbW1tH0EtRwaeeeYZ2r9/P+3du/esc+Kzd8fp06fp0UcfpXvvvZe++93v0t69e+lrX/samc1muvnmm2O+ebf5+kn123e+8x3q7++nkpISMhgMFIlE6IEHHqAbb7yRiEh89gHwQXzU1tZG6enpcN5oNFJycrL48f/g9/vp29/+Nt1www2x5HIjxW8j7uVDcH5YtWoVHT16lLZv3/5RV2VEo7Gxke666y5av349Wa3Wj7o6/zaIRqM0c+ZM+ulPf0pERNOmTaOjR4/Sb3/7W7r55ps/4tqNTDz33HP01FNP0dNPP00TJkyggwcP0t13303Z2dniM8GwIRQK0ac//WnSNI0effTRj7o6Z2HE0S6pqalkMBjO2mXQ3t5OmZmZH1GtRibuuOMOevXVV+ntt9+mnJyc2P9nZmZSMBgkj8cD13+SfVhRUUEdHR00ffp0MhqNZDQaacuWLfSrX/2KjEYjZWRkiM/eBVlZWTR+/Hj4v9LSUmpoaCAiivlG5qvCN7/5TfrOd75D119/PU2aNIk+97nP0T333EOrV68mIvHZB8EH8VFmZiZ1dHTA+XA4TD09PZ94P/79xaO+vp7Wr18f++pBNHL8NuJePsxmM82YMYM2btwY+79oNEobN26ksrKyj7BmIweaptEdd9xBL774Im3atIkKCwvh/IwZM8hkMoEPKysrqaGh4RPrw4suuoiOHDlCBw8ejP2bOXMm3XjjjbFj8dnZmD9//lnbuE+dOkX5+flERFRYWEiZmZngt/7+ftq9e/cn1m9DQ0Ok1+PSajAYKBqNEpH47IPgg/iorKyMPB4PVVRUxK7ZtGkTRaNRmjNnzrDXeaTg7y8eVVVVtGHDBkpJSYHzI8ZvwyZtPQ8888wzmsVi0Z544gnt+PHj2pe+9CXN7XZrbW1tH3XVRgRuv/12zeVyaZs3b9ZaW1tj/4aGhmLXfOUrX9Hy8vK0TZs2afv27dPKysq0srKyj7DWIw/xu100TXz2btizZ49mNBq1Bx54QKuqqtKeeuopzW63a3/5y19i1zz44IOa2+3WXn75Ze3w4cPalVde+YnbNhqPm2++WRs1alRsq+0LL7ygpaamat/61rdi14jPzuw8O3DggHbgwAGNiLSf//zn2oEDB2K7Mj6Ijy655BJt2rRp2u7du7Xt27drY8eO/dhvtT2X34LBoHbFFVdoOTk52sGDB+H3IRAIxMoYCX4bkS8fmqZpv/71r7W8vDzNbDZrs2fP1nbt2vVRV2nEgIje9d/jjz8eu8bn82lf/epXtaSkJM1ut2tXX3211tra+tFVegSCv3yIz94da9eu1SZOnKhZLBatpKRE+/3vfw/no9Go9v3vf1/LyMjQLBaLdtFFF2mVlZUfUW0/evT392t33XWXlpeXp1mtVm306NHa9773PVj8xWea9vbbb7/rOnbzzTdrmvbBfNTd3a3dcMMNmsPh0JxOp3brrbdqXq/3I2jN8OFcfqutrX3P34e33347VsZI8JtO0+LC7gkEAoFAIBB8yBhxmg+BQCAQCAQfb8jLh0AgEAgEgmGFvHwIBAKBQCAYVsjLh0AgEAgEgmGFvHwIBAKBQCAYVsjLh0AgEAgEgmGFvHwIBAKBQCAYVsjLh0AgEAgEgmGFvHwIBAKBQCAYVsjLh0AgEAgEgmGFvHwIBAKBQCAYVsjLh0AgEAgEgmHF/wf7Q9c2TTk4IwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(some_batch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(some_model(some_batch[0]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification.auroc import BinaryAUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINI(BinaryAUROC):\n",
    "    def __init__(self) -> None:\n",
    "        super(GINI, self).__init__()\n",
    "        \n",
    "    def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        return (2. * super().forward(logits, labels) - 1.) * 100.\n",
    "    \n",
    "    # def compute(self) -> torch.Tensor:\n",
    "    #     return super().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = GINI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(43.7500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a(some_model(some_batch[0]), some_batch[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0903,  0.0469,  0.0347, -0.1100,  0.0162,  0.0895,  0.0320,  0.1441,\n",
       "         0.0787,  0.0022,  0.0888, -0.0043,  0.1492, -0.0996,  0.0271,  0.0832,\n",
       "        -0.0649,  0.0250,  0.0833, -0.0095,  0.1098,  0.1297,  0.0403,  0.0176,\n",
       "        -0.0573, -0.0441, -0.1633,  0.0786, -0.0913,  0.0039, -0.0435, -0.0718],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(some_model(some_batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a._buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.979999999999993"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d((0.5749 * 2 - 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7188)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(a.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6924)\n",
      "tensor(11.7409)\n",
      "tensor(0.5587) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danil/projects/torch_template/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:436: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(0.6924, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(some_model.training_step(some_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.collate import ModelInput, SingleForwardState, BaseCollator, ModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sampler(targets: dict, n_samples: int = 1000, replacement: bool = True):\n",
    "\n",
    "    targets = np.asarray(list(targets.values()))\n",
    "    \n",
    "    sampler_factory = SamplerFactory(\n",
    "        targets=targets, \n",
    "        n_samples=n_samples,\n",
    "        replacement=replacement\n",
    "    )\n",
    "    return sampler_factory.balanced_random_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(features_path: str, data_path: str, indexes_path: str, targets_path: str, use_sampler: bool = True, batch_size: int = 32):\n",
    "    features_dict = OmegaConf.load(features_path)\n",
    "\n",
    "    data_reader = DataReader(data_path=data_path)\n",
    "    data_reader.setup()\n",
    "\n",
    "    indexes = IndexesReader(train_path=indexes_path).train_indexes\n",
    "\n",
    "    targets = TargetsReader(targets_path).targets\n",
    "\n",
    "    targets = {idx: targets.get(idx) for idx in indexes}\n",
    "\n",
    "    dataset = CreditsHistoryDataset(\n",
    "        data=data_reader, \n",
    "        targets=targets,\n",
    "        indexes=indexes,\n",
    "        features=features_dict\n",
    "    )\n",
    "\n",
    "    print(f\"dataset sample: {dataset[0]}\")\n",
    "\n",
    "    train_sampler = set_sampler(\n",
    "        targets=dataset.targets, \n",
    "        n_samples=10000,\n",
    "        replacement=False\n",
    "    ) if use_sampler else None\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=BaseCollator(max_seq_len=50),\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True\n",
    "    ) \n",
    "\n",
    "    return dataloader, features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sample: {'numerical': tensor([[ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
      "        [ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
      "        [ 0.4800,  0.1688,  0.1680,  0.9858,  7.2181,  0.0000],\n",
      "        [ 3.1200,  2.6531,  0.4693, -0.8830,  7.2181,  0.0000],\n",
      "        [ 0.2400,  0.0925,  0.0923,  0.9957,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 1.2000,  0.4866,  0.4677,  0.8839,  7.2181,  0.0000],\n",
      "        [ 2.2800,  1.3662,  0.9791,  0.2032,  7.2181,  0.0000],\n",
      "        [ 2.6400,  1.8312,  0.9663, -0.2574,  7.2181,  0.0000]]), 'categorical': tensor([[ 8, 12,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4, 11,\n",
      "          0],\n",
      "        [ 8,  6,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          3],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  1,  4,  2,\n",
      "          0],\n",
      "        [10,  1,  4,  3,  0,  2,  5, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          2],\n",
      "        [ 0, 17,  4,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          6],\n",
      "        [ 6,  8,  3,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "         11],\n",
      "        [18, 14,  3,  3,  0,  2, 13, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          0],\n",
      "        [11, 13,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          4],\n",
      "        [11,  0,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [ 7,  2,  0,  1,  0,  2,  4,  2,  2, 17,  0,  1,  1,  1,  2,  0,  4,  3,\n",
      "          0],\n",
      "        [ 7,  7,  2,  3,  0,  2,  1, 16,  2, 17,  1,  1,  1,  1,  2,  3,  4,  0,\n",
      "          2]]), 'target': 0, 'length': 12, 'sample_index': '205752'}\n"
     ]
    }
   ],
   "source": [
    "test_dataloader, _ = initialize_data(\n",
    "    \"configs/data/features/features_credits_aggregated_v2.yaml\",\n",
    "    \"./data/credits-history/serialized/serialized_first_part_v2\",\n",
    "    \"./data/credits-history/indexes/ser_full_0_indexes/train_indexes.pickle\",\n",
    "    \"./data/credits-history/targets/targets_dict.pickle\",\n",
    "    use_sampler=False,\n",
    "    batch_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sample: {'numerical': tensor([[ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
      "        [ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
      "        [ 0.4800,  0.1688,  0.1680,  0.9858,  7.2181,  0.0000],\n",
      "        [ 3.1200,  2.6531,  0.4693, -0.8830,  7.2181,  0.0000],\n",
      "        [ 0.2400,  0.0925,  0.0923,  0.9957,  7.2181,  0.0000],\n",
      "        [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
      "        [ 1.2000,  0.4866,  0.4677,  0.8839,  7.2181,  0.0000],\n",
      "        [ 2.2800,  1.3662,  0.9791,  0.2032,  7.2181,  0.0000],\n",
      "        [ 2.6400,  1.8312,  0.9663, -0.2574,  7.2181,  0.0000]]), 'categorical': tensor([[ 8, 12,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4, 11,\n",
      "          0],\n",
      "        [ 8,  6,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          3],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [15, 19,  2,  3,  0,  2,  4, 16,  2, 17,  1,  1,  1,  1,  3,  1,  4,  2,\n",
      "          0],\n",
      "        [10,  1,  4,  3,  0,  2,  5, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          2],\n",
      "        [ 0, 17,  4,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          6],\n",
      "        [ 6,  8,  3,  3,  0,  2,  7, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "         11],\n",
      "        [18, 14,  3,  3,  0,  2, 13, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  0,\n",
      "          0],\n",
      "        [11, 13,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  3,  4,  0,\n",
      "          4],\n",
      "        [11,  0,  2,  3,  0,  2,  3, 16,  2, 17,  1,  1,  1,  1,  3,  4,  4,  1,\n",
      "          0],\n",
      "        [ 7,  2,  0,  1,  0,  2,  4,  2,  2, 17,  0,  1,  1,  1,  2,  0,  4,  3,\n",
      "          0],\n",
      "        [ 7,  7,  2,  3,  0,  2,  1, 16,  2, 17,  1,  1,  1,  1,  2,  3,  4,  0,\n",
      "          2]]), 'target': 0, 'length': 12, 'sample_index': '205752'}\n"
     ]
    }
   ],
   "source": [
    "dataloader, features_dict = initialize_data(\n",
    "    \"configs/data/features/features_credits_aggregated_v2.yaml\",\n",
    "    \"./data/credits-history/serialized/serialized_first_part_v2\",\n",
    "    \"./data/credits-history/indexes/ser_full_0_indexes/train_indexes.pickle\",\n",
    "    \"./data/credits-history/targets/targets_dict.pickle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelBatch(numerical=tensor([[[ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
       "         [ 1.6800,  0.8012,  0.7182,  0.6959,  7.2181,  0.0000],\n",
       "         [ 0.1200,  0.0587,  0.0586,  0.9983,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.3200,  1.4793,  0.9958,  0.0914,  7.2181,  0.2000],\n",
       "         [ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
       "         [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.8800,  2.2093,  0.8030, -0.5960,  7.2181,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.8800,  1.0448,  0.8648,  0.5021,  7.2181,  0.2000],\n",
       "         [ 2.8800,  2.2093,  0.8030, -0.5960,  7.2181,  0.0000],\n",
       "         [ 1.6800,  0.8012,  0.7182,  0.6959,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.6800,  1.8967,  0.9474, -0.3202,  7.2181,  0.2000],\n",
       "         [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
       "         [ 0.1200,  0.0587,  0.0586,  0.9983,  7.2181,  0.2000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
       "         [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
       "         [ 0.1600,  0.0742,  0.0741,  0.9972,  7.2181,  0.2500],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]), categorical=tensor([[[ 8, 16,  2,  ...,  4,  0, 15],\n",
       "         [ 8, 13,  2,  ...,  4,  6,  0],\n",
       "         [ 8, 18,  2,  ...,  1,  3,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[15, 18,  2,  ...,  4,  5,  0],\n",
       "         [10,  5,  2,  ...,  4,  0,  3],\n",
       "         [ 0,  3,  2,  ...,  4,  0,  3],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 0,  4,  2,  ...,  4,  0,  5],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3,  3,  2,  ...,  4, 13,  0],\n",
       "         [ 1, 13,  2,  ...,  4,  0,  8],\n",
       "         [ 1,  0,  0,  ...,  4,  3,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[14,  5,  2,  ...,  4,  0,  3],\n",
       "         [14,  9,  2,  ...,  4,  0,  4],\n",
       "         [ 0,  2,  2,  ...,  1,  0,  7],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 8,  1,  2,  ...,  4,  2,  0],\n",
       "         [ 8, 17,  2,  ...,  4,  1,  0],\n",
       "         [ 8, 14,  2,  ...,  2,  7,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]]]), targets=tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]), sample_indexes=['101892', '50122', '133513', '100091', '248737', '17332', '140764', '184293', '120868', '223657', '37512', '53206', '230880', '117336', '215864', '76287', '140929', '106413', '249060', '175671', '10765', '97081', '213726', '156114', '163398', '87182', '99161', '191615', '104514', '105235', '145869', '192778'], mask=tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False,  True,  True,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True]]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sample check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample():\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    x = ModelInput(\n",
    "        numerical=batch.numerical,\n",
    "        categorical=batch.categorical,\n",
    "        mask=batch.mask\n",
    "    )\n",
    "\n",
    "    labels = batch.targets\n",
    "\n",
    "    return x, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(sample[0].numerical.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d((~sample[0].mask).sum(dim=1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6800,  2.0000,  2.4800,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8012,  1.1430,  1.6569,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7182,  0.9099,  0.9963,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.6959,  0.4149, -0.0860,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  7.2181,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.2500,  0.4500,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.6800,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8012,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7182,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.6959,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1200,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0587,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0586,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9983,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.2000,  0.1200,  0.1200,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4866,  0.0587,  0.0587,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4677,  0.0586,  0.0586,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8839,  0.9983,  0.9983,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  7.2181,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.3200,  2.5200,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.4372,  1.6636,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9911,  0.9957,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1332, -0.0927,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2500,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2400,  2.3600,  1.8800,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.3824,  1.5141,  0.9819,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9823,  0.9984,  0.8315,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1873,  0.0566,  0.5555,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 7.2181,  7.2181,  7.2181,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4500,  0.2000,  0.2500,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(rearrange(sample[0].numerical, \"N L H -> N H L\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model layers check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            categorical_features: dict,\n",
    "            embedding_dim: int = 32,\n",
    "            div_emb_dim: int = 4\n",
    "        ) -> None:\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.embeddings = nn.ModuleList()\n",
    "\n",
    "        for num_embs in self.categorical_features.values():\n",
    "            embedding = nn.Embedding(\n",
    "                num_embeddings=num_embs, \n",
    "                embedding_dim=embedding_dim // div_emb_dim\n",
    "            )\n",
    "\n",
    "            nn.init.xavier_normal_(embedding.weight, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "            self.embeddings.append(embedding)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        x = torch.concatenate(\n",
    "            [embedding(x[..., idx]) for idx, embedding in enumerate(self.embeddings)], dim=-1\n",
    "        ) # size = (batch_size, len(cat_features), embedding_dim)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            numerical_features: list,\n",
    "            categorical_features: dict,\n",
    "            embedding_dim: int = 16,\n",
    "            dropout_inputs: float = 0.5,\n",
    "            non_linear: bool = False,\n",
    "            num_batch_norm: bool = True,\n",
    "            div_emb_dim: int = 4\n",
    "        ) -> None:\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_inputs)\n",
    "\n",
    "        self.numerical_features = numerical_features\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "        self.embeddings = EmbeddingLayer(\n",
    "            categorical_features=categorical_features,\n",
    "            embedding_dim=embedding_dim,\n",
    "            div_emb_dim=div_emb_dim\n",
    "        )\n",
    "\n",
    "        if non_linear:\n",
    "            self.out_linear_block = nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    (embedding_dim // div_emb_dim) * len(self.categorical_features)  + len(self.numerical_features), \n",
    "                    embedding_dim\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Linear(embedding_dim, embedding_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.out_linear_block = nn.Linear(\n",
    "                (embedding_dim // div_emb_dim) * len(self.categorical_features) + len(self.numerical_features), \n",
    "                embedding_dim\n",
    "            )\n",
    "\n",
    "        if num_batch_norm:\n",
    "            self.num_bn = nn.BatchNorm1d(len(self.numerical_features))\n",
    "        else: \n",
    "            self.num_bn = None\n",
    "\n",
    "\n",
    "    def forward(self, inputs: ModelInput) -> SingleForwardState:\n",
    "\n",
    "        embeddings = self.embeddings(inputs.categorical)\n",
    "        \n",
    "        if self.num_bn is None:\n",
    "            x_num = inputs.numerical\n",
    "        else:\n",
    "            x_num = rearrange(inputs.numerical, \"N L H -> N H L\")\n",
    "\n",
    "            x_num = self.num_bn(x_num)\n",
    "\n",
    "            x_num = rearrange(x_num, \"N H L -> N L H\")\n",
    "            \n",
    "        x = torch.concatenate((x_num, embeddings), dim=-1)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_linear_block(x)\n",
    "\n",
    "        return SingleForwardState(\n",
    "            sequences=x, \n",
    "            mask=inputs.mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = EncoderLayer(\n",
    "    numerical_features=features_dict[\"numerical\"],\n",
    "    categorical_features=features_dict[\"categorical\"],\n",
    "    embedding_dim=32,\n",
    "    dropout_inputs=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc = enc(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleForwardState(sequences=tensor([[[-0.5113, -0.9685, -0.0861,  ...,  0.4099,  0.1583,  0.0737],\n",
       "         [-0.4842, -0.6502,  0.1040,  ...,  0.6913,  0.2640,  0.1248],\n",
       "         [-0.0340, -0.1316, -0.1748,  ..., -0.1548,  0.2995,  0.0970],\n",
       "         ...,\n",
       "         [ 0.1010, -0.0307, -0.0775,  ..., -0.2422,  0.2941, -0.0362],\n",
       "         [-0.0772, -0.1057, -0.0137,  ..., -0.1716,  0.1372, -0.0911],\n",
       "         [ 0.0984, -0.0449, -0.0655,  ..., -0.1163,  0.2412, -0.0523]],\n",
       "\n",
       "        [[-0.7419, -0.8589, -0.1126,  ...,  0.3296, -0.0126, -0.2237],\n",
       "         [-0.2850, -0.6907, -0.2830,  ...,  0.6737,  0.1470, -0.2512],\n",
       "         [-0.3457, -0.9516, -0.3187,  ...,  0.1937,  0.1948,  0.1292],\n",
       "         ...,\n",
       "         [-0.0898, -0.2178, -0.0795,  ..., -0.1736,  0.1483, -0.0140],\n",
       "         [ 0.2293, -0.1584, -0.2936,  ..., -0.3162,  0.3244, -0.0136],\n",
       "         [ 0.1604, -0.2722, -0.0267,  ..., -0.3264,  0.3231, -0.0405]],\n",
       "\n",
       "        [[-0.2048, -1.0213, -0.4025,  ..., -0.0259,  0.2322,  0.0123],\n",
       "         [ 0.0787, -0.1720, -0.1735,  ..., -0.4180,  0.2567, -0.1505],\n",
       "         [ 0.0636, -0.0520, -0.0669,  ..., -0.0565,  0.2630, -0.1176],\n",
       "         ...,\n",
       "         [ 0.0454, -0.2407,  0.0763,  ..., -0.2073,  0.1439, -0.2064],\n",
       "         [ 0.0171, -0.1895, -0.1307,  ..., -0.1847,  0.1052, -0.2581],\n",
       "         [-0.1174, -0.0287,  0.0505,  ..., -0.1428,  0.1621, -0.0444]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3949, -0.9354, -0.0825,  ...,  0.4605,  0.1936,  0.9574],\n",
       "         [-0.8886, -1.4487, -0.1313,  ...,  0.6568,  0.1683,  0.4965],\n",
       "         [-0.6205, -0.5862, -0.3987,  ...,  0.4056, -0.0524,  0.1606],\n",
       "         ...,\n",
       "         [-0.0515, -0.0713,  0.0173,  ..., -0.1622,  0.2149, -0.2112],\n",
       "         [-0.1775,  0.0875,  0.1322,  ..., -0.2395,  0.2658,  0.0132],\n",
       "         [ 0.0371, -0.0991,  0.0746,  ..., -0.2975,  0.2432, -0.2525]],\n",
       "\n",
       "        [[-0.0517, -0.9243, -0.1646,  ...,  0.3621, -0.2297,  0.1740],\n",
       "         [-1.0453, -0.7771,  0.0713,  ...,  0.4788,  0.3669, -0.3553],\n",
       "         [-0.5756, -1.1447,  0.0380,  ...,  0.5929,  0.2022,  0.4663],\n",
       "         ...,\n",
       "         [ 0.0423, -0.0463, -0.0621,  ..., -0.1655,  0.2218, -0.0975],\n",
       "         [ 0.1234, -0.0773,  0.0686,  ..., -0.2694,  0.1608, -0.2614],\n",
       "         [ 0.0417, -0.0466, -0.0353,  ..., -0.1430,  0.2341, -0.1188]],\n",
       "\n",
       "        [[-0.6133, -0.9264, -0.3943,  ...,  0.1705,  0.0388,  0.0907],\n",
       "         [-0.5743, -0.7615, -0.2856,  ...,  0.1684,  0.2532,  0.3716],\n",
       "         [-0.1516, -1.1503, -0.1648,  ..., -0.2443, -0.5089,  0.3311],\n",
       "         ...,\n",
       "         [ 0.0228, -0.0307, -0.0101,  ..., -0.3476,  0.0886, -0.0850],\n",
       "         [ 0.0213, -0.2130, -0.0670,  ..., -0.1293,  0.2965, -0.0326],\n",
       "         [-0.1408, -0.0150,  0.0327,  ..., -0.2180,  0.0884, -0.0906]]],\n",
       "       grad_fn=<ViewBackward0>), mask=tensor([[False, False,  True,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False,  True,  True,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True]]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False,  True,  True,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_enc.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_enc.sequences.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f844e083b10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(12, 10))\n",
    "\n",
    "ax = figure.add_subplot(2, 2, 1)\n",
    "ax.imshow(sample[0].categorical[0])\n",
    "\n",
    "ax = figure.add_subplot(2, 1, 1)\n",
    "ax.imshow(x_enc.sequences[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.base_transformer.encoder_decoder import Encoder\n",
    "from src.models.components.base_transformer.sub_layers import EncoderLayer\n",
    "from src.models.components.base_transformer.multihead_attention import MultiHeadAttention\n",
    "from src.models.components.base_transformer.positionwise_ff import PositionwiseFeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Encoder(\n",
    "    encoder_layer=EncoderLayer(\n",
    "        attention=MultiHeadAttention(32, 1),\n",
    "        feed_forward=PositionwiseFeedForward(32, activation_type=\"relu\")\n",
    "    ),\n",
    "    n_layers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att = attn(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7758, -1.9994,  0.1757,  ...,  1.4013, -1.1907, -0.2025],\n",
       "        [ 0.9439, -0.4874, -0.2644,  ...,  1.4152,  0.8526, -0.5830],\n",
       "        [-0.0913, -0.0525, -0.8279,  ..., -0.3373,  0.7199,  0.9299],\n",
       "        ...,\n",
       "        [ 0.0078, -0.5842,  1.0844,  ..., -0.3644,  1.0874, -0.2336],\n",
       "        [ 0.1086, -0.3108,  1.0199,  ..., -0.5918,  0.1625, -0.9471],\n",
       "        [-0.3101, -0.1325, -0.6453,  ..., -0.5450, -0.2703, -0.6323]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_att.sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_att.sequences.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f844e104750>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(6, 6))\n",
    "\n",
    "ax = figure.add_subplot()\n",
    "ax.imshow(x_att.sequences[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUSeqToSeq(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_size: int, \n",
    "            num_layers_gru: int = 1,\n",
    "            bidirectional: bool = False,\n",
    "            dropout_gru: float = 0.0\n",
    "    ) -> None:\n",
    "        super(GRUSeqToSeq, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=num_layers_gru,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_gru\n",
    "        )\n",
    "\n",
    "    def forward(self, x: SingleForwardState) -> SingleForwardState:\n",
    "\n",
    "        lengths = (~x.mask).sum(dim=1)\n",
    "\n",
    "        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            input=x.sequences, \n",
    "            lengths=lengths, \n",
    "            batch_first=True, \n",
    "            enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        state, _ = self.gru(packed_sequences)\n",
    "\n",
    "        padded_state, _ = torch.nn.utils.rnn.pad_packed_sequence(state, batch_first=True)\n",
    "\n",
    "        # unpacked_sequences = torch.nn.utils.rnn.unpack_sequence(packed_sequences=packed_sequences)\n",
    "\n",
    "        return SingleForwardState(\n",
    "            sequences=padded_state,\n",
    "            mask=x.mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gru_ = GRUSeqToSeq(\n",
    "    hidden_size=32,\n",
    "    num_layers_gru=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gru = x_gru_(x_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 19, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_gru.sequences.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f84497bbe50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(6, 6))\n",
    "\n",
    "ax = figure.add_subplot()\n",
    "ax.imshow(x_gru.sequences[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.pooling.agg_pooling import ConvPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingType(nn.Module):\n",
    "    num_poolings: int = None\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PoolingType, self).__init__()\n",
    "\n",
    "def first_pooling(hidden_state: torch.Tensor, dim: int = 1):\n",
    "    assert len(hidden_state.size()) == 3, \\\n",
    "        \"hidden state size should be (batch_size x num_seq x seq_len)\"\n",
    "\n",
    "    return hidden_state[:, 0, :] if dim == 1 else hidden_state[:, :, 0]\n",
    "\n",
    "\n",
    "def last_pooling(hidden_state: torch.Tensor, lengths: torch.Tensor, dim: int = 1):\n",
    "    assert len(hidden_state.size()) == 3, \\\n",
    "        \"hidden state size should be (batch_size x num_seq x seq_len)\"\n",
    "    \n",
    "    if dim == 1:\n",
    "        hidden_state = hidden_state[torch.arange(hidden_state.size(0)), lengths - 1, :] # (N, L, B)\n",
    "    elif dim == 2:\n",
    "        hidden_state = hidden_state[torch.arange(hidden_state.size(0)), :, lengths - 1] # (N, B, L)\n",
    "    else:\n",
    "        raise NotImplementedError(\"dim is not valid, select dim from the <[1, 2]>\")\n",
    "\n",
    "    return hidden_state\n",
    "\n",
    "\n",
    "def avg_pooling(hidden_state: torch.Tensor, lengths: torch.Tensor, dim: int = 1):\n",
    "    assert len(hidden_state.size()) == 3, \\\n",
    "        \"hidden state size should be (batch_size x num_seq x seq_len) or (num_seq x seq_len)\"\n",
    "\n",
    "    return torch.mean(hidden_state, dim=dim)\n",
    "\n",
    "\n",
    "class FirstLastAvgPoolings(PoolingType):\n",
    "    def __init__(self, dim: int = 1):\n",
    "        super(FirstLastAvgPoolings, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "\n",
    "        self.num_poolings = 3\n",
    "\n",
    "    def forward(self, hidden_state: torch.Tensor):\n",
    "        pooled_results = [\n",
    "            first_pooling(hidden_state, self.dim),\n",
    "            last_pooling(hidden_state, self.dim),\n",
    "            avg_pooling(hidden_state, self.dim)\n",
    "        ]\n",
    "        hidden_state_pooled = torch.concatenate(pooled_results, dim=self.dim)\n",
    "\n",
    "        return hidden_state_pooled\n",
    "    \n",
    "\n",
    "POOLING_MAPPING = {\n",
    "    \"first_last_avg\": FirstLastAvgPoolings\n",
    "}\n",
    "\n",
    "\n",
    "class Pooling(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            emb_dim: int,\n",
    "            pooling_type: str = \"all\", \n",
    "            use_batch_norm: bool = True,\n",
    "            dim: int = 1\n",
    "        ) -> None:\n",
    "        super(Pooling, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "\n",
    "        pooling_types = list(POOLING_MAPPING.keys())\n",
    "        assert pooling_type in pooling_types, \\\n",
    "            f\"You should specify pooling type from {pooling_types}, not {pooling_type}\"\n",
    "        \n",
    "        self.pooling_layer = POOLING_MAPPING[pooling_type](dim=dim)\n",
    "\n",
    "        input_size = self.pooling_layer.num_poolings * emb_dim\n",
    "\n",
    "        self.agg_layer = nn.Linear(input_size, emb_dim)\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(emb_dim) if use_batch_norm else nn.Identity()\n",
    "        \n",
    "    def forward(self, hidden_state: SingleForwardState) -> ModelOutput:\n",
    "        x = self.pooling_layer(hidden_state.sequences)\n",
    "        x = self.batch_norm(self.agg_layer(x))\n",
    "\n",
    "        return ModelOutput(\n",
    "            representations=x,\n",
    "            logits=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pooled_ = Pooling(emb_dim=32, pooling_type=\"first_last_avg\", use_batch_norm=False, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pooling(\n",
       "  (pooling_layer): FirstLastAvgPoolings()\n",
       "  (agg_layer): Linear(in_features=96, out_features=32, bias=True)\n",
       "  (batch_norm): Identity()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_pooled_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pooled = x_pooled_(x_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_pooled.representations.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f63a2eb4790>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_pooled.representations[0].detach().unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.collate import ModelOutput\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_TYPE_MAPPING = {\n",
    "    \"tanh\": nn.Tanh,\n",
    "    \"gelu\": nn.GELU,\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"none\": nn.Identity\n",
    "}\n",
    "\n",
    "def init_linear_block_weights(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.zeros_(layer.bias)\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            in_features: int, \n",
    "            out_features: int = 1, \n",
    "            num_layers: int = 3, \n",
    "            dropout_rate: float = 0.0, \n",
    "            activation_type: str = \"tanh\",\n",
    "            use_batch_norm: bool = False,\n",
    "            bias: bool = True\n",
    "        ) -> None:\n",
    "        super(LinearBlock, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        if activation_type is None:\n",
    "            self.act = ACTIVATION_TYPE_MAPPING[\"tanh\"]\n",
    "        elif activation_type in ACTIVATION_TYPE_MAPPING.keys():\n",
    "            self.act = ACTIVATION_TYPE_MAPPING[activation_type]\n",
    "        else: \n",
    "            NotImplementedError(f\"activation_type must be in <{list(ACTIVATION_TYPE_MAPPING.keys())}>\")\n",
    "\n",
    "        if use_batch_norm:\n",
    "            self.layer_norm = nn.BatchNorm1d\n",
    "        else:\n",
    "            self.layer_norm = nn.LayerNorm\n",
    "\n",
    "        self.linear_block = nn.Sequential(\n",
    "            *[\n",
    "                nn.Sequential(\n",
    "                    *[\n",
    "                        nn.Linear(in_features // (2 ** i), in_features // (2 ** (i + 1)), bias),\n",
    "                        self.layer_norm(in_features // (2 ** (i + 1))),\n",
    "                        self.act()\n",
    "                    ]\n",
    "                ) for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.out_block = nn.Linear(\n",
    "            in_features=in_features // (2 ** num_layers), out_features=out_features\n",
    "        )\n",
    "\n",
    "        self.cls_layers = nn.Sequential(\n",
    "            self.dropout,\n",
    "            self.linear_block,\n",
    "            self.out_block,\n",
    "            self.act()\n",
    "        )\n",
    "\n",
    "        # weights init\n",
    "        self.cls_layers.apply(init_linear_block_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x: ModelOutput) -> ModelOutput:\n",
    "        logits = self.cls_layers(x.representations)\n",
    "\n",
    "        return ModelOutput(\n",
    "            representations=x.representations,\n",
    "            logits=logits\n",
    "        )\n",
    "\n",
    "\n",
    "class MultiTaskLinearBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            heads: List[LinearBlock]\n",
    "    ) -> None: \n",
    "        super(MultiTaskLinearBlock, self).__init__()\n",
    "\n",
    "        self.heads = nn.ModuleList(heads)\n",
    "\n",
    "    def forward(self, x: ModelOutput) -> ModelOutput:\n",
    "        multi_state = [\n",
    "            head(x).logits for head in self.heads\n",
    "        ]\n",
    "\n",
    "        logits = torch.concat(multi_state, dim=1) # size(batch_size, num_outputs)\n",
    "        \n",
    "        return ModelOutput(\n",
    "            representations=x.representations,\n",
    "            logits=logits\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = MultiTaskLinearBlock(\n",
    "    heads=[\n",
    "        LinearBlock(32, 1, 2)\n",
    "    ]\n",
    ")(x_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelOutput(representations=tensor([[-0.0807, -0.0925,  0.0185,  ...,  0.0862,  0.0276, -0.0489],\n",
       "        [-0.0164, -0.0240,  0.0047,  ...,  0.0191,  0.0072, -0.0139],\n",
       "        [-0.0550, -0.0686,  0.0153,  ...,  0.0614,  0.0193, -0.0378],\n",
       "        ...,\n",
       "        [-0.0029, -0.0036,  0.0004,  ...,  0.0021,  0.0021, -0.0017],\n",
       "        [-0.1101, -0.1254,  0.0267,  ...,  0.1202,  0.0347, -0.0692],\n",
       "        [-0.0092, -0.0124, -0.0006,  ...,  0.0077,  0.0030, -0.0051]],\n",
       "       grad_fn=<SqueezeBackward1>), logits=tensor([[-0.3835],\n",
       "        [-0.4595],\n",
       "        [-0.3846],\n",
       "        [-0.5128],\n",
       "        [-0.4077],\n",
       "        [-0.4268],\n",
       "        [-0.4213],\n",
       "        [-0.6295],\n",
       "        [-0.4995],\n",
       "        [-0.0691],\n",
       "        [-0.4164],\n",
       "        [-0.4121],\n",
       "        [-0.3576],\n",
       "        [-0.3559],\n",
       "        [-0.3748],\n",
       "        [-0.3683],\n",
       "        [-0.3324],\n",
       "        [-0.3280],\n",
       "        [-0.3166],\n",
       "        [-0.3467],\n",
       "        [-0.4153],\n",
       "        [-0.5702],\n",
       "        [-0.4393],\n",
       "        [-0.3760],\n",
       "        [-0.3955],\n",
       "        [-0.4136],\n",
       "        [-0.3758],\n",
       "        [-0.4318],\n",
       "        [-0.3609],\n",
       "        [-0.2603],\n",
       "        [-0.3825],\n",
       "        [-0.5049]], grad_fn=<CatBackward0>))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metrics import GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "            self, \n",
    "            model: nn.Module, \n",
    "            optimizer: torch.optim.Optimizer, \n",
    "            criterion: nn.BCEWithLogitsLoss,\n",
    "            train_dataloader: torch.utils.data.DataLoader, \n",
    "            scheduler: torch.optim.lr_scheduler.LRScheduler = None\n",
    "        ) -> None:\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.task_names = [\"tanh_output\"]\n",
    "        self.task_weights = torch.tensor([1.0])\n",
    "\n",
    "        self.train_data = train_dataloader\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "        self.gini = GINI()\n",
    "\n",
    "        self.train_results = list()\n",
    "\n",
    "    def multioutput_loss(self, logits: ModelOutput, targets: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # logits size is (batch_size, num_outputs)\n",
    "        # targets size is (batch_size, 1)\n",
    "\n",
    "        targets = targets.expand(size=(-1, len(self.task_names))) # to size like logits\n",
    "\n",
    "        weighted_loss = self.task_weights * self.criterion(logits, targets)\n",
    "        \n",
    "        # (self.task_weights * self.criterion(logits, targets)).sum() / len(self.task_names)\n",
    "        loss = weighted_loss.sum() / (len(weighted_loss) * len(self.task_names))\n",
    "        branched_loss = (weighted_loss.sum(dim=0) / len(weighted_loss)).detach()\n",
    "\n",
    "        return loss, branched_loss\n",
    "\n",
    "    def fit(self, epochs: int = 3, show_step: int = 100):\n",
    "        n_total_steps = len(self.train_data)\n",
    "\n",
    "        loss_step = 0\n",
    "        gini_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            self.epoch = epoch\n",
    "            \n",
    "            print('Epoch %s/%s' % (epoch + 1, epochs))\n",
    "\n",
    "            for step, batch in enumerate(self.train_data):\n",
    "                self.optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                x = ModelInput(\n",
    "                    numerical=batch.numerical,\n",
    "                    categorical=batch.categorical,\n",
    "                    lengths=batch.lengths\n",
    "                )\n",
    "\n",
    "                labels = batch.targets\n",
    "\n",
    "                outputs = self.model(x)\n",
    "        \n",
    "                loss, _ = self.multioutput_loss(\n",
    "                    logits=outputs.logits,\n",
    "                    targets=labels\n",
    "                )\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                loss_step += loss.item()\n",
    "                gini_step += self.gini(outputs.logits[:, 0], labels.squeeze())\n",
    "\n",
    "                self.train_results.append(\n",
    "                    [\n",
    "                        self.epoch * n_total_steps + step, \n",
    "                        loss.item()\n",
    "\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                if (step + 1) % show_step == 0:\n",
    "                    print(\n",
    "                        f\"Step [{step+1}/{n_total_steps}] | Time: {time.time() - epoch_start_time:.2f}s | Loss: {loss_step / show_step:.4f} | GINI: {gini_step / show_step:.1f}\"\n",
    "                    )\n",
    "                    gini_step = 0\n",
    "                    loss_step = 0\n",
    "\n",
    "        self.train_writer = pd.DataFrame(self.train_results, columns=[\"step\", \"loss\"])\n",
    "\n",
    "        print('\\nDone.')\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'''[INFO]\\n{\"-\" * 60}\\ndata: {self.data} \\n{\"-\" * 60} \\nmodel: {self.model} \\n{\"-\" * 60} \\noptimizer: {self.optimizer} \\n{\"-\" * 60}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    EncoderLayer(\n",
    "        numerical_features=features_dict[\"numerical\"],\n",
    "        categorical_features=features_dict[\"categorical\"],\n",
    "        embedding_dim=32,\n",
    "        dropout_inputs=0.1\n",
    "    ),\n",
    "    SimpleAttention1d(\n",
    "        features_dim=32\n",
    "    ),\n",
    "    GRUSeqToSeq(\n",
    "        hidden_size=32,\n",
    "        num_layers_gru=1\n",
    "    ),\n",
    "    ConvPooling(\n",
    "        pooling_type=\"avg\", dim=1\n",
    "    ),\n",
    "    MultiTaskLinearBlock(\n",
    "        heads=[\n",
    "            LinearBlock(32, 1, 2)\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = bnb.optim.Adam8bit(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.99)\n",
    "\n",
    "train_model = Trainer(\n",
    "    model=model, \n",
    "    criterion=nn.BCEWithLogitsLoss(\n",
    "        reduction=\"none\"\n",
    "    ),\n",
    "    train_dataloader=dataloader, \n",
    "    optimizer=opt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.fit(epochs=3, show_step=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(test_sample).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(44.4487)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(GINI()(preds, test_sample.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - 40.82 ~ lr 1e-4\n",
    "# 2 - 44.80 ~ lr 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_preds = torch.concatenate((torch.sigmoid(preds), test_sample.targets), dim=1).sort(dim=0).values.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(test_sample.targets, torch.sigmoid(preds).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr, label=np.trapz(fpr, tpr))\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.ch_lit_module import CHLitModule\n",
    "from IPython.display import display as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, ckpt_path: str):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = CHLitModule.load_from_checkpoint(ckpt_path)\n",
    "        self.net.eval()\n",
    "        self.net.freeze()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danil/projects/LHT_credits_history/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n"
     ]
    }
   ],
   "source": [
    "trained_model = PretrainedModel(\"logs/train/runs/2024-05-17_15-29-11/checkpoints/epoch_008.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'net.layers.0.embeddings.embeddings.0.weight': Parameter containing:\n",
       " tensor([[ 0.3699, -0.2070, -0.0574,  0.2860,  0.2871, -0.6516, -0.6582,  0.5127],\n",
       "         [ 0.1410,  0.2636, -0.3663,  0.0577, -0.0728, -0.2222, -0.1203,  0.2031],\n",
       "         [-0.0567,  0.1484, -0.0080,  0.4410, -0.4481,  0.6227,  0.2812,  0.1424],\n",
       "         [ 0.5029,  0.5404,  0.2679, -0.2057,  0.1066,  0.6148,  0.0578,  0.2919],\n",
       "         [ 0.0854, -0.5548, -0.3337, -0.7263, -0.8032,  0.1141,  0.6581, -0.1204],\n",
       "         [ 0.0527,  0.1385,  0.4128,  0.0555, -0.0998,  0.6886,  0.2679,  0.2707],\n",
       "         [ 0.0658, -0.6800,  0.2542,  0.0125,  0.1882, -0.2867, -0.4131, -0.0066],\n",
       "         [-0.5129,  0.3926, -0.1316,  0.1095,  0.1492,  0.0342, -0.1043, -0.1082],\n",
       "         [ 0.7351, -0.2886, -0.0506, -0.1919, -0.3095, -0.0912, -0.4972, -0.6453],\n",
       "         [-0.0855,  0.7006,  0.1623,  0.0464, -0.3214,  0.2569,  0.4515, -0.2935],\n",
       "         [ 0.1043, -1.0722,  0.4554, -0.1094, -0.4576,  0.2693, -0.4176, -0.5339],\n",
       "         [-0.0371,  0.3646,  0.0029,  0.1255,  0.3745, -0.1615, -0.2103,  0.1747],\n",
       "         [-0.4477,  0.4286, -0.7409, -0.2609,  0.8090, -0.2080,  0.7119,  0.1521],\n",
       "         [-0.5949,  0.2777,  0.2093, -0.1092, -1.0188,  0.3513, -0.0582,  0.6688],\n",
       "         [ 0.7310, -0.3986, -0.3268,  0.1958, -0.1449, -0.1986,  0.1352,  0.0091],\n",
       "         [ 0.5874,  0.3664,  0.4509,  0.1803, -0.0789,  0.3012, -0.4218, -0.0349],\n",
       "         [ 0.2038, -0.5040, -0.1111,  0.3532,  0.3121,  0.2887, -0.4364, -0.0628],\n",
       "         [ 0.3136, -0.6425,  0.2121,  0.2583, -0.0404, -0.3557,  0.4833, -0.4263],\n",
       "         [-0.1137,  0.6033, -0.3684, -0.4334, -0.4225, -0.4419, -0.1906,  0.0969],\n",
       "         [-0.5504,  0.2417,  0.0559,  0.5556,  0.6404, -0.0128,  0.5223, -0.9649]]),\n",
       " 'net.layers.0.embeddings.embeddings.1.weight': Parameter containing:\n",
       " tensor([[ 1.4486e-01, -8.4162e-03, -4.5565e-01,  1.9824e-01,  3.5770e-01,\n",
       "          -6.7466e-01,  2.1231e-02, -5.9421e-02],\n",
       "         [ 6.2493e-01,  2.9356e-01,  3.8539e-02, -2.5011e-01, -4.3072e-01,\n",
       "           1.8201e-01,  8.8827e-01,  8.6883e-02],\n",
       "         [ 2.1339e-01,  2.5476e-01, -2.7484e-01, -7.7017e-01,  2.8994e-01,\n",
       "          -6.1247e-01, -3.1169e-01, -4.6875e-01],\n",
       "         [-1.9644e-01, -4.6290e-01, -5.3011e-01,  1.6047e-01, -6.8754e-01,\n",
       "          -2.2702e-02,  4.1159e-01,  3.6379e-01],\n",
       "         [-4.9860e-01,  3.4768e-01, -1.9776e-01, -4.3667e-02,  1.6519e-02,\n",
       "           1.4165e-01,  1.3021e-01,  3.0409e-01],\n",
       "         [ 1.0245e-01, -1.9459e-01,  9.2944e-01,  7.6801e-01,  3.6170e-01,\n",
       "           1.3476e-01,  5.3134e-02,  7.4413e-01],\n",
       "         [-4.8779e-02,  2.3430e-01,  3.3678e-01, -3.7895e-01, -8.2183e-01,\n",
       "           5.9627e-01, -4.4715e-02, -3.0324e-02],\n",
       "         [ 2.1342e-01,  6.2804e-01, -6.1529e-01,  1.6437e-01,  1.1295e-01,\n",
       "           1.2914e-01, -2.2412e-01, -1.8831e-01],\n",
       "         [-3.7579e-02, -1.5021e-02, -2.2728e-01, -1.4991e-01, -5.8891e-01,\n",
       "          -2.6950e-01, -4.0308e-01, -2.9204e-01],\n",
       "         [-9.1534e-02,  3.7934e-02, -1.4085e-01, -1.1701e-01,  6.4543e-02,\n",
       "           2.5350e-01, -1.5982e-01, -6.4189e-01],\n",
       "         [ 5.3639e-02, -6.7709e-01,  3.7026e-01, -1.2262e-01, -2.7149e-01,\n",
       "          -1.2375e-01, -4.6411e-01, -1.2218e-01],\n",
       "         [-3.6897e-01,  6.1150e-02, -4.4581e-01,  1.8853e-01,  6.0916e-01,\n",
       "          -6.5131e-01, -3.3568e-01, -4.2717e-01],\n",
       "         [-2.0694e-01, -3.8299e-01, -3.5880e-01, -2.5959e-01, -1.3685e-01,\n",
       "           3.3959e-02,  5.1714e-01,  5.0149e-01],\n",
       "         [-1.0959e-01,  1.2136e-01, -8.4377e-01,  1.9433e-02, -7.5642e-01,\n",
       "           2.0120e-01,  5.3814e-01,  6.7135e-01],\n",
       "         [ 2.1148e-01,  2.5272e-01, -8.0080e-01, -6.6379e-01, -2.8547e-01,\n",
       "           1.1342e-01, -6.1835e-01, -2.6939e-01],\n",
       "         [-5.7616e-01,  5.5770e-01,  2.2561e-01, -4.1419e-01,  2.9555e-01,\n",
       "          -3.2157e-01, -1.9211e-02, -5.0737e-01],\n",
       "         [-3.9740e-01,  9.5004e-02, -4.4697e-02,  3.2251e-01,  3.6058e-01,\n",
       "           2.1366e-01, -4.4092e-01, -5.1126e-02],\n",
       "         [ 6.4047e-01, -3.5863e-04,  3.8538e-01, -6.6080e-01,  8.4513e-02,\n",
       "          -4.3819e-01, -6.5651e-01,  4.4106e-01],\n",
       "         [-8.3729e-01, -4.2938e-01,  2.7319e-01,  8.4573e-01, -1.7910e-01,\n",
       "           2.2771e-01,  6.2106e-01,  3.3628e-01],\n",
       "         [-5.5010e-01,  2.1760e-01,  6.0231e-03, -3.7408e-01, -5.1552e-01,\n",
       "          -4.0486e-01, -8.0313e-02,  4.9991e-01]]),\n",
       " 'net.layers.0.embeddings.embeddings.2.weight': Parameter containing:\n",
       " tensor([[ 0.6608,  0.3828,  0.0715,  0.4743,  0.9467, -0.4042, -0.6038,  0.5793],\n",
       "         [-0.0612,  0.0080, -0.6608, -0.2622, -0.1906,  0.0737, -0.0367, -0.2096],\n",
       "         [-0.0613, -0.0596, -0.1397, -0.1823,  0.0946,  0.4129,  0.4616,  0.0570],\n",
       "         [ 0.4553, -0.2540,  0.4839, -0.1264, -0.4109,  0.1005, -0.3238, -0.4464],\n",
       "         [ 0.2446,  0.1265, -0.3660,  0.3330, -0.4137,  0.0578,  0.2425, -0.6465],\n",
       "         [-0.1739,  0.7009,  0.7156,  0.1337,  0.4426, -0.7709,  0.0276, -0.0102],\n",
       "         [ 0.3795, -0.6475, -0.0967,  0.2992, -0.4874,  0.7064, -0.0865, -0.8072]]),\n",
       " 'net.layers.0.embeddings.embeddings.3.weight': Parameter containing:\n",
       " tensor([[-1.0307e-38,  5.6863e-38,  1.3083e-37, -1.1697e-37, -4.3280e-37,\n",
       "          -6.1806e-16,  1.2844e-12,  6.1162e-37],\n",
       "         [-1.9754e-01,  9.8726e-02,  9.4574e-01,  1.8982e-01, -2.6669e-01,\n",
       "          -1.2165e+00,  3.3451e-01, -4.1318e-02],\n",
       "         [ 4.7152e-01,  2.4193e-01, -2.0784e-02, -1.1080e+00, -5.6541e-01,\n",
       "          -1.0781e-01,  5.4607e-01,  2.7843e-01],\n",
       "         [ 3.9281e-01,  3.9180e-02, -2.5086e-01,  1.0118e+00,  2.0189e-02,\n",
       "           7.5169e-01, -1.0633e-01,  1.3392e-01],\n",
       "         [ 2.3112e-01,  2.1500e-01, -2.8654e-01,  1.2198e-01,  1.1343e-01,\n",
       "           7.2469e-01,  2.1169e-01, -4.4113e-02],\n",
       "         [-6.1595e-01,  1.4697e-01,  6.3444e-02, -4.7802e-01,  5.5114e-01,\n",
       "           1.2976e-01,  2.6681e-01,  7.6738e-01]]),\n",
       " 'net.layers.0.embeddings.embeddings.4.weight': Parameter containing:\n",
       " tensor([[ 1.3618e-01, -1.8195e-01,  2.1763e-01,  2.9006e-04, -1.0983e-01,\n",
       "           9.5374e-01,  8.8828e-01, -2.7143e-01]]),\n",
       " 'net.layers.0.embeddings.embeddings.5.weight': Parameter containing:\n",
       " tensor([[-6.9460e-37,  5.8971e-37, -4.8037e-41,  1.6891e-16, -1.4655e-37,\n",
       "           1.7127e-37,  2.9910e-15, -2.6226e-24],\n",
       "         [ 7.6857e-01, -4.5586e-01,  7.3561e-02,  9.7966e-01, -5.7258e-01,\n",
       "          -5.3602e-02,  2.7674e-01, -3.9850e-01],\n",
       "         [-2.7756e-01,  2.5624e-01, -1.1488e+00, -7.0115e-01, -1.5195e-01,\n",
       "          -1.9409e-01,  1.0869e+00,  9.1124e-02],\n",
       "         [ 6.9379e-01,  2.2495e-01,  7.4558e-01, -7.9139e-01, -8.2792e-01,\n",
       "          -1.9944e-01, -1.0485e+00,  1.3868e+00]]),\n",
       " 'net.layers.0.embeddings.embeddings.6.weight': Parameter containing:\n",
       " tensor([[-0.2413,  0.1284,  0.0037, -0.0816,  0.2464,  0.5616,  0.6795, -0.1006],\n",
       "         [ 0.0222, -0.7855, -0.0211, -0.2199, -0.1987, -0.5374,  0.5106,  0.3013],\n",
       "         [-0.1688,  1.3242,  0.7843,  0.1698, -0.3121, -0.9089,  0.4922, -1.0942],\n",
       "         [ 0.0239, -0.1377, -0.2940, -0.0451,  0.0362,  0.2306, -0.2560,  0.1016],\n",
       "         [ 0.3291, -0.0495,  0.3242,  0.1616, -0.1243, -0.0969,  0.5979, -0.0494],\n",
       "         [ 1.0816,  0.4916, -0.4460, -0.5293, -0.1079, -0.3923,  0.3422, -0.0344],\n",
       "         [-0.8146, -0.4814, -0.8073, -0.8589, -1.7223,  0.7144, -1.0766,  0.3380],\n",
       "         [-0.4894,  0.6819,  0.4576, -1.0043,  0.4201,  0.1259, -0.3841,  0.6140],\n",
       "         [-0.1321,  0.0510,  0.2373,  0.0292,  0.7752,  0.0834, -0.3249,  0.4005],\n",
       "         [-0.8666,  0.4070, -0.2442, -0.5267, -0.6530,  0.0758,  0.3668,  0.2747],\n",
       "         [-0.1379,  0.0351, -0.6636,  0.0691, -0.8350, -0.1817,  0.2017, -0.2158],\n",
       "         [ 0.3363,  0.5530,  0.8710,  0.2909,  0.9601, -0.6810,  0.3714,  0.5128],\n",
       "         [-0.1757,  0.0308, -0.1793, -0.2242, -0.1382,  0.1037, -0.1528, -0.0276],\n",
       "         [ 0.7769,  0.1083,  0.0385,  0.8766, -0.2536, -0.1284,  0.2989,  0.3563]]),\n",
       " 'net.layers.0.embeddings.embeddings.7.weight': Parameter containing:\n",
       " tensor([[-0.3831, -0.4169, -0.4428, -0.1510,  0.2282, -0.0667, -0.5584,  0.1191],\n",
       "         [-0.2802, -0.1744, -0.1539,  0.0575,  0.0026,  0.3624, -0.3464, -0.0626],\n",
       "         [ 0.0131,  0.2963, -0.1381,  0.2302, -0.3822,  0.2743, -0.1141, -0.0994],\n",
       "         [-0.7013,  0.5318,  0.4939, -0.2377,  0.3926,  0.2371,  0.4776,  0.0802],\n",
       "         [ 0.0450, -0.0245, -0.7132,  0.0357, -0.7897,  0.3641, -0.5876, -0.0212],\n",
       "         [-0.0416, -0.7332,  0.0334,  0.2584, -0.6165,  0.1971, -0.5438,  0.0716],\n",
       "         [-0.4723,  0.5654,  0.3618, -0.6227,  0.9729,  0.0349, -0.1327,  0.6978],\n",
       "         [ 0.0999, -0.3877,  0.1779,  0.4706, -0.4632, -0.2266,  0.6148, -0.3059],\n",
       "         [ 0.0262, -0.3809, -1.0266,  0.1099, -0.0987, -0.1246, -0.2548, -0.3345],\n",
       "         [ 0.4611, -0.4514,  0.1950,  0.3692, -0.0317, -0.6240,  0.3002, -0.4926],\n",
       "         [ 0.7806,  0.0408, -0.8322,  0.2131,  0.0719, -0.3996,  0.0612, -0.4567],\n",
       "         [ 0.3560, -0.0604, -0.1971, -0.5029,  0.6104,  0.3185, -0.0287,  0.1506],\n",
       "         [ 0.3948,  0.1358, -0.6924, -0.0508, -0.1562,  0.0299, -0.3302, -0.6646],\n",
       "         [ 0.3628, -0.6740,  0.4207,  0.0690, -0.6097,  0.9868, -1.0510, -0.6634],\n",
       "         [-0.4883,  1.1292,  0.3740,  0.0675,  0.4617, -0.6138,  0.3504,  0.4487],\n",
       "         [ 0.2615, -0.3776, -0.4519, -0.4168,  0.2798, -0.1662,  0.3122,  0.0571],\n",
       "         [ 0.6981, -0.3692, -0.2504,  0.1838, -0.0111, -0.3197, -0.3824, -0.8023],\n",
       "         [-0.3031,  0.1286,  0.2887, -0.4914,  0.5416, -0.1604,  0.0435,  0.3013],\n",
       "         [-0.8132,  0.2175, -0.0792, -0.1296,  0.4513,  0.0279, -0.3165,  0.1563],\n",
       "         [ 0.0203, -0.1471, -0.6696,  0.6428, -0.0872, -0.1789,  0.0263, -0.3440]]),\n",
       " 'net.layers.0.embeddings.embeddings.8.weight': Parameter containing:\n",
       " tensor([[-0.0887,  0.0170,  0.0787,  0.0677,  0.0756, -0.0773, -0.0963, -0.0482],\n",
       "         [ 0.0419, -0.1665, -0.3908,  0.0793, -0.3039,  0.0738,  0.0727, -0.0283],\n",
       "         [-0.0011,  0.1489,  0.1656,  0.0133, -0.0372, -0.1898, -0.0264,  0.0895],\n",
       "         [-0.2190, -0.7439, -0.1381,  0.2555,  0.0461,  0.1681,  0.2141,  0.0791],\n",
       "         [ 0.1159,  0.1202,  0.0080, -0.4905,  0.0407, -0.1019,  0.0962, -0.0536],\n",
       "         [-0.3728,  0.8235,  0.6007, -0.0352,  0.5079, -0.7777, -0.4698, -0.3093],\n",
       "         [-0.1261, -0.3202, -0.4856, -0.1554,  0.1413,  0.2780,  0.1156,  0.3592],\n",
       "         [-0.0191,  0.0695,  0.0480, -0.0247,  0.2341, -0.0353, -0.0913, -0.0529],\n",
       "         [ 0.3356,  0.1528, -0.0897, -0.0039, -0.0739,  0.1632,  0.3652, -0.0745],\n",
       "         [-0.3567, -0.2443, -0.3196,  0.0603, -0.2701,  0.2214, -0.2196,  0.5629],\n",
       "         [ 0.3753,  0.0369, -0.0829, -0.0962,  0.0412, -0.0087,  0.2009,  0.0116],\n",
       "         [ 0.1938,  0.4010, -0.2405, -0.1433, -0.1336,  0.4342,  0.1869,  0.1119],\n",
       "         [ 0.0010, -0.1381, -0.0301, -0.0407,  0.0045,  0.2324,  0.0015,  0.0239],\n",
       "         [ 0.2502, -0.0748, -0.0329, -0.2237, -0.0660,  0.1394,  0.0933,  0.0889],\n",
       "         [ 0.1725,  0.1875,  0.1636, -0.0098,  0.6621,  0.0621,  0.2414,  0.0727],\n",
       "         [-0.7369, -0.1966,  0.8105, -0.1380,  0.1937,  0.3890,  0.1746, -0.0463],\n",
       "         [ 0.1713,  0.0159, -0.1305, -0.1307, -0.1213, -0.1826,  0.0161,  0.2578],\n",
       "         [ 0.8933,  0.5469,  0.0242, -0.4879, -0.0253,  0.4660,  0.5605,  0.0847],\n",
       "         [ 0.0652, -0.0024, -0.0419, -0.0670, -0.0487,  0.2839, -0.0283,  0.0283],\n",
       "         [-0.0255,  0.1182,  0.0724, -0.0030,  0.0246,  0.0268, -0.0100, -0.2308]]),\n",
       " 'net.layers.0.embeddings.embeddings.9.weight': Parameter containing:\n",
       " tensor([[-0.3213,  0.5153, -0.1018,  0.0601,  0.0301,  0.3129,  0.0267,  0.3361],\n",
       "         [-0.1591,  0.4491, -0.1488, -0.3203,  0.2155,  0.0978, -0.4693,  0.3432],\n",
       "         [-0.2984,  0.2238,  0.1454, -0.1610,  0.0139, -0.1156,  0.0280,  0.1426],\n",
       "         [-0.4718,  1.0050, -0.6100, -0.7001,  0.7681,  0.3090, -0.1499,  0.3004],\n",
       "         [-0.3025, -0.3094, -0.1449,  0.7013, -0.2669,  0.0736, -0.1078, -0.5032],\n",
       "         [-0.2671, -0.2319,  0.0858, -0.0189,  0.3643,  0.5338,  0.0410, -0.4559],\n",
       "         [-0.0715, -0.2244, -0.1092,  0.5166,  0.0093,  0.0112, -0.0499,  0.3208],\n",
       "         [-0.7349, -0.0860, -0.2521, -0.3993, -0.1924,  0.6249, -0.0383, -0.6879],\n",
       "         [-0.1712,  0.4790, -0.4338, -0.0961, -0.0756,  0.5965, -0.2708,  0.3095],\n",
       "         [-0.4475,  0.0493,  0.2219, -0.7793,  0.2198, -0.2449, -0.5104,  0.2094],\n",
       "         [-0.2789,  0.4379, -0.1685,  0.4615,  0.4090, -0.1856,  0.6667, -0.3288],\n",
       "         [ 0.4492, -0.1214, -0.1666, -0.0107, -0.1517,  0.4920, -0.0994,  0.4554],\n",
       "         [-0.0350,  0.2706,  0.2295,  0.0117, -0.2074,  0.3779,  0.0185,  0.0496],\n",
       "         [ 0.1030,  0.3818, -0.2804, -0.0565, -0.0500,  0.3161, -0.4357,  0.1672],\n",
       "         [-0.2674,  0.3690, -0.1886, -0.2708, -0.0643, -0.0652,  0.3795,  0.1503],\n",
       "         [-0.2040,  0.5028, -0.1293, -0.1505,  0.4970, -0.0878, -0.0750,  0.0107],\n",
       "         [-0.7710,  0.5228, -0.0239, -0.1900,  0.9982,  0.5661, -0.4154, -0.3557],\n",
       "         [ 0.2565, -0.0655,  0.3542,  0.3906, -0.2783, -0.7857,  0.0610, -0.1003],\n",
       "         [ 0.2237,  0.4810,  0.0777,  0.0153, -0.3737, -0.0502, -0.0437, -0.1091],\n",
       "         [-0.1595,  0.4802,  0.4217, -0.0025,  0.2673, -0.4429,  0.1339, -0.0154]]),\n",
       " 'net.layers.0.embeddings.embeddings.10.weight': Parameter containing:\n",
       " tensor([[-0.1891,  0.2401,  0.6123, -0.1554, -0.1301,  0.7779,  0.3927, -0.3423],\n",
       "         [ 0.1212, -0.4372, -0.4910,  0.3850,  0.1452,  0.3034,  0.7498,  0.8975]]),\n",
       " 'net.layers.0.embeddings.embeddings.11.weight': Parameter containing:\n",
       " tensor([[-0.5760, -0.6169,  0.4271,  1.5180,  0.0122, -0.7530,  0.5248,  1.0505],\n",
       "         [ 0.0851, -0.4647, -0.3914, -0.0527,  0.4631,  0.4202,  0.0944, -0.2080]]),\n",
       " 'net.layers.0.embeddings.embeddings.12.weight': Parameter containing:\n",
       " tensor([[ 0.1376, -0.4114,  0.4250,  0.1801,  0.9097,  0.1948, -0.3582, -0.7290],\n",
       "         [-0.4982,  0.4025,  0.0877, -0.3788, -0.2560, -0.0104,  0.8675, -0.3599]]),\n",
       " 'net.layers.0.embeddings.embeddings.13.weight': Parameter containing:\n",
       " tensor([[-6.0072e-08,  2.3362e-04,  8.3390e-13, -1.0469e-03, -5.8885e-04,\n",
       "          -6.2651e-06, -6.6802e-05, -8.4885e-06],\n",
       "         [ 1.6027e-01,  3.5757e-01, -8.9040e-03,  2.7691e-01,  3.8958e-01,\n",
       "           4.3144e-01,  4.1128e-01,  4.9539e-01],\n",
       "         [ 3.1289e-01, -1.0793e-01, -7.5482e-02,  1.3855e-01,  8.3097e-02,\n",
       "          -4.7159e-01,  2.8731e-01, -5.9911e-02],\n",
       "         [ 1.6580e-01,  5.6175e-01, -1.1814e+00,  8.2343e-02, -1.6861e-01,\n",
       "          -1.1163e-01, -1.0191e+00, -1.0704e-01],\n",
       "         [ 3.2897e-02, -1.4383e-01, -6.9260e-01, -1.3416e-01,  2.6739e-01,\n",
       "           4.0858e-01, -4.7624e-01, -2.0612e-01],\n",
       "         [-1.3136e-01, -1.2645e-01,  2.6186e-01, -1.0437e-01, -7.9133e-02,\n",
       "           2.8178e-01,  3.5988e-01,  9.6962e-02],\n",
       "         [ 2.0276e-01,  1.9968e-02,  7.0914e-02, -1.8071e-01, -2.8233e-01,\n",
       "           9.3903e-01, -6.8328e-02, -8.4316e-03]]),\n",
       " 'net.layers.0.embeddings.embeddings.14.weight': Parameter containing:\n",
       " tensor([[-0.1353, -0.6455, -0.1610,  0.1535,  0.0486, -0.1417,  0.4860,  0.6765],\n",
       "         [-0.7442,  0.1611,  0.4347, -0.5585,  0.2298,  0.2902,  0.0047, -0.3423],\n",
       "         [ 0.4194, -0.1868, -0.3656, -0.5380,  0.0782, -0.2336, -0.2759, -0.1146],\n",
       "         [ 0.0030,  0.2495,  0.3349,  0.3881,  0.4534,  0.6536,  0.1641,  0.1043],\n",
       "         [ 0.1121, -0.1445, -0.3760, -1.1398, -0.4515, -0.3297, -0.6497,  0.3621],\n",
       "         [ 0.3684,  0.0864, -0.2460,  0.3889,  0.3454, -0.2345, -0.2668, -0.6077],\n",
       "         [-0.0304,  0.0534,  0.1391,  0.1652,  0.0433, -0.0218, -0.3206, -0.3333]]),\n",
       " 'net.layers.0.embeddings.embeddings.15.weight': Parameter containing:\n",
       " tensor([[-0.1895,  0.3512, -0.3661,  0.0062,  0.2483,  0.5834,  0.2658, -1.7934],\n",
       "         [-0.6979,  0.1805, -1.1045,  0.1074, -0.5061,  1.1015,  0.6865, -0.0029],\n",
       "         [ 0.1658,  0.1043, -0.4313, -1.1367,  0.2264,  0.4805, -0.0635, -1.0172],\n",
       "         [ 0.4902, -0.2647,  0.2869,  1.0406, -0.4891, -0.4472, -0.2855, -0.2732],\n",
       "         [ 0.0246, -0.5862, -0.0483,  0.8256,  0.4503,  0.0913,  0.0567,  0.3148],\n",
       "         [-0.8464,  0.9901,  0.4946,  0.3443, -0.0529, -0.1688, -0.4665,  1.1000]]),\n",
       " 'net.layers.0.embeddings.embeddings.16.weight': Parameter containing:\n",
       " tensor([[ 1.6203e-37, -6.0786e-37,  2.8775e-26, -6.3934e-37,  7.8445e-15,\n",
       "           2.4013e-18, -1.2605e-37, -3.0099e-07],\n",
       "         [ 1.5572e-01, -7.1458e-01, -9.2235e-01,  6.4094e-01, -4.9816e-01,\n",
       "          -9.8599e-02, -3.7303e-01, -3.2612e-01],\n",
       "         [-7.1664e-01,  1.5654e-01,  6.4631e-02, -7.0614e-01,  5.4036e-01,\n",
       "           7.4472e-02, -1.1542e+00, -3.8993e-02],\n",
       "         [ 1.7894e-01,  3.1493e-01, -3.4817e-01, -6.3263e-01,  3.3546e-02,\n",
       "          -5.2596e-01,  1.0314e+00,  3.4716e-01],\n",
       "         [ 5.1263e-02, -1.1011e+00,  1.6123e-01,  2.5478e-01, -1.8900e-01,\n",
       "          -9.6235e-02,  8.0228e-01,  6.7749e-01]]),\n",
       " 'net.layers.0.embeddings.embeddings.17.weight': Parameter containing:\n",
       " tensor([[ 4.3539e-01,  3.4163e-01,  8.9343e-01,  2.1335e-01, -2.1181e-01,\n",
       "           4.4179e-02, -1.4050e-01,  9.3238e-02],\n",
       "         [-2.5339e-01,  5.0645e-01, -1.4207e-01,  3.7112e-01, -7.7007e-02,\n",
       "           2.7463e-01, -6.4376e-01, -2.6677e-02],\n",
       "         [ 2.9055e-01,  5.0680e-02, -2.9195e-01, -4.4720e-01, -7.3568e-01,\n",
       "           2.1418e-01, -1.3449e-01, -1.0054e-01],\n",
       "         [ 4.1167e-01,  5.1290e-02,  3.0616e-01,  3.9143e-01, -4.0894e-01,\n",
       "          -1.9080e-02, -4.4146e-01, -5.6574e-01],\n",
       "         [-1.4218e-01, -2.8339e-01, -4.2854e-01,  3.8817e-04,  6.4396e-02,\n",
       "          -6.2242e-02,  1.5361e-01,  4.0618e-01],\n",
       "         [ 2.6432e-01,  2.0742e-01,  2.3468e-01, -4.4556e-01,  4.0000e-02,\n",
       "          -3.7557e-01,  1.7160e-01,  5.3973e-01],\n",
       "         [-6.5461e-01, -6.9751e-01, -9.7789e-02,  3.5048e-02,  3.8629e-01,\n",
       "           7.2590e-01, -5.6016e-02,  9.6905e-01],\n",
       "         [-6.1588e-01,  7.7564e-01, -1.6748e-01,  8.5528e-01, -3.2732e-01,\n",
       "           4.4020e-01, -1.9385e-01, -7.3765e-01],\n",
       "         [ 6.3634e-02, -1.7160e-02,  1.7056e-02, -4.3382e-01, -2.3687e-01,\n",
       "          -5.1957e-01,  2.6780e-01,  9.9234e-01],\n",
       "         [ 5.4904e-01, -6.0352e-01, -4.0018e-01, -3.8817e-01, -5.4633e-01,\n",
       "           7.9012e-01,  8.2668e-02,  1.0462e-01],\n",
       "         [ 8.6447e-01, -7.6857e-01, -1.3896e-02,  2.4954e-01, -2.8747e-01,\n",
       "          -5.0881e-01,  5.1559e-01, -1.2843e-02],\n",
       "         [-1.1647e-01,  2.0484e-01, -3.5006e-01, -4.0192e-01, -1.7167e-01,\n",
       "          -4.0066e-01, -2.9514e-02,  7.1507e-01],\n",
       "         [ 2.8056e-01, -6.5353e-02, -8.9366e-01,  1.7662e-01,  4.5346e-01,\n",
       "          -2.3570e-01,  1.2821e-01, -2.7469e-01],\n",
       "         [-5.9398e-02, -2.4007e-01, -3.4979e-01, -2.5347e-01, -4.7828e-01,\n",
       "          -1.7809e-01,  3.7143e-01,  5.2174e-01],\n",
       "         [-3.0315e-01, -6.1225e-01,  8.2811e-01,  4.0402e-01,  4.3790e-01,\n",
       "          -2.2718e-01,  4.5417e-01,  2.1983e-02],\n",
       "         [-2.1968e-01, -9.7699e-01,  7.2826e-02,  2.8257e-01,  1.8036e-01,\n",
       "           3.2361e-01,  9.2294e-01, -5.5877e-01],\n",
       "         [-3.9790e-01, -1.3958e-01,  4.9135e-01, -6.1779e-02, -4.6985e-01,\n",
       "           1.9947e-01,  8.3648e-02, -3.4447e-01],\n",
       "         [ 4.7954e-01,  3.5575e-01, -1.7876e-01, -9.8665e-02,  5.3181e-03,\n",
       "           3.7279e-01,  6.9046e-02,  1.3126e-01]]),\n",
       " 'net.layers.0.embeddings.embeddings.18.weight': Parameter containing:\n",
       " tensor([[-0.0549,  0.3557, -0.3752,  0.0790, -0.1296,  0.1875, -0.0361, -0.1924],\n",
       "         [-0.5485, -0.4588,  0.4104,  0.0770,  0.7058, -0.4511,  0.1482, -0.4598],\n",
       "         [ 0.6910, -0.0158, -0.0235,  0.0466, -0.7259,  0.2444, -0.3894,  0.7420],\n",
       "         [-0.8548, -0.2296,  0.1978, -0.2134, -0.0438, -0.1481,  0.0615,  0.1818],\n",
       "         [ 0.4070,  0.3224, -0.1304,  0.5145, -0.3644,  0.0499, -0.4189, -0.8215],\n",
       "         [-0.4851,  0.2049,  0.0790,  0.4298, -0.5386, -0.4876,  0.2717,  0.1191],\n",
       "         [-0.1082,  0.5287,  0.1941, -0.1939, -0.3707,  0.5616, -0.1148,  0.3887],\n",
       "         [-0.1413, -0.1806,  0.7639,  0.2811,  0.5759,  0.0979,  0.3890, -0.4435],\n",
       "         [-0.0275, -0.0221, -0.6424, -0.4822, -0.2432, -0.0957,  0.0827, -0.2710],\n",
       "         [ 0.0867, -0.0937, -0.4486, -0.3780,  0.1472,  0.0607, -0.5104,  0.2844],\n",
       "         [-0.2980,  0.1437, -0.2575,  0.0655, -0.1744, -0.4496,  0.6490, -0.1050],\n",
       "         [-0.0389, -0.3472,  0.0728, -0.3594,  0.0991, -0.5701, -0.6624, -0.6770],\n",
       "         [-0.4006, -0.4330,  0.0789, -0.2948,  0.0383,  0.1184, -0.2945,  0.3538],\n",
       "         [ 0.6115, -0.3334,  0.2896,  0.0479,  0.4364,  0.1239, -0.4277,  0.2253],\n",
       "         [ 0.2127, -0.2855,  0.1152,  0.1721,  0.1543, -0.0668, -0.4994, -0.2221],\n",
       "         [-0.1723, -0.0629,  0.1204,  0.5192,  0.1148, -0.5376,  0.4710,  0.7193],\n",
       "         [ 0.4769, -0.0566, -0.5287, -0.1655,  0.4982, -0.6181, -0.3408,  0.1398]]),\n",
       " 'net.layers.0.out_linear_block.weight': Parameter containing:\n",
       " tensor([[-0.0180,  0.0209, -0.0287,  ...,  0.0361, -0.0553,  0.0406],\n",
       "         [-0.0255, -0.0080, -0.0378,  ...,  0.0333, -0.0747,  0.0360],\n",
       "         [ 0.0002, -0.0062, -0.0031,  ..., -0.0703,  0.0235,  0.0046],\n",
       "         ...,\n",
       "         [ 0.0735,  0.0225,  0.0532,  ..., -0.1285,  0.0714,  0.1155],\n",
       "         [-0.0032,  0.0125,  0.0189,  ..., -0.0300,  0.1586, -0.0604],\n",
       "         [ 0.0132, -0.0121,  0.0581,  ..., -0.0417, -0.0724, -0.0736]]),\n",
       " 'net.layers.0.out_linear_block.bias': Parameter containing:\n",
       " tensor([-0.0397, -0.0874, -0.0478,  0.0162, -0.0749, -0.0132,  0.0528,  0.0234,\n",
       "          0.0089,  0.0588,  0.1218, -0.0620,  0.0212,  0.0846, -0.1005, -0.0398,\n",
       "          0.0591, -0.0231,  0.0337, -0.0832,  0.0659, -0.0164, -0.0561, -0.0477,\n",
       "          0.0525,  0.1063,  0.0805,  0.0162, -0.0567, -0.1046, -0.0704,  0.0157]),\n",
       " 'net.layers.0.num_bn.weight': Parameter containing:\n",
       " tensor([0.9007, 0.9247, 0.8880, 0.9454, 0.8057, 1.2055]),\n",
       " 'net.layers.0.num_bn.bias': Parameter containing:\n",
       " tensor([-0.1994, -0.2414, -0.2604, -0.0786, -0.1908, -0.1913]),\n",
       " 'net.layers.1.position_wise_layer.0.weight': Parameter containing:\n",
       " tensor([[-0.0898, -0.1443, -0.0776,  ..., -0.1566, -0.0926, -0.0913],\n",
       "         [-0.1884,  0.0630, -0.0407,  ...,  0.1368, -0.0161,  0.1441],\n",
       "         [-0.0139, -0.1241,  0.1603,  ...,  0.0809, -0.1675,  0.0091],\n",
       "         ...,\n",
       "         [-0.1136, -0.0003,  0.1104,  ...,  0.0535,  0.2096, -0.0023],\n",
       "         [ 0.1302,  0.1176,  0.2322,  ...,  0.1465,  0.0769,  0.0855],\n",
       "         [-0.1827, -0.1797,  0.0293,  ..., -0.1256, -0.1043,  0.0998]]),\n",
       " 'net.layers.1.position_wise_layer.0.bias': Parameter containing:\n",
       " tensor([ 0.0497, -0.0881, -0.0402,  0.0433, -0.1759, -0.0909, -0.0711, -0.0167,\n",
       "         -0.1448, -0.0933,  0.0224, -0.1780, -0.0223, -0.1625, -0.2358, -0.1808,\n",
       "          0.1166, -0.1606,  0.0907, -0.0616, -0.1796, -0.2069,  0.1143, -0.1865,\n",
       "         -0.1275,  0.0138, -0.1726, -0.0260,  0.0649, -0.1251,  0.0074,  0.0437,\n",
       "          0.0822, -0.0094,  0.0043,  0.0878, -0.1825, -0.1465,  0.0906, -0.1362,\n",
       "         -0.0498, -0.0647, -0.0636, -0.0909,  0.0214, -0.1539, -0.0549, -0.0312,\n",
       "         -0.1184, -0.2282, -0.2838, -0.0478, -0.0774,  0.0728, -0.1735,  0.0810,\n",
       "          0.0552,  0.0416, -0.1570, -0.0187,  0.1729,  0.0331, -0.0244, -0.0423]),\n",
       " 'net.layers.1.position_wise_layer.2.weight': Parameter containing:\n",
       " tensor([[ 0.1334,  0.1508,  0.0824,  ..., -0.0050, -0.0555, -0.0422],\n",
       "         [-0.0663, -0.0693, -0.0681,  ..., -0.0699, -0.0976,  0.0959],\n",
       "         [-0.0852, -0.0285,  0.0880,  ..., -0.0385, -0.0404, -0.2013],\n",
       "         ...,\n",
       "         [ 0.0231,  0.0985, -0.0376,  ...,  0.1101,  0.0562, -0.1266],\n",
       "         [-0.0277,  0.1610, -0.0322,  ..., -0.0507, -0.0140, -0.0829],\n",
       "         [ 0.0003,  0.0370,  0.0965,  ...,  0.0058, -0.0417,  0.0155]]),\n",
       " 'net.layers.1.position_wise_layer.2.bias': Parameter containing:\n",
       " tensor([ 0.0176,  0.0611, -0.0404, -0.0976,  0.0564, -0.1150, -0.0684,  0.1453,\n",
       "         -0.1264, -0.0260, -0.0103, -0.0017, -0.0003,  0.1086,  0.0516, -0.0916,\n",
       "          0.1189,  0.1206, -0.0276,  0.1009, -0.0312,  0.0612,  0.0537,  0.0436,\n",
       "         -0.0360, -0.0267, -0.0624, -0.0562,  0.0144, -0.0406, -0.0380,  0.0160]),\n",
       " 'net.layers.1.layer_norm.weight': Parameter containing:\n",
       " tensor([1.0268, 1.0857, 0.9313, 1.0373, 0.8841, 0.9817, 0.9772, 0.9801, 0.9052,\n",
       "         0.9523, 0.9848, 0.9749, 0.9732, 0.9731, 0.9676, 0.9902, 1.1238, 0.9981,\n",
       "         0.8287, 0.9608, 0.9791, 0.8742, 0.9073, 0.9014, 0.9727, 0.9736, 0.9590,\n",
       "         0.8445, 0.9091, 1.0826, 0.9626, 1.0928]),\n",
       " 'net.layers.1.layer_norm.bias': Parameter containing:\n",
       " tensor([ 3.0717e-02, -2.7414e-02,  6.9915e-02,  4.9484e-05, -2.6491e-02,\n",
       "          2.4890e-02,  3.7044e-04,  1.2504e-02,  3.0295e-02, -5.2074e-02,\n",
       "         -3.3098e-02,  4.1176e-02,  7.5433e-02,  1.8818e-02,  1.1207e-02,\n",
       "          2.5477e-02, -2.1186e-02, -2.0661e-02,  4.1460e-03,  8.1063e-03,\n",
       "          1.9449e-02, -1.1387e-03,  5.7350e-03, -1.3789e-04,  4.9138e-02,\n",
       "         -4.0924e-02, -1.9845e-02, -6.0532e-02,  8.6678e-04,  1.0556e-03,\n",
       "          2.0784e-02,  2.8078e-02]),\n",
       " 'net.layers.2.gru.weight_ih_l0': Parameter containing:\n",
       " tensor([[ 0.0641, -0.0320,  0.0253,  ...,  0.1477,  0.1248,  0.1878],\n",
       "         [-0.0305, -0.0604,  0.0616,  ..., -0.1363, -0.0322,  0.0153],\n",
       "         [-0.0580, -0.1045, -0.0354,  ...,  0.3431,  0.2326, -0.1190],\n",
       "         ...,\n",
       "         [ 0.0428, -0.0848,  0.1358,  ...,  0.0890,  0.0801,  0.1203],\n",
       "         [-0.1012, -0.0637, -0.0695,  ...,  0.1512, -0.0324,  0.1003],\n",
       "         [ 0.1605, -0.2403,  0.0643,  ...,  0.2116,  0.0329,  0.0674]]),\n",
       " 'net.layers.2.gru.weight_hh_l0': Parameter containing:\n",
       " tensor([[ 0.1252, -0.0832, -0.0551,  ...,  0.0469,  0.2503,  0.1052],\n",
       "         [-0.0457,  0.0952,  0.1296,  ...,  0.1408,  0.0984, -0.0053],\n",
       "         [-0.0437,  0.0212,  0.1516,  ...,  0.0363, -0.0067, -0.0554],\n",
       "         ...,\n",
       "         [ 0.0980, -0.1581,  0.0090,  ..., -0.1855,  0.0437, -0.1293],\n",
       "         [ 0.0794,  0.1149, -0.1771,  ..., -0.1339, -0.1018,  0.0516],\n",
       "         [ 0.0841,  0.0382, -0.0077,  ...,  0.1389, -0.1262, -0.0472]]),\n",
       " 'net.layers.2.gru.bias_ih_l0': Parameter containing:\n",
       " tensor([ 0.0182,  0.0426, -0.1152, -0.0699,  0.1286, -0.1811, -0.0333, -0.1298,\n",
       "          0.0171, -0.0622,  0.1290, -0.0965,  0.0953, -0.0862, -0.1125, -0.0477,\n",
       "         -0.1179,  0.0624,  0.2178,  0.0350,  0.0528, -0.0082, -0.1448, -0.0979,\n",
       "          0.1778,  0.2542, -0.1884, -0.0853, -0.1801, -0.1076,  0.1513,  0.0818,\n",
       "         -0.1960, -0.0517,  0.1168, -0.0636,  0.0999, -0.0528, -0.0757,  0.0003,\n",
       "          0.0554,  0.0637,  0.0136,  0.2018,  0.1753, -0.0011, -0.1860, -0.0770,\n",
       "         -0.0972, -0.1346, -0.0228,  0.0040, -0.0350,  0.0919,  0.1336,  0.0096,\n",
       "         -0.1066,  0.0775, -0.1105,  0.0823,  0.0037,  0.1789,  0.0945,  0.0589,\n",
       "         -0.1526,  0.2496, -0.1363,  0.0080,  0.0623,  0.1137,  0.1313,  0.1089,\n",
       "         -0.1071,  0.0613,  0.0477, -0.1502, -0.0930,  0.0912, -0.1227,  0.0492,\n",
       "         -0.0967,  0.1799,  0.0211, -0.1046,  0.0644, -0.1126,  0.0364,  0.1003,\n",
       "          0.0926,  0.0706, -0.0485, -0.0545,  0.0167, -0.1726,  0.0382,  0.0311]),\n",
       " 'net.layers.2.gru.bias_hh_l0': Parameter containing:\n",
       " tensor([-0.2026,  0.0376,  0.0675, -0.1831,  0.1923,  0.1047, -0.0090,  0.1654,\n",
       "         -0.1057,  0.0570,  0.0994,  0.0672, -0.0136, -0.0071, -0.1924,  0.2321,\n",
       "         -0.0896, -0.0152,  0.0357, -0.0010,  0.0693, -0.1082,  0.0421, -0.2020,\n",
       "          0.0393,  0.0931, -0.0194, -0.0151,  0.1245,  0.1126,  0.1242, -0.1788,\n",
       "         -0.0333, -0.0191,  0.0204, -0.0640, -0.0191, -0.0479,  0.1350,  0.0283,\n",
       "         -0.0947,  0.1139, -0.0541,  0.0823,  0.1690, -0.0309, -0.2586,  0.0573,\n",
       "         -0.0655,  0.1126,  0.0958, -0.0321, -0.1529,  0.1671,  0.0793, -0.0886,\n",
       "         -0.1549,  0.1073,  0.1566,  0.1232,  0.0460, -0.0676, -0.0580, -0.0866,\n",
       "         -0.0350,  0.1547, -0.0133,  0.1254, -0.0074,  0.0473,  0.1020, -0.0492,\n",
       "         -0.0014, -0.1628,  0.0419, -0.0373,  0.1198,  0.0648, -0.1506, -0.1495,\n",
       "         -0.1252,  0.0801,  0.0428,  0.0839, -0.1411,  0.0075, -0.0864, -0.1257,\n",
       "         -0.0532, -0.1148, -0.0174,  0.0084,  0.0047,  0.0068, -0.0930,  0.0497]),\n",
       " 'net.layers.3.agg_layer.weight': Parameter containing:\n",
       " tensor([[[ 0.0043,  0.2484, -0.1597],\n",
       "          [ 0.1646,  0.0241,  0.2101],\n",
       "          [ 0.1220,  0.1829,  0.3189]]]),\n",
       " 'net.layers.4.heads.0.linear_block.0.0.weight': Parameter containing:\n",
       " tensor([[-0.2124, -0.1738,  0.0606,  0.3558,  0.2000, -0.2629,  0.1284,  0.4022,\n",
       "           0.4317,  0.3059, -0.5277,  0.3435,  0.0983, -0.2995, -0.1152,  0.2583,\n",
       "           0.1792,  0.2158, -0.1293, -0.2302, -0.0500,  0.0146, -0.0208,  0.4554,\n",
       "          -0.2079, -0.5258, -0.0102,  0.0412,  0.1117,  0.2160,  0.1763,  0.2738],\n",
       "         [-0.2780, -0.0870, -0.0108, -0.2906, -0.0060,  0.0349, -0.3999, -0.0700,\n",
       "           0.3480, -0.0381,  0.1043, -0.2678,  0.1311, -0.5006, -0.0639, -0.1828,\n",
       "          -0.0644,  0.5551, -0.2088,  0.5612, -0.4323,  0.4973,  0.2037, -0.4380,\n",
       "          -0.0159, -0.4176,  0.0629,  0.1088,  0.5038,  0.4842,  0.0735, -0.1471],\n",
       "         [ 0.1281,  0.3320,  0.0571, -0.3767,  0.0023, -0.0282,  0.0263,  0.4732,\n",
       "          -0.2240, -0.0960, -0.2471,  0.0353, -0.0875,  0.1641,  0.4672, -0.4446,\n",
       "          -0.4008, -0.1283,  0.1861, -0.1658,  0.1691,  0.1299, -0.1950, -0.2108,\n",
       "           0.3001, -0.1613, -0.0417, -0.0865,  0.4109, -0.4541, -0.4589, -0.2309],\n",
       "         [-0.0187,  0.1639, -0.1142, -0.4457, -0.3123, -0.1266,  0.0173,  0.1374,\n",
       "           0.4733,  0.4250, -0.3774,  0.1169, -0.0336, -0.1072, -0.0722, -0.0617,\n",
       "           0.0462,  0.5896, -0.2964, -0.2145,  0.4392,  0.2613,  0.3691,  0.3443,\n",
       "           0.0736,  0.5139, -0.1659,  0.4853,  0.2025, -0.0507,  0.0220, -0.2582],\n",
       "         [ 0.1786, -0.0938,  0.3968, -0.2059, -0.0451, -0.0701, -0.3632, -0.4442,\n",
       "          -0.2435, -0.4445, -0.3260, -0.3669,  0.3480, -0.4940, -0.2186,  0.2794,\n",
       "          -0.4696, -0.1340,  0.0889,  0.3186, -0.0245, -0.2973,  0.3898, -0.3912,\n",
       "           0.3120,  0.3733, -0.0429, -0.5304,  0.0496, -0.0762,  0.1489,  0.2959],\n",
       "         [ 0.1441,  0.2465, -0.2794,  0.5298,  0.1818, -0.4208, -0.2333,  0.2303,\n",
       "          -0.2726,  0.0357,  0.4593,  0.3748,  0.1910,  0.5283,  0.4029, -0.2348,\n",
       "          -0.2271,  0.0350,  0.0498, -0.0704, -0.4248,  0.2213, -0.3331, -0.4643,\n",
       "           0.3163,  0.3623, -0.2025,  0.1500,  0.2379,  0.4059,  0.4125,  0.2971],\n",
       "         [ 0.2135,  0.1148,  0.0411, -0.4213,  0.1475,  0.2535, -0.3928, -0.1510,\n",
       "          -0.4573, -0.4600, -0.2478, -0.0338, -0.3964, -0.2728, -0.3017,  0.2831,\n",
       "           0.2473,  0.4607,  0.3263, -0.3431,  0.1516, -0.4060, -0.3365, -0.1539,\n",
       "          -0.1442,  0.1935, -0.0102,  0.4599,  0.1750, -0.2095,  0.3673,  0.2765],\n",
       "         [-0.1604,  0.2186,  0.2285,  0.4997, -0.2969,  0.1255, -0.4738,  0.0634,\n",
       "          -0.3871,  0.1468, -0.2154,  0.3085, -0.1898,  0.4191, -0.0633, -0.0327,\n",
       "          -0.0627, -0.4328,  0.3827,  0.3538,  0.3542,  0.1247, -0.0747, -0.2172,\n",
       "           0.1713, -0.3972,  0.0620,  0.3712,  0.2977, -0.2696,  0.4406, -0.4652],\n",
       "         [-0.3796,  0.1601, -0.5405,  0.1957, -0.2561,  0.3361,  0.0348, -0.4152,\n",
       "          -0.3202,  0.0351,  0.2156, -0.3202,  0.2278,  0.2326,  0.0011, -0.2128,\n",
       "          -0.4363, -0.4330, -0.0020,  0.2960, -0.0228, -0.2841,  0.0481,  0.2626,\n",
       "           0.3094,  0.3751, -0.3658,  0.2223, -0.0226, -0.0377,  0.3559, -0.1261],\n",
       "         [-0.2336,  0.3778, -0.0890, -0.3293,  0.4204, -0.2637, -0.3938,  0.3022,\n",
       "           0.3845, -0.2236, -0.2328, -0.4345, -0.1588, -0.3239,  0.5580, -0.1468,\n",
       "          -0.2124,  0.3579,  0.0779, -0.2371,  0.3244, -0.0826, -0.2746,  0.5241,\n",
       "           0.4663, -0.0754,  0.2642, -0.4266,  0.0605,  0.0082, -0.4343,  0.2463],\n",
       "         [-0.5899,  0.0479,  0.4076,  0.1428,  0.1046,  0.2194,  0.5341,  0.2373,\n",
       "          -0.3444,  0.1540,  0.2242,  0.1249,  0.0477,  0.3803, -0.0819,  0.4619,\n",
       "          -0.1376, -0.2556,  0.0673,  0.1680, -0.0995,  0.3847, -0.4767,  0.3726,\n",
       "          -0.2821, -0.4039,  0.3756,  0.2540, -0.0969,  0.0664,  0.1000,  0.2428],\n",
       "         [ 0.3476,  0.4543, -0.0526,  0.4526,  0.1550, -0.3160, -0.0622, -0.3306,\n",
       "           0.2825, -0.0210,  0.2212, -0.3897,  0.0298, -0.3216,  0.1069,  0.3214,\n",
       "          -0.1120,  0.5427, -0.1638,  0.5077, -0.2618,  0.3641, -0.4408, -0.4186,\n",
       "          -0.4167, -0.3538,  0.2686, -0.1232, -0.1253, -0.0682, -0.3008,  0.1853],\n",
       "         [-0.1483,  0.0956,  0.3471,  0.3535,  0.4236, -0.0479,  0.0085,  0.4106,\n",
       "          -0.4218, -0.3240,  0.3817,  0.1092,  0.1328,  0.1122, -0.0441,  0.4131,\n",
       "           0.5023,  0.2269, -0.1586, -0.2234, -0.0351,  0.0660, -0.3250,  0.1700,\n",
       "           0.4266,  0.4552, -0.1254, -0.0750,  0.0112, -0.0035,  0.0586,  0.1545],\n",
       "         [-0.2952,  0.2970, -0.4292, -0.1713,  0.3671,  0.4048, -0.2157,  0.1894,\n",
       "           0.4727,  0.1699, -0.0949,  0.3091,  0.4019, -0.2228,  0.1038,  0.3209,\n",
       "          -0.3126, -0.2467, -0.1849, -0.0533, -0.0695, -0.1582,  0.4109,  0.4492,\n",
       "           0.1504, -0.5032,  0.1065, -0.4633, -0.4752, -0.0800,  0.1498, -0.3362],\n",
       "         [-0.2413, -0.2629, -0.1804, -0.1968,  0.2745, -0.1584,  0.0912, -0.1650,\n",
       "          -0.1015,  0.4338, -0.2942, -0.1950, -0.3209, -0.5143,  0.1098,  0.4244,\n",
       "          -0.2654, -0.0199,  0.2046, -0.2862,  0.4878, -0.4456, -0.2567,  0.2776,\n",
       "           0.2393, -0.0412, -0.1154, -0.3646,  0.1043, -0.3034,  0.1689,  0.4576],\n",
       "         [-0.5464, -0.0460,  0.0049,  0.0637, -0.3368, -0.4549,  0.3593, -0.1827,\n",
       "           0.4533, -0.1314,  0.3590, -0.3934, -0.4090,  0.1727, -0.3831, -0.0061,\n",
       "          -0.3776, -0.0593, -0.4302,  0.2666, -0.5334, -0.1446, -0.2606,  0.2546,\n",
       "           0.4435, -0.4288, -0.0832,  0.2300,  0.2415,  0.2468, -0.3642, -0.0154]]),\n",
       " 'net.layers.4.heads.0.linear_block.0.0.bias': Parameter containing:\n",
       " tensor([ 0.0143,  0.0114, -0.0391, -0.0602, -0.0634,  0.0209,  0.0366,  0.0187,\n",
       "         -0.0722,  0.0398,  0.1127, -0.0019, -0.0597,  0.0062, -0.0919,  0.0257]),\n",
       " 'net.layers.4.heads.0.linear_block.0.2.weight': Parameter containing:\n",
       " tensor([0.8730, 1.0432, 1.0400, 0.8886, 0.9895, 0.9508, 1.0054, 0.9488, 0.8833,\n",
       "         0.9736, 1.0425, 0.9900, 0.8869, 1.0556, 1.0102, 0.8849]),\n",
       " 'net.layers.4.heads.0.linear_block.0.2.bias': Parameter containing:\n",
       " tensor([-0.0393, -0.0223, -0.0113, -0.0462, -0.0223, -0.0120,  0.0026, -0.0168,\n",
       "         -0.0585,  0.0176,  0.0374, -0.0096, -0.0436, -0.0202, -0.0504,  0.0078]),\n",
       " 'net.layers.4.heads.0.linear_block.1.0.weight': Parameter containing:\n",
       " tensor([[-0.3166,  0.0973,  0.6656,  0.5064,  0.1783,  0.5528, -0.4960,  0.6029,\n",
       "           0.0443,  0.1628, -0.5169,  0.1280,  0.4964,  0.2515,  0.5787, -0.3217],\n",
       "         [ 0.2940, -0.4714,  0.6931, -0.1047,  0.2046, -0.5082, -0.3708, -0.2665,\n",
       "           0.3916, -0.1111, -0.5787, -0.2939,  0.1932,  0.0037, -0.2871,  0.1056],\n",
       "         [-0.0866,  0.0116,  0.3738,  0.5510, -0.3977,  0.5233, -0.0264, -0.5678,\n",
       "           0.5173, -0.6758, -0.6167,  0.6716,  0.5679, -0.1012, -0.4026, -0.6170],\n",
       "         [-0.4246, -0.1881, -0.1869,  0.3188, -0.1345,  0.2172, -0.4782,  0.4276,\n",
       "          -0.6815,  0.1803,  0.2713, -0.3107,  0.4826, -0.6422, -0.2912,  0.3323],\n",
       "         [-0.1659, -0.3984,  0.6463, -0.1486,  0.1964,  0.3450, -0.4135,  0.6210,\n",
       "          -0.3450,  0.5348,  0.4681, -0.4821, -0.6626,  0.6016, -0.3119, -0.4986],\n",
       "         [-0.1029,  0.0285, -0.8009, -0.1304, -0.5691,  0.1518,  0.6123,  0.0990,\n",
       "          -0.3911, -0.5219,  0.7726,  0.3208,  0.4287,  0.0877,  0.2784, -0.0070],\n",
       "         [ 0.1238,  0.0200, -0.0661, -0.1776,  0.7180, -0.6390,  0.2812,  0.4800,\n",
       "           0.3603,  0.4731, -0.3718, -0.5741, -0.0473,  0.0339,  0.2466,  0.5549],\n",
       "         [ 0.3706, -0.1776, -0.6062, -0.5569,  0.6383, -0.7115,  0.3974, -0.3920,\n",
       "          -0.3417, -0.1982,  0.3647, -0.3257, -0.3809,  0.3811,  0.1942, -0.6701]]),\n",
       " 'net.layers.4.heads.0.linear_block.1.0.bias': Parameter containing:\n",
       " tensor([-0.0345, -0.0003, -0.0148,  0.0483,  0.0108,  0.0391, -0.0466, -0.0256]),\n",
       " 'net.layers.4.heads.0.linear_block.1.2.weight': Parameter containing:\n",
       " tensor([0.9994, 0.9860, 0.9058, 0.9907, 1.0222, 1.0271, 1.0099, 1.0466]),\n",
       " 'net.layers.4.heads.0.linear_block.1.2.bias': Parameter containing:\n",
       " tensor([ 0.0115,  0.0096, -0.0108, -0.0114,  0.0065, -0.0161, -0.0076,  0.0040]),\n",
       " 'net.layers.4.heads.0.out_block.weight': Parameter containing:\n",
       " tensor([[-0.4989, -0.8744,  0.3403,  0.8070, -0.8227,  0.2966,  1.1587,  0.1306]]),\n",
       " 'net.layers.4.heads.0.out_block.bias': Parameter containing:\n",
       " tensor([-0.0086]),\n",
       " 'net.layers.4.heads.1.linear_block.0.0.weight': Parameter containing:\n",
       " tensor([[ 1.7297e-01, -3.8574e-01,  3.3804e-01,  2.9325e-01,  3.4257e-01,\n",
       "           4.4139e-01,  2.0597e-02,  6.5701e-02, -2.2464e-01, -3.7165e-01,\n",
       "          -2.4600e-01,  3.1355e-01, -4.2074e-01,  7.1384e-02,  5.1989e-01,\n",
       "          -3.8925e-01, -2.8892e-02,  2.0921e-01, -3.7555e-01,  1.4762e-01,\n",
       "           5.0512e-01,  5.9261e-03, -2.9207e-01, -4.2581e-01, -8.3991e-02,\n",
       "          -3.1531e-01, -2.0859e-01,  3.8341e-01, -2.2971e-01, -2.7271e-01,\n",
       "           6.2375e-02,  2.5072e-01],\n",
       "         [ 2.3265e-01,  2.2144e-01, -6.6527e-01,  1.5660e-01,  1.2381e-01,\n",
       "           3.8551e-01, -4.5768e-01,  4.4672e-01,  3.4395e-01,  3.5845e-02,\n",
       "           2.7454e-01,  4.5306e-01, -2.2483e-01,  7.2891e-02,  6.8983e-01,\n",
       "           1.3901e-01, -1.4825e-01, -6.4295e-01,  2.5312e-01, -1.6991e-01,\n",
       "           1.2592e-02,  3.6743e-01,  4.4540e-01, -2.3903e-02, -1.4459e-01,\n",
       "          -2.1334e-01, -3.1582e-01, -2.6704e-01,  4.1709e-01,  1.0114e-01,\n",
       "          -4.6628e-02,  1.6645e-01],\n",
       "         [-4.0890e-01,  5.3379e-02, -2.3728e-01,  2.6707e-01, -2.0222e-01,\n",
       "          -2.5948e-01, -2.0064e-01,  1.1054e-01,  4.0311e-01, -4.9349e-01,\n",
       "          -3.8275e-01, -3.1727e-01,  5.0526e-02, -2.1049e-01, -3.2937e-01,\n",
       "           2.3411e-01, -3.2005e-01, -1.2991e-01, -1.0093e-01,  4.4542e-01,\n",
       "          -5.7283e-01, -1.6633e-01, -2.9679e-02, -3.3604e-01, -1.2443e-01,\n",
       "          -1.9523e-01,  1.2154e-01,  2.1478e-01, -1.5600e-02,  1.9118e-01,\n",
       "          -3.0966e-01,  3.9755e-01],\n",
       "         [ 2.4085e-01,  4.2227e-01, -4.9350e-02,  1.4161e-01,  1.7556e-01,\n",
       "          -5.9528e-02,  1.8866e-01, -3.3017e-01,  4.0259e-01, -1.0033e-02,\n",
       "          -2.0483e-01,  2.6439e-01, -4.2940e-01, -1.3741e-01,  4.0891e-01,\n",
       "          -2.2517e-01, -1.4813e-01,  3.5670e-02,  1.9561e-01, -1.5148e-01,\n",
       "          -2.0261e-01,  7.8713e-02, -1.9004e-01, -3.9463e-01, -3.9293e-01,\n",
       "          -1.0758e-01, -8.2491e-02,  1.5150e-01, -4.1254e-01, -2.4779e-01,\n",
       "          -3.4040e-01, -2.3282e-01],\n",
       "         [ 1.2528e-02,  2.2371e-01, -1.4103e-01,  2.9513e-01, -4.8497e-01,\n",
       "           4.4642e-01,  2.6416e-01,  2.7693e-02,  4.9795e-01, -4.7636e-01,\n",
       "           2.7240e-01,  1.1329e-01, -1.6459e-01,  3.6757e-01,  5.9892e-01,\n",
       "           3.5446e-02, -5.5793e-01, -2.9479e-01,  3.0316e-01, -1.1856e-01,\n",
       "           2.4849e-01,  4.5297e-02,  2.6892e-02, -1.6117e-01,  2.4925e-01,\n",
       "           3.2495e-01, -1.0862e-01, -2.4417e-01, -3.8741e-02, -1.6732e-01,\n",
       "           1.4444e-01, -5.7965e-01],\n",
       "         [-1.4791e-01, -1.1755e-02, -3.3276e-01,  1.2633e-01,  4.0125e-01,\n",
       "          -2.8792e-01,  9.6784e-02, -3.7951e-01,  2.0022e-01,  1.4986e-01,\n",
       "           1.9178e-01,  1.9324e-02, -1.3677e-01, -5.2360e-01, -5.4826e-02,\n",
       "          -6.6862e-04,  3.0970e-01,  4.9736e-01, -3.4518e-01,  2.5434e-01,\n",
       "           4.7170e-02,  2.7625e-01, -3.4071e-02, -4.4287e-02, -2.4457e-01,\n",
       "          -7.7664e-02, -2.5062e-01, -3.8482e-01,  5.2578e-01,  5.5675e-02,\n",
       "           3.1574e-01,  3.0989e-01],\n",
       "         [ 3.6868e-01,  2.6899e-01,  2.1885e-01, -2.8683e-01, -2.6339e-01,\n",
       "          -3.1801e-01, -2.3108e-01, -7.7869e-02, -5.0068e-01,  2.6952e-01,\n",
       "          -1.2460e-02, -5.5114e-02,  3.4647e-01,  1.0455e-01, -2.2841e-01,\n",
       "          -4.2548e-01, -4.0412e-01,  1.8396e-01,  1.8046e-01, -5.2358e-01,\n",
       "           5.1928e-01, -2.3082e-01,  4.6226e-01,  1.3533e-01, -8.8320e-02,\n",
       "          -5.6696e-01, -1.7854e-01, -1.8742e-01,  4.2130e-01, -4.4596e-01,\n",
       "          -1.7476e-01, -6.6240e-02],\n",
       "         [-2.3932e-01, -1.4161e-01,  4.4608e-01,  4.5663e-01,  1.0143e-01,\n",
       "          -3.4785e-01,  4.6689e-02,  4.8440e-01,  1.9490e-01, -3.1931e-01,\n",
       "          -3.7412e-01,  7.6419e-02, -4.8448e-02,  4.6554e-01, -4.8278e-02,\n",
       "           2.7050e-01, -4.8223e-01, -3.7226e-01,  2.3498e-01,  3.2877e-01,\n",
       "          -1.9533e-01,  1.5450e-01,  3.5258e-01, -6.6143e-02,  1.8604e-01,\n",
       "          -1.5660e-01, -2.7991e-01,  1.3825e-01, -2.1820e-01, -3.1182e-01,\n",
       "          -2.2252e-01, -4.8097e-01],\n",
       "         [-2.3027e-01,  4.4907e-01, -1.1176e-01, -1.6989e-01, -1.1659e-01,\n",
       "          -2.0905e-01, -1.8295e-01,  9.7155e-02, -3.7850e-01, -4.7795e-01,\n",
       "           3.8663e-01, -1.9352e-01, -1.2869e-01,  2.7577e-01, -6.8569e-02,\n",
       "           6.4246e-01,  8.2988e-02,  4.1787e-01,  3.0266e-01,  6.1569e-01,\n",
       "           7.1636e-02, -1.0855e-01, -5.3757e-02,  1.5634e-01, -5.4048e-01,\n",
       "           3.6537e-01, -3.3860e-02,  7.0581e-01,  6.4138e-02,  1.5708e-01,\n",
       "           5.3076e-02,  4.3497e-01],\n",
       "         [ 1.0048e-01, -1.6395e-01,  2.4054e-01,  3.0296e-02, -1.5791e-01,\n",
       "          -9.3646e-02,  1.0364e-01, -4.9196e-01, -2.5267e-01,  8.0739e-03,\n",
       "          -1.4284e-01,  3.9780e-01, -1.1432e-01,  7.0513e-02, -4.8003e-01,\n",
       "          -2.5883e-01,  1.8912e-01,  1.0796e-01,  4.4542e-01,  5.6392e-01,\n",
       "          -1.1716e-01, -4.1819e-01,  1.3058e-01, -2.6280e-01, -3.7242e-01,\n",
       "          -3.6353e-01, -3.0331e-01,  6.2106e-01, -7.3850e-03,  2.6846e-01,\n",
       "           4.2539e-02, -9.4445e-02],\n",
       "         [-1.9917e-01,  2.2476e-01,  3.9035e-02, -3.2475e-01, -6.6277e-02,\n",
       "           2.3265e-01,  4.2003e-03,  2.3301e-01,  3.5003e-01, -4.4953e-01,\n",
       "          -1.6816e-01,  3.5605e-01, -2.6043e-01, -5.1027e-02,  4.6144e-02,\n",
       "          -4.1523e-01, -3.3723e-01, -6.4206e-01, -2.4900e-01, -2.2377e-01,\n",
       "          -2.1418e-01, -2.4108e-01, -3.0543e-01, -1.9351e-01, -5.2857e-02,\n",
       "           1.8650e-01, -6.4794e-01, -5.4633e-01,  1.0664e-01, -3.7318e-01,\n",
       "           1.6407e-01, -1.3987e-01],\n",
       "         [ 4.9908e-02,  4.6477e-01, -3.3370e-01, -2.0321e-02, -9.2211e-02,\n",
       "          -1.5475e-02, -2.9751e-01,  3.6127e-01, -3.7333e-01, -1.7854e-01,\n",
       "           1.4070e-01,  3.5133e-01,  5.2097e-02,  1.6140e-03,  4.4850e-01,\n",
       "          -2.4951e-01, -5.9877e-03, -9.9544e-02, -7.2605e-02, -2.9844e-01,\n",
       "          -2.5578e-01, -1.7789e-01,  5.2446e-01, -4.4785e-03,  2.7119e-01,\n",
       "          -1.5640e-01,  2.1198e-01, -2.4075e-01,  8.4396e-02,  1.5073e-01,\n",
       "           6.9853e-03, -1.9368e-01],\n",
       "         [ 2.4091e-01, -4.5701e-01, -1.2428e-03, -2.7665e-01,  3.2732e-01,\n",
       "           3.8301e-01, -2.2550e-01, -7.9034e-02,  1.3055e-03, -3.9990e-01,\n",
       "           1.1992e-01,  4.3074e-02, -1.6176e-01,  2.6370e-01, -3.2065e-02,\n",
       "          -2.3039e-01,  4.1561e-01,  4.3740e-01, -3.9541e-01, -1.4960e-01,\n",
       "          -4.1048e-01, -4.2983e-01, -4.3220e-01, -1.0366e-01,  7.2663e-02,\n",
       "           4.5546e-02, -3.9856e-01, -4.1632e-01, -3.9119e-01,  3.2669e-01,\n",
       "          -2.0245e-01, -3.5139e-01],\n",
       "         [-1.1320e-01,  2.8648e-01,  2.3279e-01,  4.1759e-01, -3.3881e-01,\n",
       "          -1.2570e-01,  3.2807e-01,  1.3224e-01, -7.0638e-02, -4.0318e-03,\n",
       "          -2.3460e-01,  4.4364e-01,  3.5855e-01, -1.2474e-01,  9.7949e-02,\n",
       "           3.3764e-01, -2.2169e-01,  2.8687e-01, -1.2881e-01, -1.6453e-01,\n",
       "           2.2480e-01, -3.8407e-01, -4.0156e-02, -3.8704e-01,  1.4420e-01,\n",
       "          -1.0746e-01, -2.2572e-01,  1.0584e-01, -6.8222e-02,  4.2629e-01,\n",
       "          -6.8424e-02,  3.5323e-01],\n",
       "         [ 5.5399e-01, -5.4357e-01,  3.2655e-01,  2.6741e-01, -1.1026e-01,\n",
       "          -7.4273e-02, -5.5076e-01, -2.4942e-01, -7.0972e-02,  1.2262e-01,\n",
       "          -3.9277e-01,  2.3006e-01,  2.5718e-02, -4.9245e-01, -2.6717e-01,\n",
       "          -3.3660e-02,  3.6524e-01,  1.6293e-01,  4.0846e-01,  4.4835e-01,\n",
       "           9.3579e-02, -3.4911e-02,  3.1036e-01, -3.1907e-01,  6.0266e-01,\n",
       "           4.4760e-01,  1.5553e-01, -5.5398e-01, -3.7996e-01,  3.2391e-02,\n",
       "          -1.5284e-01,  2.2069e-02],\n",
       "         [ 3.7439e-01, -1.4052e-01,  2.2532e-01, -2.8654e-01, -1.6603e-01,\n",
       "          -7.7781e-02, -2.2644e-01,  2.8366e-01,  7.9883e-02,  4.9433e-03,\n",
       "           1.9599e-01,  2.0578e-01, -9.7355e-02,  3.1257e-01,  4.9471e-02,\n",
       "           1.5787e-01, -1.7591e-02,  4.1992e-01, -3.7248e-01, -3.3425e-01,\n",
       "           2.4003e-01,  5.3825e-02, -8.0969e-02, -3.3413e-01, -4.4901e-01,\n",
       "           4.8847e-02,  1.3318e-01,  2.1760e-01,  1.7269e-01,  3.3391e-01,\n",
       "           3.2740e-01,  6.2025e-01]]),\n",
       " 'net.layers.4.heads.1.linear_block.0.0.bias': Parameter containing:\n",
       " tensor([-0.0153, -0.0224, -0.0921,  0.0231, -0.0829, -0.0125,  0.0336,  0.1135,\n",
       "          0.1365,  0.0961, -0.0481,  0.0269, -0.0800, -0.0184, -0.1717,  0.0541]),\n",
       " 'net.layers.4.heads.1.linear_block.0.2.weight': Parameter containing:\n",
       " tensor([0.7565, 0.9716, 1.1201, 0.8799, 0.9698, 0.9819, 1.0483, 0.8186, 1.1776,\n",
       "         1.0920, 1.0602, 0.9545, 0.9735, 0.8851, 1.0809, 1.0694]),\n",
       " 'net.layers.4.heads.1.linear_block.0.2.bias': Parameter containing:\n",
       " tensor([ 0.0063, -0.0498, -0.1116,  0.0380, -0.0517,  0.0356, -0.0234,  0.0727,\n",
       "          0.0934,  0.0755,  0.0241,  0.0010, -0.0119, -0.0298, -0.0808,  0.0336]),\n",
       " 'net.layers.4.heads.1.linear_block.1.0.weight': Parameter containing:\n",
       " tensor([[ 0.1903,  0.3642, -0.6201, -0.4680,  0.2943,  0.2797,  0.2668, -0.0358,\n",
       "           0.2517, -0.4422,  0.6428, -0.3046,  0.4866,  0.1635,  0.1863, -0.4893],\n",
       "         [-0.1951, -0.1487, -0.0346,  0.6234, -0.4592,  0.3299,  0.3782, -0.6565,\n",
       "          -0.4304, -0.7030, -0.5120,  0.0819, -0.0621,  0.3985,  0.3650,  0.1630],\n",
       "         [ 0.3904,  0.0731, -0.8192,  0.5142, -0.2861, -0.6718,  0.4513,  0.7070,\n",
       "           0.1235,  0.1761, -0.5123,  0.8729, -0.2515, -0.1991, -0.6882,  0.2689],\n",
       "         [ 0.0777, -0.2196,  0.3942,  0.5380,  0.6054,  0.7654, -0.3067, -0.5312,\n",
       "           0.3066,  0.2251,  0.0264,  0.5236,  0.3748, -0.2902,  0.4083,  0.1601],\n",
       "         [ 0.3711, -0.5942, -0.4251,  0.5958, -0.0123,  0.2093, -0.2249, -0.3899,\n",
       "          -0.6502, -0.5213, -0.4077,  0.7403,  0.1317, -0.4485,  0.4274, -0.2509],\n",
       "         [ 0.1110,  0.2420,  0.5030, -0.3651,  0.3372,  0.0205,  0.1598, -0.4708,\n",
       "          -0.2838, -0.4963, -0.1402, -0.0033,  0.6820, -0.0629, -0.2727, -0.0406],\n",
       "         [-0.2475,  0.2429, -0.6361,  0.0149,  0.2747, -0.1592,  0.1275, -0.2600,\n",
       "          -0.7794, -0.6017,  0.4725,  0.1019, -0.0321, -0.5607, -0.0422, -0.2827],\n",
       "         [-0.5343, -0.6015, -0.6549,  0.3184, -0.7181,  0.4766, -0.6670,  0.1881,\n",
       "           0.3574,  0.6615,  0.0682, -0.3248, -0.4644,  0.0282, -0.7207,  0.4973]]),\n",
       " 'net.layers.4.heads.1.linear_block.1.0.bias': Parameter containing:\n",
       " tensor([ 0.0235, -0.0271,  0.1184,  0.0206, -0.0034, -0.0307, -0.0565,  0.1344]),\n",
       " 'net.layers.4.heads.1.linear_block.1.2.weight': Parameter containing:\n",
       " tensor([0.9201, 0.9862, 0.9694, 0.9849, 0.9524, 0.9629, 0.9345, 0.9717]),\n",
       " 'net.layers.4.heads.1.linear_block.1.2.bias': Parameter containing:\n",
       " tensor([ 0.0587, -0.0518,  0.0449, -0.0508,  0.0598,  0.0609, -0.0525, -0.0604]),\n",
       " 'net.layers.4.heads.1.out_block.weight': Parameter containing:\n",
       " tensor([[-0.7103,  0.9887, -0.1703,  0.5886, -0.7154, -0.5442,  0.6406,  0.7531]]),\n",
       " 'net.layers.4.heads.1.out_block.bias': Parameter containing:\n",
       " tensor([-0.0557])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(dict(trained_model.net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHLitModule(\n",
       "  (net): SequentialLitModel(\n",
       "    (layers): Sequential(\n",
       "      (0): EncoderLayer(\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (embeddings): EmbeddingLayer(\n",
       "          (embeddings): ModuleList(\n",
       "            (0-1): 2 x Embedding(20, 8)\n",
       "            (2): Embedding(7, 8)\n",
       "            (3): Embedding(6, 8)\n",
       "            (4): Embedding(1, 8)\n",
       "            (5): Embedding(4, 8)\n",
       "            (6): Embedding(14, 8)\n",
       "            (7-9): 3 x Embedding(20, 8)\n",
       "            (10-12): 3 x Embedding(2, 8)\n",
       "            (13-14): 2 x Embedding(7, 8)\n",
       "            (15): Embedding(6, 8)\n",
       "            (16): Embedding(5, 8)\n",
       "            (17): Embedding(18, 8)\n",
       "            (18): Embedding(17, 8)\n",
       "          )\n",
       "        )\n",
       "        (out_linear_block): Linear(in_features=158, out_features=32, bias=True)\n",
       "        (num_bn): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): PositionwiseFeedForward(\n",
       "        (position_wise_layer): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (2): GRUSeqToSeq(\n",
       "        (gru): GRU(32, 32, batch_first=True)\n",
       "      )\n",
       "      (3): ConvPooling(\n",
       "        (pooling_layer): MinMaxAvgPoolings()\n",
       "        (agg_layer): Conv1d(3, 1, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
       "      )\n",
       "      (4): MultiTaskLinearBlock(\n",
       "        (heads): ModuleList(\n",
       "          (0): LinearBlock(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear_block): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                (1): Tanh()\n",
       "                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "                (1): Tanh()\n",
       "                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (out_block): Linear(in_features=8, out_features=1, bias=True)\n",
       "            (cls_layers): Sequential(\n",
       "              (0): Dropout(p=0.0, inplace=False)\n",
       "              (1): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                  (1): Tanh()\n",
       "                  (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "                  (1): Tanh()\n",
       "                  (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=8, out_features=1, bias=True)\n",
       "              (3): Tanh()\n",
       "            )\n",
       "          )\n",
       "          (1): LinearBlock(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear_block): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (out_block): Linear(in_features=8, out_features=1, bias=True)\n",
       "            (cls_layers): Sequential(\n",
       "              (0): Dropout(p=0.0, inplace=False)\n",
       "              (1): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                  (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                  (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=8, out_features=1, bias=True)\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       "  (train_metrics): ModuleDict(\n",
       "    (tanh_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "    (gelu_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "  )\n",
       "  (val_metrics): ModuleDict(\n",
       "    (tanh_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "    (gelu_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "  )\n",
       "  (test_metrics): ModuleDict(\n",
       "    (tanh_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "    (gelu_output): ModuleDict(\n",
       "      (auroc): BinaryAUROC()\n",
       "    )\n",
       "  )\n",
       "  (monitor_metric): CompositionalMetric(\n",
       "    true_divide(\n",
       "      CompositionalMetric(\n",
       "    add(\n",
       "      CompositionalMetric(\n",
       "    add(\n",
       "      0,\n",
       "      BinaryAUROC()\n",
       "    )\n",
       "  ),\n",
       "      BinaryAUROC()\n",
       "    )\n",
       "  ),\n",
       "      2\n",
       "    )\n",
       "  )\n",
       "  (train_loss): MeanMetric()\n",
       "  (train_branched_loss): ModuleDict(\n",
       "    (tanh_output): MeanMetric()\n",
       "    (gelu_output): MeanMetric()\n",
       "  )\n",
       "  (val_loss): MeanMetric()\n",
       "  (val_branched_loss): ModuleDict(\n",
       "    (tanh_output): MeanMetric()\n",
       "    (gelu_output): MeanMetric()\n",
       "  )\n",
       "  (test_loss): MeanMetric()\n",
       "  (test_branched_loss): ModuleDict(\n",
       "    (tanh_output): MeanMetric()\n",
       "    (gelu_output): MeanMetric()\n",
       "  )\n",
       "  (val_best_metric): MaxMetric()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(trained_model.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metrics import GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelBatch(numerical=tensor([[[ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
       "         [ 2.7600,  2.0127,  0.9039, -0.4276,  7.2181,  0.0000],\n",
       "         [ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.6800,  0.8012,  0.7182,  0.6959,  7.2181,  0.0000],\n",
       "         [ 1.9200,  1.0005,  0.8417,  0.5399,  7.2181,  0.0000],\n",
       "         [ 2.5200,  1.6636,  0.9957, -0.0927,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.0400,  1.1128,  0.8969,  0.4422,  7.2181,  0.0000],\n",
       "         [ 2.2800,  1.3662,  0.9791,  0.2032,  7.2181,  0.0000],\n",
       "         [ 2.8800,  2.2093,  0.8030, -0.5960,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.2000,  0.4866,  0.4677,  0.8839,  7.2181,  0.0000],\n",
       "         [ 2.6400,  1.8312,  0.9663, -0.2574,  7.2181,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 3.0000,  2.4223,  0.6588, -0.7523,  7.2181,  0.0000],\n",
       "         [ 2.8800,  2.2093,  0.8030, -0.5960,  7.2181,  0.0000],\n",
       "         [ 0.1200,  0.0587,  0.0586,  0.9983,  7.2181,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.4000,  1.5090,  0.9981,  0.0618,  7.2181,  0.0000],\n",
       "         [ 0.1600,  0.1297,  0.1293,  0.9916,  7.2181,  0.2500],\n",
       "         [ 3.1200,  2.6531,  0.4693, -0.8830,  7.2181,  0.3333],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]), categorical=tensor([[[ 8, 12,  2,  ...,  4, 11,  0],\n",
       "         [ 8,  6,  2,  ...,  4,  0,  3],\n",
       "         [15, 19,  2,  ...,  4,  1,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 5, 13,  2,  ...,  4,  0,  3],\n",
       "         [17,  3,  2,  ...,  4, 10,  0],\n",
       "         [ 3, 11,  2,  ...,  4,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 9, 13,  2,  ...,  4,  3,  0],\n",
       "         [ 7, 14,  0,  ...,  4,  0,  2],\n",
       "         [12,  3,  2,  ...,  4,  1,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3, 14,  2,  ...,  4,  2,  0],\n",
       "         [19,  8,  2,  ...,  4,  9,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[14,  8,  2,  ...,  4,  0, 12],\n",
       "         [13,  0,  2,  ...,  4,  4,  0],\n",
       "         [ 6,  2,  2,  ...,  1,  0, 14],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "        [[ 4, 14,  2,  ...,  4,  3,  0],\n",
       "         [ 5,  2,  5,  ...,  1,  7,  0],\n",
       "         [ 2,  4,  2,  ...,  4,  0,  4],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  0]]]), targets=tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]), sample_indexes=['205752', '79395', '237004', '233274', '176497', '220761', '197006', '165157', '228883', '175573', '155502', '195609', '195726', '58738', '171916', '193082', '11649', '1116', '175727', '34714', '202912', '103650', '106129', '136174', '224524', '148490', '30124', '158412', '174236', '68798', '82200', '155277', '219993', '215575', '81732', '592', '193218', '231031', '16741', '118495', '214495', '104164', '99691', '10936', '180521', '101774', '106907', '20267', '35367', '66714', '103116', '200972', '96991', '64278', '189668', '70112', '158102', '144628', '191553', '66367', '65547', '146623', '527', '175564', '124653', '74817', '111847', '100079', '44827', '188182', '113297', '4869', '181560', '95904', '126643', '214624', '112306', '243763', '144068', '35462', '2477', '46625', '179391', '174178', '68917', '5686', '118464', '241625', '31124', '86201', '71228', '29394', '62751', '188514', '97880', '248371', '131067', '37967', '109722', '156417', '51795', '110407', '99115', '226683', '200117', '190791', '240985', '199927', '13278', '46056', '33870', '35143', '110621', '102285', '91293', '3257', '242937', '149155', '10684', '95783', '63452', '181734', '239771', '145718', '135222', '56459', '116006', '104710', '98669', '153555', '228660', '111249', '73343', '95823', '219240', '118536', '58976', '184242', '103592', '236517', '137659', '80327', '33891', '211857', '140486', '4907', '206821', '10109', '241423', '196897', '21048', '188219', '175083', '9831', '116893', '42824', '162608', '13425', '17442', '115767', '241378', '129945', '204266', '107253', '119214', '155669', '152369', '244473', '183061', '220889', '91925', '23594', '177934', '206804', '229225', '164330', '237477', '229686', '214521', '189351', '48147', '19441', '237414', '214093', '28746', '238566', '124189', '246181', '167099', '199457', '48771', '214689', '204663', '243149', '83258', '120993', '200224', '92608', '99918', '90682', '230522', '161590', '172970', '221955', '32842', '1606', '18685', '59628', '43467', '136628', '59477', '187683', '2106', '203808', '103854', '238966', '194149', '199769', '240135', '146730', '104313', '164764', '30768', '245188', '183602', '172451', '107623', '135183', '217383', '56237', '47009', '194819', '18839', '1110', '152975', '156845', '171881', '121382', '139979', '32286', '23512', '246355', '175544', '190984', '85308', '78489', '221515', '56325', '115746', '28895', '35474', '24032', '186406', '238104', '227549', '237752', '77775', '3392', '173115', '186763', '245788', '156042', '177084', '7740', '197251', '190313', '25322', '112403', '133746', '32539', '62098', '195214', '200951', '63778', '155155', '117726', '157843', '4488', '138242', '172563', '48333', '170458', '87653', '167105', '40184', '195783', '60874', '92987', '219194', '189659', '64400', '128680', '163134', '237927', '65421', '174452', '77466', '68299', '222277', '124557', '188881', '148494', '165936', '179561', '46354', '152912', '208370', '61808', '113636', '66607', '178105', '32829', '30492', '159497', '23854', '141125', '64985', '46564', '98477', '119059', '18889', '54070', '241211', '5768', '176484', '71416', '137117', '187574', '91155', '118395', '174574', '82794', '122712', '145020', '243294', '142252', '191788', '224812', '210496', '13089', '99403', '47694', '205631', '103689', '197626', '59925', '142951', '4042', '39538', '115533', '85440', '91426', '120165', '133712', '206278', '235205', '144972', '43737', '5728', '232278', '16644', '232089', '150265', '36348', '236708', '54953', '9990', '94189', '149403', '238091', '240440', '76786', '192640', '207840', '170523', '15457', '42052', '22558', '205925', '51910', '43235', '179006', '243298', '26498', '34024', '168065', '213611', '47642', '168869', '23667', '124118', '3159', '170315', '23874', '97054', '188049', '103861', '124395', '141673', '214013', '31573', '32322', '171671', '196324', '224463', '47371', '49281', '83579', '72943', '28626', '144306', '116489', '115223', '223884', '108693', '183937', '46820', '126061', '61814', '132482', '80407', '217865', '37379', '37660', '78917', '57044', '9085', '41871', '22731', '151699', '199', '228698', '119289', '199568', '76739', '237527', '209227', '52575', '52460', '204787', '192041', '247233', '55629', '107100', '97948', '197242', '139957', '150316', '54323', '211505', '235714', '177588', '100058', '203421', '144995', '245435', '201325', '132776', '152545', '183379', '5838', '144641', '203302', '223178', '100563', '199745', '20636', '200515', '197843', '189221', '234207', '93664', '171214', '65924', '200432', '145755', '238913', '182835', '30412', '91493', '44696', '242025', '108151', '214922', '160323', '126108', '232573', '118820', '67838', '80689', '171242', '132606', '90608', '94218', '191262', '158445', '52203', '83025', '105719', '18081', '113191', '200089', '114204', '14672', '143288', '240014', '8057', '192675', '131314', '247863', '88271', '151424', '125935', '146031', '173521', '5791', '51682', '130575', '156599', '33780', '35149', '187106', '233760', '164149', '14763', '45791', '13018', '33841', '99973', '16886', '169121', '16783', '60475', '170099', '114294', '148856', '218425', '83199', '125777', '147484', '229820', '236069', '49900', '22080', '76928', '66081', '85373', '3911', '167496', '121083', '127062', '186034', '139791', '216629', '172020', '95056', '202134', '135128', '188895', '21653', '47676', '208852', '155777', '44901', '217292', '126824', '87256', '119392', '144175', '181784', '60541', '162579', '83653', '152340', '73066', '144326', '34459', '84731', '230728', '15307', '147508', '10292', '136439', '175250', '24177', '115576', '44005', '239927', '26509', '102837', '151255', '9660', '97662', '167285', '4518', '217136', '233757', '93083', '151980', '338', '229424', '141199', '188526', '218512', '203330', '226076', '217820', '35637', '67426', '69421', '191146', '164843', '17044', '46289', '200046', '201374', '193900', '33243', '86150', '54135', '129040', '240198', '100991', '240677', '17122', '128027', '18836', '220647', '113203', '215372', '34897', '161655', '25879', '133292', '29777', '211499', '55494', '176530', '112643', '130212', '211701', '68563', '2731', '133912', '230197', '34954', '227979', '69152', '184807', '89409', '248727', '217039', '187654', '173697', '205870', '176494', '99708', '108477', '55460', '237568', '24096', '23259', '89432', '2124', '238640', '113517', '28311', '64565', '58560', '164771', '245899', '221651', '66875', '208738', '147231', '194147', '154369', '176432', '178571', '97781', '80146', '73576', '147175', '65857', '190366', '158046', '239718', '184855', '18376', '190862', '191746', '241430', '148786', '181919', '109101', '61534', '175881', '79678', '83045', '230518', '148538', '86864', '182008', '76104', '125962', '114446', '165681', '151114', '192424', '65267', '167467', '29802', '117388', '149461', '32871', '158367', '48649', '245972', '6711', '39704', '208653', '101804', '42705', '71943', '115369', '63217', '107568', '197640', '117237', '158526', '65115', '181730', '119899', '238872', '231569', '234472', '243334', '40211', '175846', '177602', '199531', '110566', '93829', '124385', '10409', '225352', '130650', '216531', '226459', '103392', '80993', '19142', '236353', '218031', '215852', '27798', '108269', '248406', '1544', '181165', '42066', '87161', '54277', '13124', '43614', '48085', '72051', '82128', '135340', '42515', '84869', '142530', '8853', '168197', '40437', '192007', '79593', '150699', '23983', '154058', '193121', '162763', '57024', '97878', '183378', '213724', '238323', '197003', '140223', '203189', '152365', '242874', '168044', '209640', '58121', '54930', '141818', '182490', '134655', '207865', '3096', '201968', '94510', '229127', '190409', '161228', '17848', '78926', '45771', '116344', '130947', '175792', '74973', '192457', '132505', '62166', '45740', '149389', '90461', '202100', '213791', '20078', '92097', '169079', '104984', '233345', '209250', '95135', '238604', '187637', '214292', '45545', '166502', '124529', '136787', '189215', '14170', '248125', '129495', '216793', '149042', '105948', '30650', '165424', '70824', '202280', '36290', '166890', '34453', '51974', '183355', '102876', '155981', '105171', '50701', '155215', '201350', '249803', '185963', '217022', '80084', '57221', '190259', '89368', '49231', '135265', '91893', '220513', '103537', '73663', '218958', '2907', '61422', '40099', '28096', '58418', '122343', '138074', '201038', '47048', '232828', '78959', '120845', '224337', '31666', '7510', '35621', '221693', '232724', '67763', '60784', '66963', '43166', '63046', '141383', '175157', '22572', '53400', '74389', '119271', '103164', '152342', '232096', '24830', '124997', '206703', '34645', '19022', '245150', '227374', '120586', '172973', '151381', '125104', '36398', '162355', '65213', '128783', '231957', '96050', '211550', '87958', '66621', '88457', '18100', '10326', '99839', '204355', '118460', '68417', '116575', '119080', '44178', '125635', '178875', '222731', '81717', '30664', '51509', '76864', '88411', '191026', '179721', '45380', '152854', '118539', '61517', '57229', '111099', '230394', '227328', '107861', '86781', '103717', '13064', '11511', '112072', '214887', '219416', '10217', '72287', '31073', '219222', '233474', '136802', '94823', '139897', '181820', '48030', '59974', '32879', '234697', '138451', '225424', '138911', '23982', '178825', '206219', '173887', '214946', '212644', '111094', '73619', '26400', '232971', '221286', '39183', '41119', '72638', '113586', '98882', '122355', '12794', '189559', '145655', '83217', '9445', '212992', '165514', '75268', '65341', '178565', '152254', '141965', '67852', '33480', '38822', '157964', '162183', '1906', '162302', '35876', '131894', '183942', '32647', '100906', '173732', '101491', '17680', '225397', '141666', '20045', '74125', '234333'], lengths=tensor([12,  6,  3,  ...,  2,  4,  3]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(54.0041)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(55.8003)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sample = next(iter(test_dataloader))\n",
    "d(GINI()(trained_model.net(test_sample).logits[:, 0], test_sample.targets))\n",
    "d(GINI()(trained_model.net(test_sample).logits[:, 1], test_sample.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [\n",
    "    trained_model.net(sample).logits.ravel() for i, sample in enumerate(test_dataloader) if i < 5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(plt.hist(preds, bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(plt.hist(torch.sigmoid(preds), bins=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thunder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_trained_model = thunder.jit(trained_model.net.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterpreterError",
     "evalue": "Encountered exception AttributeError: module 'dis' has no attribute '_parse_exception_table' while tracing SequentialLitModel(\n  (layers): Sequential(\n    (0): EncoderLayer(\n      (dropout): Dropout(p=0.3, inplace=False)\n      (embeddings): EmbeddingLayer(\n        (embeddings): ModuleList(\n          (0-1): 2 x Embedding(18, 32)\n          (2-3): 2 x Embedding(17, 32)\n          (4): Embedding(16, 32)\n          (5): Embedding(20, 32)\n          (6): Embedding(7, 32)\n          (7): Embedding(6, 32)\n          (8): Embedding(4, 32)\n          (9): Embedding(14, 32)\n          (10): Embedding(4, 32)\n          (11-12): 2 x Embedding(7, 32)\n          (13): Embedding(6, 32)\n          (14): Embedding(4, 32)\n          (15-16): 2 x Embedding(2, 32)\n          (17): Embedding(4, 32)\n          (18): Embedding(25, 32)\n          (19): Embedding(5, 32)\n          (20): Embedding(26, 32)\n          (21): Embedding(5, 32)\n          (22): Embedding(27, 32)\n          (23): Embedding(7, 32)\n          (24): Embedding(19, 32)\n          (25): Embedding(9, 32)\n          (26): Embedding(5, 32)\n          (27): Embedding(15, 32)\n          (28-30): 3 x Embedding(20, 32)\n        )\n      )\n      (out_linear_block): Linear(in_features=992, out_features=32, bias=True)\n    )\n    (1): GRUSeqToSeq(\n      (gru): GRU(32, 32, batch_first=True)\n    )\n    (2): ConvPooling(\n      (pooling_layer): AllPoolings()\n      (conv_layer): Conv1d(5, 1, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n    )\n    (3): MultiOutputLinearBlock(\n      (heads): ModuleList(\n        (0): LinearBlock(\n          (dropout): Dropout(p=0.0, inplace=False)\n          (linear_block): Sequential(\n            (0): Sequential(\n              (0): Linear(in_features=32, out_features=16, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n            )\n            (1): Sequential(\n              (0): Linear(in_features=16, out_features=8, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (out_block): Linear(in_features=8, out_features=1, bias=True)\n          (cls_layers): Sequential(\n            (0): Dropout(p=0.0, inplace=False)\n            (1): Sequential(\n              (0): Sequential(\n                (0): Linear(in_features=32, out_features=16, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n              )\n              (1): Sequential(\n                (0): Linear(in_features=16, out_features=8, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n              )\n            )\n            (2): Linear(in_features=8, out_features=1, bias=True)\n            (3): GELU(approximate='none')\n          )\n        )\n      )\n    )\n  )\n):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6557\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   6555\u001b[0m     populate_attribute_wrapper(wrapped_cell, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_contents\u001b[39m\u001b[38;5;124m\"\u001b[39m, fn_wrapped)\n\u001b[0;32m-> 6557\u001b[0m interpretation_result: Any \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_fn_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6558\u001b[0m interpretation_result \u001b[38;5;241m=\u001b[39m unwrap(interpretation_result)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6543\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_.<locals>.getfn.<locals>.fn_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_2\u001b[39m(args, kwargs):\n\u001b[0;32m-> 6543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/sequential_model.py:19\u001b[0m, in \u001b[0;36mSequentialLitModel.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: ModelInput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelOutput:\n\u001b[0;32m---> 19\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(inputs)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/embedding/encoder_layer.py:66\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: ModelInput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SingleForwardState:\n\u001b[0;32m---> 66\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(inputs\u001b[38;5;241m.\u001b[39mcategorical)\n\u001b[1;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6110\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6109\u001b[0m     populate_attribute_wrapper(wrapped_call, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, wrapped_fn)\n\u001b[0;32m-> 6110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;66;03m# (7) interprets into the function\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _interpret_call at line 5885 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _call_function_ex_handler at line 3507 (1 times), _interpret_call at line 5885 (1 times), _run_frame at line 6284 (1 times), _setup_frame_and_run_python_function at line 6238 (1 times), default_opcode_interpreter at line 1206 (1 times), InterpreterCompileCtx.interpret at line 408 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5944\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5946\u001b[0m \u001b[38;5;66;03m# (1b) The callable is a builtin method, in which case it's canonicalized\u001b[39;00m\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;66;03m#   A builtin is canonicalized when it's a call on a type or a module (or their equivalent)\u001b[39;00m\n\u001b[1;32m   5948\u001b[0m \u001b[38;5;66;03m#   Ex. The append method of a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5989\u001b[0m \u001b[38;5;66;03m# NOTE Builtin Methods\u001b[39;00m\n\u001b[1;32m   5990\u001b[0m \u001b[38;5;66;03m#   Builtin methods are not considered methods by inspect.ismethod\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _call_dispatch at line 6114 (1 times), _interpret_call at line 5885 (1 times), _setup_frame_and_run_python_function at line 6243 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5942\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 5942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3507\u001b[0m, in \u001b[0;36m_call_function_ex_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   3506\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m wrap_kwargs_from_dict(kwargs)\n\u001b[0;32m-> 3507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m check_and_append(stack, \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/embedding/encoder_layer.py:29\u001b[0m, in \u001b[0;36mEmbeddingLayer.forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m---> 29\u001b[0m         [embedding(x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]) \u001b[38;5;28;01mfor\u001b[39;00m idx, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m     ) \u001b[38;5;66;03m# size = (batch_size, len(cat_features), embedding_dim)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/nfs/samples_RNN/LHT_credits-history/src/models/components/embedding/encoder_layer.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m---> 29\u001b[0m         [embedding(x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]) \u001b[38;5;28;01mfor\u001b[39;00m idx, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m     ) \u001b[38;5;66;03m# size = (batch_size, len(cat_features), embedding_dim)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5601\u001b[0m, in \u001b[0;36m_unpack_sequence_handler\u001b[0;34m(inst, stack, **kwargs)\u001b[0m\n\u001b[1;32m   5599\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[0;32m-> 5601\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6046\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6045\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_lookaside(lookaside_fn)\n\u001b[0;32m-> 6046\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mlookaside_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6047\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1831\u001b[0m, in \u001b[0;36m_next_lookaside\u001b[0;34m(iterator, default)\u001b[0m\n\u001b[1;32m   1829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n\u001b[0;32m-> 1831\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _nil \u001b[38;5;129;01mand\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1829\u001b[0m, in \u001b[0;36m_next_lookaside.<locals>.impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimpl\u001b[39m(iterator):\n\u001b[0;32m-> 1829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6284\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6283\u001b[0m frame\u001b[38;5;241m.\u001b[39mlasti \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39minst_ptr  \u001b[38;5;66;03m# ???\u001b[39;00m\n\u001b[0;32m-> 6284\u001b[0m interpretation_result: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS \u001b[38;5;241m=\u001b[39m \u001b[43mcompilectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minst_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobals_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntimectx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mco\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpretation_result \u001b[38;5;129;01mis\u001b[39;00m INTERPRETER_SIGNALS\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:408\u001b[0m, in \u001b[0;36mInterpreterCompileCtx.interpret\u001b[0;34m(self, inst, **interpreter_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: dis\u001b[38;5;241m.\u001b[39mInstruction, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minterpreter_state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m INTERPRETER_SIGNALS:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opcode_interpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1206\u001b[0m, in \u001b[0;36mdefault_opcode_interpreter\u001b[0;34m(inst, **interpreter_state)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interpreter_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_cur_instruction(inst):\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minterpreter_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:3467\u001b[0m, in \u001b[0;36m_call_handler\u001b[0;34m(inst, stack, frame, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m     func \u001b[38;5;241m=\u001b[39m func_or_self\n\u001b[0;32m-> 3467\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_interpret_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3468\u001b[0m ctx: InterpreterCompileCtx \u001b[38;5;241m=\u001b[39m get_interpretercompilectx()\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:5885\u001b[0m, in \u001b[0;36m_interpret_call\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5884\u001b[0m runtimectx\u001b[38;5;241m.\u001b[39mrecord_interpreter_call(fn)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 5885\u001b[0m rval \u001b[38;5;241m=\u001b[39m \u001b[43m_call_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compilectx\u001b[38;5;241m.\u001b[39m_with_provenance_tracking:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6114\u001b[0m, in \u001b[0;36m_call_dispatch\u001b[0;34m(compilectx, runtimectx, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, FunctionType), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m had an unexpected type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fn)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_frame_and_run_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6243\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6242\u001b[0m     tb \u001b[38;5;241m=\u001b[39m TracebackType(e\u001b[38;5;241m.\u001b[39m__traceback__, python_frame, python_frame\u001b[38;5;241m.\u001b[39mf_lasti, python_frame\u001b[38;5;241m.\u001b[39mf_lineno)\n\u001b[0;32m-> 6243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m   6244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:1966\u001b[0m, in \u001b[0;36mSequenceIter.__next__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_reversed \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_pos \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms))) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_reversed \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_pos \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 1966\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[1;32m   1967\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_pos]\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6238\u001b[0m, in \u001b[0;36m_setup_frame_and_run_python_function\u001b[0;34m(compilectx, runtimectx, wrapped_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6238\u001b[0m     res, status \u001b[38;5;241m=\u001b[39m \u001b[43m_run_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompilectx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntimectx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   6240\u001b[0m     \u001b[38;5;66;03m# We need to cheat a bit to get a Python frame here...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6301\u001b[0m, in \u001b[0;36m_run_frame\u001b[0;34m(frame, compilectx, runtimectx, send_value)\u001b[0m\n\u001b[1;32m   6300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m-> 6301\u001b[0m     exception_table \u001b[38;5;241m=\u001b[39m \u001b[43mdis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_exception_table\u001b[49m(frame\u001b[38;5;241m.\u001b[39mcode)  \u001b[38;5;66;03m# type: ignore (_parse_exception_table is undocumented)\u001b[39;00m\n\u001b[1;32m   6303\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dis' has no attribute '_parse_exception_table'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInterpreterError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mjit_trained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:194\u001b[0m, in \u001b[0;36mThunderModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 194\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:611\u001b[0m, in \u001b[0;36mjit.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m cs\u001b[38;5;241m.\u001b[39mlast_trace_host_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[1;32m    609\u001b[0m cs\u001b[38;5;241m.\u001b[39mcalls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 611\u001b[0m cache_entry, inps, pro_to_epi \u001b[38;5;241m=\u001b[39m \u001b[43mget_computation_and_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m cs\u001b[38;5;241m.\u001b[39mlast_trace_host_execution_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[1;32m    614\u001b[0m result \u001b[38;5;241m=\u001b[39m cache_entry\u001b[38;5;241m.\u001b[39mcomputation_fn(\u001b[38;5;241m*\u001b[39minps)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:262\u001b[0m, in \u001b[0;36m_with_cache_info_ctx.<locals>.cache_info_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m tok \u001b[38;5;241m=\u001b[39m _cache_info_ctx\u001b[38;5;241m.\u001b[39mset({})\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     _cache_info_ctx\u001b[38;5;241m.\u001b[39mreset(tok)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:498\u001b[0m, in \u001b[0;36mjit.<locals>.get_computation_and_inputs\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m     prologue_trc: TraceCtx\n\u001b[1;32m    497\u001b[0m     computation_trc: TraceCtx\n\u001b[0;32m--> 498\u001b[0m     prologue_trc, computation_trc, \u001b[38;5;241m*\u001b[39mmaybe_epilogue \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharp_edges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msharp_edges\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maybe_epilogue:\n\u001b[1;32m    503\u001b[0m     epilogue_traces \u001b[38;5;241m=\u001b[39m maybe_epilogue\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/__init__.py:175\u001b[0m, in \u001b[0;36m_general_frontend\u001b[0;34m(fn, args, kwargs, sharp_edges)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_general_frontend\u001b[39m(fn: Callable, args, kwargs, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m, sharp_edges: SHARP_EDGES_OPTIONS) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[TraceCtx, TraceCtx]:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthunder_general_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharp_edges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharp_edges\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/jit_ext.py:1386\u001b[0m, in \u001b[0;36mthunder_general_jit\u001b[0;34m(fn, args, kwargs, sharp_edges)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m general_jit_ctx(ctx):\n\u001b[1;32m   1385\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracectx(computation_trace):\n\u001b[0;32m-> 1386\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mjfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m         prims\u001b[38;5;241m.\u001b[39mpython_return(result)\n\u001b[1;32m   1388\u001b[0m         process_recorded_modifications(ctx, epilogue_trace)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/thunder/core/interpreter.py:6566\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   6562\u001b[0m     traceback_str \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlinesep\u001b[38;5;241m.\u001b[39mjoin(f\u001b[38;5;241m.\u001b[39mformat_with_source() \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m runtimectx\u001b[38;5;241m.\u001b[39mframe_stack)\n\u001b[1;32m   6563\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   6564\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m while tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mlinesep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6565\u001b[0m     )\n\u001b[0;32m-> 6566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterpreterError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   6567\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   6568\u001b[0m     \u001b[38;5;66;03m# NOTE: Wrapped functions are valid to assign new attributes to.\u001b[39;00m\n\u001b[1;32m   6569\u001b[0m     fn_\u001b[38;5;241m.\u001b[39m_last_interpreted_instructions \u001b[38;5;241m=\u001b[39m runtimectx\u001b[38;5;241m.\u001b[39minterpreted_instructions  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mInterpreterError\u001b[0m: Encountered exception AttributeError: module 'dis' has no attribute '_parse_exception_table' while tracing SequentialLitModel(\n  (layers): Sequential(\n    (0): EncoderLayer(\n      (dropout): Dropout(p=0.3, inplace=False)\n      (embeddings): EmbeddingLayer(\n        (embeddings): ModuleList(\n          (0-1): 2 x Embedding(18, 32)\n          (2-3): 2 x Embedding(17, 32)\n          (4): Embedding(16, 32)\n          (5): Embedding(20, 32)\n          (6): Embedding(7, 32)\n          (7): Embedding(6, 32)\n          (8): Embedding(4, 32)\n          (9): Embedding(14, 32)\n          (10): Embedding(4, 32)\n          (11-12): 2 x Embedding(7, 32)\n          (13): Embedding(6, 32)\n          (14): Embedding(4, 32)\n          (15-16): 2 x Embedding(2, 32)\n          (17): Embedding(4, 32)\n          (18): Embedding(25, 32)\n          (19): Embedding(5, 32)\n          (20): Embedding(26, 32)\n          (21): Embedding(5, 32)\n          (22): Embedding(27, 32)\n          (23): Embedding(7, 32)\n          (24): Embedding(19, 32)\n          (25): Embedding(9, 32)\n          (26): Embedding(5, 32)\n          (27): Embedding(15, 32)\n          (28-30): 3 x Embedding(20, 32)\n        )\n      )\n      (out_linear_block): Linear(in_features=992, out_features=32, bias=True)\n    )\n    (1): GRUSeqToSeq(\n      (gru): GRU(32, 32, batch_first=True)\n    )\n    (2): ConvPooling(\n      (pooling_layer): AllPoolings()\n      (conv_layer): Conv1d(5, 1, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n    )\n    (3): MultiOutputLinearBlock(\n      (heads): ModuleList(\n        (0): LinearBlock(\n          (dropout): Dropout(p=0.0, inplace=False)\n          (linear_block): Sequential(\n            (0): Sequential(\n              (0): Linear(in_features=32, out_features=16, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n            )\n            (1): Sequential(\n              (0): Linear(in_features=16, out_features=8, bias=True)\n              (1): GELU(approximate='none')\n              (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (out_block): Linear(in_features=8, out_features=1, bias=True)\n          (cls_layers): Sequential(\n            (0): Dropout(p=0.0, inplace=False)\n            (1): Sequential(\n              (0): Sequential(\n                (0): Linear(in_features=32, out_features=16, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n              )\n              (1): Sequential(\n                (0): Linear(in_features=16, out_features=8, bias=True)\n                (1): GELU(approximate='none')\n                (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n              )\n            )\n            (2): Linear(in_features=8, out_features=1, bias=True)\n            (3): GELU(approximate='none')\n          )\n        )\n      )\n    )\n  )\n):\n"
     ]
    }
   ],
   "source": [
    "preds = jit_trained_model(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: ModelInput",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrained_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcredits_history_lit_model.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1405\u001b[0m, in \u001b[0;36mLightningModule.to_onnx\u001b[0;34m(self, file_path, input_sample, **kwargs)\u001b[0m\n\u001b[1;32m   1402\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_before_batch_transfer(input_sample)\n\u001b[1;32m   1403\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_batch_transfer_handler(input_sample)\n\u001b[0;32m-> 1405\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(mode)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:1613\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1610\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1611\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1613\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1628\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1629\u001b[0m )\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:1135\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m   1134\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1135\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:1011\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m   1007\u001b[0m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m   1013\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:915\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    913\u001b[0m prev_autocast_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    914\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 915\u001b[0m trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    924\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/jit/_trace.py:1296\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1295\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m-> 1296\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/torch_template/.venv/lib/python3.11/site-packages/torch/jit/_trace.py:105\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 105\u001b[0m     in_vars, in_desc \u001b[38;5;241m=\u001b[39m \u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# NOTE: use full state, because we need it for BatchNorm export\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# This differs from the compiler path, which doesn't support it at the moment.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     module_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(_unique_state_dict(\u001b[38;5;28mself\u001b[39m, keep_vars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: ModelInput"
     ]
    }
   ],
   "source": [
    "trained_model.net.to_onnx(\"credits_history_lit_model.onnx\", sample[0], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
